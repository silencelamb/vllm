BufferAssignment:
allocation 0: size 4194304, maybe-live-out:
 value: <2 loop_broadcast_fusion @0> (size=4194304,offset=0): f32[2,128,4096]{2,1,0}
allocation 1: size 8, output shape is |(f32[2,128,4096])|, maybe-live-out:
 value: <3 tuple.6.0{} @0> (size=8,offset=0): (f32[2,128,4096]{2,1,0})

Total bytes used: 4194312 (4.00MiB)

Used values:
<2 loop_broadcast_fusion @0>
 positions:
  loop_broadcast_fusion
  tuple.6.0 {0}
 uses:
  tuple.6.0, operand 0
 from instruction: %loop_broadcast_fusion = f32[2,128,4096]{2,1,0} fusion(), kind=kLoop, calls=%fused_broadcast, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
<3 tuple.6.0{} @0>
 positions:
  tuple.6.0 {}
 uses:
 from instruction: %tuple.6.0 = (f32[2,128,4096]{2,1,0}) tuple(f32[2,128,4096]{2,1,0} %loop_broadcast_fusion)


HloLiveRange (max 2):
  InstructionSequence:
    0:loop_broadcast_fusion
    1:tuple.6.0
  BufferLiveRange:
    loop_broadcast_fusion{}:0-2
    tuple.6.0{}:1-2
  Live ranges at 1 (peak):
    loop_broadcast_fusion: 4194304 bytes
    tuple.6.0: 8 bytes
