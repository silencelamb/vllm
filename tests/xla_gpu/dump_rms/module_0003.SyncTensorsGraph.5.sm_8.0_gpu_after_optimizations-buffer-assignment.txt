BufferAssignment:
allocation 0: size 4194304, maybe-live-out:
 value: <2 copy.1 @0> (size=4194304,offset=0): f32[2,128,4096]{2,1,0}
allocation 1: size 4194304, parameter 0, shape |f32[2,128,4096]| at ShapeIndex {}:
 value: <0 p0.1.0 @0> (size=4194304,offset=0): f32[2,128,4096]{2,1,0}
allocation 2: size 8, output shape is |(f32[2,128,4096])|, maybe-live-out:
 value: <3 tuple.1{} @0> (size=8,offset=0): (f32[2,128,4096]{2,1,0})
allocation 3: size 8, preallocated-temp:
 value: <1 tuple{} @0> (size=8,offset=0): (f32[2,128,4096]{2,1,0})

Total bytes used: 8388624 (8.00MiB)

Used values:
<0 p0.1.0 @0>
 positions:
  p0.1.0
  tuple {0}
  get-tuple-element.1
 uses:
  copy.1, operand 0
 from instruction: %p0.1.0 = f32[2,128,4096]{2,1,0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch/_prims_common/__init__.py" source_line=1991}
<1 tuple{} @0>
 positions:
  tuple {}
 uses:
  get-tuple-element.1, operand 0 {}
 from instruction: %tuple = (f32[2,128,4096]{2,1,0}) tuple(f32[2,128,4096]{2,1,0} %p0.1.0)
<2 copy.1 @0>
 positions:
  copy.1
  tuple.1 {0}
 uses:
  tuple.1, operand 0
 from instruction: %copy.1 = f32[2,128,4096]{2,1,0} copy(f32[2,128,4096]{2,1,0} %get-tuple-element.1)
<3 tuple.1{} @0>
 positions:
  tuple.1 {}
 uses:
 from instruction: %tuple.1 = (f32[2,128,4096]{2,1,0}) tuple(f32[2,128,4096]{2,1,0} %copy.1)


HloLiveRange (max 5):
  InstructionSequence:
    0:p0.1.0
    1:tuple
    2:get-tuple-element.1
    3:copy.1
    4:tuple.1
  BufferLiveRange:
    p0.1.0{}:0-5
    tuple{}:1-2
    copy.1{}:3-5
    tuple.1{}:4-5
  Live ranges at 3 (peak):
    p0.1.0: 4194304 bytes
    copy.1: 4194304 bytes
