%gemm_fusion_dot.15_computation (parameter_0: bf16[1024,2048], parameter_1: bf16[1024,2048], parameter_2: bf16[1024,2048], parameter_3: bf16[1024,2048]) -> bf16[128,4096] {
  %parameter_0 = bf16[1024,2048]{1,0} parameter(0)
  %parameter_1 = bf16[1024,2048]{1,0} parameter(1)
  %parameter_2 = bf16[1024,2048]{1,0} parameter(2)
  %parameter_3 = bf16[1024,2048]{1,0} parameter(3)
  %concatenate.9 = bf16[4096,2048]{1,0} concatenate(bf16[1024,2048]{1,0} %parameter_0, bf16[1024,2048]{1,0} %parameter_1, bf16[1024,2048]{1,0} %parameter_2, bf16[1024,2048]{1,0} %parameter_3), dimensions={0}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %constant_54 = bf16[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.51 = bf16[128,2048]{1,0} broadcast(bf16[] %constant_54), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %dot.17 = bf16[4096,128]{0,1} dot(bf16[4096,2048]{1,0} %concatenate.9, bf16[128,2048]{1,0} %broadcast.51), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %bitcast.431 = bf16[128,4096]{1,0} bitcast(bf16[4096,128]{0,1} %dot.17), metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}