%triton_softmax_computation.2 (param_0.11: f32[], param_1.40: bf16[128,4096]) -> f32[128,8,128] {
  %param_1.40 = bf16[128,4096]{1,0} parameter(1)
  %slice.23.1 = bf16[128,1024]{1,0} slice(bf16[128,4096]{1,0} %param_1.40), slice={[0:128], [2048:3072]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.343.3 = bf16[128,8,128]{2,1,0} bitcast(bf16[128,1024]{1,0} %slice.23.1)
  %convert.78.3 = f32[128,8,128]{2,1,0} convert(bf16[128,8,128]{2,1,0} %bitcast.343.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.36 = f32[128,8,128]{2,1,0} multiply(f32[128,8,128]{2,1,0} %convert.78.3, f32[128,8,128]{2,1,0} %convert.78.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_17 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.4 = f32[128,8]{1,0} reduce(f32[128,8,128]{2,1,0} %multiply.36, f32[] %constant_17), dimensions={2}, to_apply=%AddComputation.60, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_18 = f32[] constant(0.0078125), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.38 = f32[128,8]{1,0} broadcast(f32[] %constant_18), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.37 = f32[128,8]{1,0} multiply(f32[128,8]{1,0} %reduce.4, f32[128,8]{1,0} %broadcast.38), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.11 = f32[] parameter(0)
  %broadcast.40 = f32[128,8]{1,0} broadcast(f32[] %param_0.11), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1525/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.12 = f32[128,8]{1,0} add(f32[128,8]{1,0} %multiply.37, f32[128,8]{1,0} %broadcast.40), metadata={op_type="aten__add" op_name="aten__add.1525/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.8 = f32[128,8]{1,0} rsqrt(f32[128,8]{1,0} %add.12), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.41 = f32[128,8,128]{2,1,0} broadcast(f32[128,8]{1,0} %rsqrt.8), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.1526/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %multiply.39 = f32[128,8,128]{2,1,0} multiply(f32[128,8,128]{2,1,0} %convert.78.3, f32[128,8,128]{2,1,0} %broadcast.41), metadata={op_type="aten__mul" op_name="aten__mul.1526/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}