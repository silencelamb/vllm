HloModule SyncTensorsGraph.1181, is_scheduled=true, entry_computation_layout={(bf16[128]{0}, f32[], bf16[4096,1024]{1,0}, bf16[1024]{0}, s32[16]{0}, /*index=5*/bf16[151936,1024]{1,0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=10*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=15*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=20*/bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, /*index=25*/bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=30*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=35*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=40*/bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, /*index=45*/bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=50*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=55*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=60*/bf16[6144,1024]{1,0}, bf16[1024]{0}, s32[16]{0}, bf16[40960,128]{1,0}, bf16[2,4233,16,8,128]{4,3,2,1,0})->(bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0})}, frontend_attributes={fingerprint_before_lhs="50940237221f5eab399a24ceb08e58a7"}

%fused_gather (param_0.9: bf16[151936,1024], param_1.571: s32[16]) -> bf16[16,1,1024] {
  %param_0.9 = bf16[151936,1024]{1,0} parameter(0)
  %param_1.571 = s32[16]{0} parameter(1)
  %convert.702.1 = s64[16]{0} convert(s32[16]{0} %param_1.571), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.703.1 = u32[16]{0} convert(s64[16]{0} %convert.702.1), metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.2296.1 = u32[16,1]{1,0} bitcast(u32[16]{0} %convert.703.1)
  ROOT %gather.3 = bf16[16,1,1024]{2,0,1} gather(bf16[151936,1024]{1,0} %param_0.9, u32[16,1]{1,0} %bitcast.2296.1), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,1024}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_concatenate_computation (param_0.657: bf16[1024,2048], param_1.614: bf16[1024,2048], param_2.386: bf16[1024,2048], param_3.332: bf16[1024,2048], param_4.185: bf16[1024,2048], param_5.65: bf16[1024,2048], param_6.55: bf16[1024,2048], param_7.28: bf16[1024,2048], param_8.6: bf16[1024,2048], param_9: bf16[1024,2048], param_10: bf16[1024,2048], param_11: bf16[1024,2048], param_12: bf16[1024,2048], param_13: bf16[1024,2048]) -> bf16[14336,2048] {
  %param_0.657 = bf16[1024,2048]{1,0} parameter(0)
  %param_1.614 = bf16[1024,2048]{1,0} parameter(1)
  %param_2.386 = bf16[1024,2048]{1,0} parameter(2)
  %param_3.332 = bf16[1024,2048]{1,0} parameter(3)
  %param_4.185 = bf16[1024,2048]{1,0} parameter(4)
  %param_5.65 = bf16[1024,2048]{1,0} parameter(5)
  %param_6.55 = bf16[1024,2048]{1,0} parameter(6)
  %param_7.28 = bf16[1024,2048]{1,0} parameter(7)
  %param_8.6 = bf16[1024,2048]{1,0} parameter(8)
  %param_9 = bf16[1024,2048]{1,0} parameter(9)
  %param_10 = bf16[1024,2048]{1,0} parameter(10)
  %param_11 = bf16[1024,2048]{1,0} parameter(11)
  %param_12 = bf16[1024,2048]{1,0} parameter(12)
  %param_13 = bf16[1024,2048]{1,0} parameter(13)
  ROOT %concatenate.31.1 = bf16[14336,2048]{1,0} concatenate(bf16[1024,2048]{1,0} %param_0.657, bf16[1024,2048]{1,0} %param_1.614, bf16[1024,2048]{1,0} %param_2.386, bf16[1024,2048]{1,0} %param_3.332, bf16[1024,2048]{1,0} %param_4.185, /*index=5*/bf16[1024,2048]{1,0} %param_5.65, bf16[1024,2048]{1,0} %param_6.55, bf16[1024,2048]{1,0} %param_7.28, bf16[1024,2048]{1,0} %param_8.6, bf16[1024,2048]{1,0} %param_9, /*index=10*/bf16[1024,2048]{1,0} %param_10, bf16[1024,2048]{1,0} %param_11, bf16[1024,2048]{1,0} %param_12, bf16[1024,2048]{1,0} %param_13), dimensions={0}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
}

%gemm_fusion_dot.56_computation (parameter_0: bf16[14336,2048]) -> bf16[16,14336] {
  %parameter_0 = bf16[14336,2048]{1,0} parameter(0)
  %constant_155 = bf16[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.128 = bf16[16,2048]{1,0} broadcast(bf16[] %constant_155), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %dot.58 = bf16[14336,16]{0,1} dot(bf16[14336,2048]{1,0} %parameter_0, bf16[16,2048]{1,0} %broadcast.128), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %bitcast.1111 = bf16[16,14336]{1,0} bitcast(bf16[14336,16]{0,1} %dot.58), metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%AddComputation.74 (x.75: f32[], y.76: f32[]) -> f32[] {
  %y.76 = f32[] parameter(1)
  %x.75 = f32[] parameter(0)
  ROOT %add.190 = f32[] add(f32[] %x.75, f32[] %y.76)
}

%fused_computation.161 (param_0.587: f32[], param_1.546: bf16[16,1,1024], param_2.299: bf16[16,14336], param_3.229: bf16[1024]) -> bf16[16,1024] {
  %param_2.299 = bf16[16,14336]{1,0} parameter(2)
  %convert.701.48 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_2.299), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.200.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.48), slice={[0:16], [13312:14336]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.546 = bf16[16,1,1024]{2,0,1} parameter(1)
  %bitcast.2299.9 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_1.546)
  %convert.705.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.2299.9), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.191.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.200.9, f32[16,1024]{1,0} %convert.705.9), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.489 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.191.7, f32[16,1024]{1,0} %add.191.7), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_447 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.61 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.489, f32[] %constant_447), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_446 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.548 = f32[16]{0} broadcast(f32[] %constant_446), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.488 = f32[16]{0} multiply(f32[16]{0} %reduce.61, f32[16]{0} %broadcast.548), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.587 = f32[] parameter(0)
  %broadcast.547 = f32[16]{0} broadcast(f32[] %param_0.587), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.267 = f32[16]{0} add(f32[16]{0} %multiply.488, f32[16]{0} %broadcast.547), metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.110 = f32[16]{0} rsqrt(f32[16]{0} %add.267), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.546 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.110), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.15/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.487 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.191.7, f32[16,1024]{1,0} %broadcast.546), metadata={op_type="aten__mul" op_name="aten__mul.15/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.229 = bf16[1024]{0} parameter(3)
  %convert.706.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.229), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.330.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.706.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.16/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.336.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.487, f32[16,1024]{1,0} %broadcast.330.1), metadata={op_type="aten__mul" op_name="aten__mul.16/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.707.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.336.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.13 (param_0.645: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.645 = bf16[16,6144]{1,0} parameter(0)
  %slice.201.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.645), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.710.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.201.1)
  %constant_1_4 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.2 = f32[] convert(bf16[] %constant_1_4)
  %broadcast.384.56 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.2), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.42.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.710.8)
  %convert.714.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.42.5)
  %exponential.42.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.714.3)
  %convert.716.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.42.1)
  %add.192.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.56, f32[16,3072]{1,0} %convert.716.3)
  %divide.42.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.56, f32[16,3072]{1,0} %add.192.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.337.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.710.8, f32[16,3072]{1,0} %divide.42.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.202.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.645), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.717.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.202.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.338.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.337.5, f32[16,3072]{1,0} %convert.717.1), metadata={op_type="aten__mul" op_name="aten__mul.17/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.718.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.338.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.159 (param_0.632: f32[], param_1.603: bf16[1024], param_2.367: bf16[16,1,1024], param_3.308: bf16[16,14336], param_4.156: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.308 = bf16[16,14336]{1,0} parameter(3)
  %convert.701.84 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_3.308), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.199.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.84), slice={[0:16], [12288:13312]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.156 = bf16[16,1024]{1,0} parameter(4)
  %convert.719.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.156), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.200.11 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.84), slice={[0:16], [13312:14336]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.367 = bf16[16,1,1024]{2,0,1} parameter(2)
  %bitcast.2299.11 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_2.367)
  %convert.705.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.2299.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.191.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.200.11, f32[16,1024]{1,0} %convert.705.11), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.193.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.719.5, f32[16,1024]{1,0} %add.191.9), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.194.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.199.5, f32[16,1024]{1,0} %add.193.5), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.394 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.194.3, f32[16,1024]{1,0} %add.194.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_358 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.33 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.394, f32[] %constant_358), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_355 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.452 = f32[16]{0} broadcast(f32[] %constant_355), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.393 = f32[16]{0} multiply(f32[16]{0} %reduce.33, f32[16]{0} %broadcast.452), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.632 = f32[] parameter(0)
  %broadcast.450 = f32[16]{0} broadcast(f32[] %param_0.632), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.238 = f32[16]{0} add(f32[16]{0} %multiply.393, f32[16]{0} %broadcast.450), metadata={op_type="aten__add" op_name="aten__add.32/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.81 = f32[16]{0} rsqrt(f32[16]{0} %add.238), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.449 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.81), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.33/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.392 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.194.3, f32[16,1024]{1,0} %broadcast.449), metadata={op_type="aten__mul" op_name="aten__mul.33/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.603 = bf16[1024]{0} parameter(1)
  %convert.720.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.603), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.333.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.720.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.34/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.339.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.392, f32[16,1024]{1,0} %broadcast.333.1), metadata={op_type="aten__mul" op_name="aten__mul.34/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.721.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.339.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.12 (param_0.647: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.647 = bf16[16,6144]{1,0} parameter(0)
  %slice.203.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.647), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.722.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.203.1)
  %constant_1_6 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.4 = f32[] convert(bf16[] %constant_1_6)
  %broadcast.384.54 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.4), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.43.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.722.8)
  %convert.726.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.43.5)
  %exponential.43.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.726.3)
  %convert.727.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.43.1)
  %add.195.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.54, f32[16,3072]{1,0} %convert.727.3)
  %divide.43.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.54, f32[16,3072]{1,0} %add.195.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.340.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.722.8, f32[16,3072]{1,0} %divide.43.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.204.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.647), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.728.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.204.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.341.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.340.5, f32[16,3072]{1,0} %convert.728.1), metadata={op_type="aten__mul" op_name="aten__mul.35/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.729.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.341.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.157 (param_0.626: f32[], param_1.595: bf16[1024], param_2.371: bf16[16,1024], param_3.311: bf16[16,14336], param_4.162: bf16[16,1,1024], param_5.34: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.311 = bf16[16,14336]{1,0} parameter(3)
  %convert.701.70 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_3.311), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.198.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.70), slice={[0:16], [11264:12288]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.371 = bf16[16,1024]{1,0} parameter(2)
  %convert.731.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.371), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.199.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.70), slice={[0:16], [12288:13312]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.34 = bf16[16,1024]{1,0} parameter(5)
  %convert.719.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.34), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.200.15 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.70), slice={[0:16], [13312:14336]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.162 = bf16[16,1,1024]{2,0,1} parameter(4)
  %bitcast.2299.15 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_4.162)
  %convert.705.15 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.2299.15), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.191.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.200.15, f32[16,1024]{1,0} %convert.705.15), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.193.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.719.9, f32[16,1024]{1,0} %add.191.13), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.194.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.199.9, f32[16,1024]{1,0} %add.193.9), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.196.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.731.5, f32[16,1024]{1,0} %add.194.7), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.197.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.198.5, f32[16,1024]{1,0} %add.196.5), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.403 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.197.3, f32[16,1024]{1,0} %add.197.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_365 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.35 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.403, f32[] %constant_365), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_364 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.460 = f32[16]{0} broadcast(f32[] %constant_364), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.401 = f32[16]{0} multiply(f32[16]{0} %reduce.35, f32[16]{0} %broadcast.460), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.626 = f32[] parameter(0)
  %broadcast.458 = f32[16]{0} broadcast(f32[] %param_0.626), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.240 = f32[16]{0} add(f32[16]{0} %multiply.401, f32[16]{0} %broadcast.458), metadata={op_type="aten__add" op_name="aten__add.50/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.83 = f32[16]{0} rsqrt(f32[16]{0} %add.240), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.457 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.83), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.51/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.400 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.197.3, f32[16,1024]{1,0} %broadcast.457), metadata={op_type="aten__mul" op_name="aten__mul.51/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.595 = bf16[1024]{0} parameter(1)
  %convert.732.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.595), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.336.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.732.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.52/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.342.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.400, f32[16,1024]{1,0} %broadcast.336.1), metadata={op_type="aten__mul" op_name="aten__mul.52/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.733.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.342.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.11 (param_0.649: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.649 = bf16[16,6144]{1,0} parameter(0)
  %slice.205.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.649), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.734.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.205.1)
  %constant_1_8 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.6 = f32[] convert(bf16[] %constant_1_8)
  %broadcast.384.52 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.6), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.44.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.734.8)
  %convert.739.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.44.5)
  %exponential.44.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.739.3)
  %convert.740.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.44.1)
  %add.198.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.52, f32[16,3072]{1,0} %convert.740.3)
  %divide.44.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.52, f32[16,3072]{1,0} %add.198.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.343.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.734.8, f32[16,3072]{1,0} %divide.44.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.206.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.649), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.741.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.206.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.344.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.343.5, f32[16,3072]{1,0} %convert.741.1), metadata={op_type="aten__mul" op_name="aten__mul.53/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.742.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.344.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_add (param_0.501: bf16[16,14336], param_1.597: bf16[16,1024], param_2.369: bf16[16,1024], param_3.310: bf16[16,1,1024], param_4.160: bf16[16,1024]) -> f32[16,1024] {
  %param_0.501 = bf16[16,14336]{1,0} parameter(0)
  %convert.701.22 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_0.501), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.197.3 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.22), slice={[0:16], [10240:11264]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.597 = bf16[16,1024]{1,0} parameter(1)
  %convert.743.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.597), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.198.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.22), slice={[0:16], [11264:12288]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.369 = bf16[16,1024]{1,0} parameter(2)
  %convert.731.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.369), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.199.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.22), slice={[0:16], [12288:13312]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.160 = bf16[16,1024]{1,0} parameter(4)
  %convert.719.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.160), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.200.13 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.22), slice={[0:16], [13312:14336]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.310 = bf16[16,1,1024]{2,0,1} parameter(3)
  %bitcast.2299.13 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_3.310)
  %convert.705.13 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.2299.13), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.191.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.200.13, f32[16,1024]{1,0} %convert.705.13), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.193.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.719.7, f32[16,1024]{1,0} %add.191.11), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.194.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.199.7, f32[16,1024]{1,0} %add.193.7), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.196.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.731.7, f32[16,1024]{1,0} %add.194.5), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.197.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.198.7, f32[16,1024]{1,0} %add.196.7), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.199.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.743.3, f32[16,1024]{1,0} %add.197.5), metadata={op_type="aten__add" op_name="aten__add.54/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %add.200.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.197.3, f32[16,1024]{1,0} %add.199.3), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.155 (param_0.605: f32[16,1024], param_1.567: f32[], param_2.320: bf16[1024]) -> bf16[16,1024] {
  %param_0.605 = f32[16,1024]{1,0} parameter(0)
  %multiply.409 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.605, f32[16,1024]{1,0} %param_0.605), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_373 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.37 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.409, f32[] %constant_373), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_372 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.466 = f32[16]{0} broadcast(f32[] %constant_372), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.408 = f32[16]{0} multiply(f32[16]{0} %reduce.37, f32[16]{0} %broadcast.466), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.567 = f32[] parameter(1)
  %broadcast.465 = f32[16]{0} broadcast(f32[] %param_1.567), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.242 = f32[16]{0} add(f32[16]{0} %multiply.408, f32[16]{0} %broadcast.465), metadata={op_type="aten__add" op_name="aten__add.68/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.85 = f32[16]{0} rsqrt(f32[16]{0} %add.242), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.464 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.85), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.69/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.407 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.605, f32[16,1024]{1,0} %broadcast.464), metadata={op_type="aten__mul" op_name="aten__mul.69/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.320 = bf16[1024]{0} parameter(2)
  %convert.744.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.320), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.341.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.744.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.70/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.345.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.407, f32[16,1024]{1,0} %broadcast.341.1), metadata={op_type="aten__mul" op_name="aten__mul.70/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.747.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.345.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.10 (param_0.651: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.651 = bf16[16,6144]{1,0} parameter(0)
  %slice.207.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.651), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.748.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.207.1)
  %constant_1_10 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.8 = f32[] convert(bf16[] %constant_1_10)
  %broadcast.384.50 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.8), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.45.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.748.8)
  %convert.754.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.45.5)
  %exponential.45.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.754.3)
  %convert.755.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.45.1)
  %add.201.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.50, f32[16,3072]{1,0} %convert.755.3)
  %divide.45.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.50, f32[16,3072]{1,0} %add.201.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.347.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.748.8, f32[16,3072]{1,0} %divide.45.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.208.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.651), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.757.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.208.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.348.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.347.5, f32[16,3072]{1,0} %convert.757.1), metadata={op_type="aten__mul" op_name="aten__mul.71/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.759.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.348.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.153 (param_0.623: f32[], param_1.591: bf16[1024], param_2.350: f32[16,1024], param_3.284: bf16[16,1024], param_4.132: bf16[16,14336]) -> bf16[16,1024] {
  %param_4.132 = bf16[16,14336]{1,0} parameter(4)
  %convert.701.66 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_4.132), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.196.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.66), slice={[0:16], [9216:10240]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.284 = bf16[16,1024]{1,0} parameter(3)
  %convert.761.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.284), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.350 = f32[16,1024]{1,0} parameter(2)
  %add.202.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.761.5, f32[16,1024]{1,0} %param_2.350), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.204.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.196.5, f32[16,1024]{1,0} %add.202.5), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.415 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.204.3, f32[16,1024]{1,0} %add.204.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_378 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.39 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.415, f32[] %constant_378), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_377 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.472 = f32[16]{0} broadcast(f32[] %constant_377), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.414 = f32[16]{0} multiply(f32[16]{0} %reduce.39, f32[16]{0} %broadcast.472), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.623 = f32[] parameter(0)
  %broadcast.471 = f32[16]{0} broadcast(f32[] %param_0.623), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.244 = f32[16]{0} add(f32[16]{0} %multiply.414, f32[16]{0} %broadcast.471), metadata={op_type="aten__add" op_name="aten__add.86/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.87 = f32[16]{0} rsqrt(f32[16]{0} %add.244), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.470 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.87), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.87/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.413 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.204.3, f32[16,1024]{1,0} %broadcast.470), metadata={op_type="aten__mul" op_name="aten__mul.87/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.591 = bf16[1024]{0} parameter(1)
  %convert.762.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.591), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.344.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.762.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.88/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.349.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.413, f32[16,1024]{1,0} %broadcast.344.1), metadata={op_type="aten__mul" op_name="aten__mul.88/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.763.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.349.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.9 (param_0.653: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.653 = bf16[16,6144]{1,0} parameter(0)
  %slice.209.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.653), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.766.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.209.1)
  %constant_1_12 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.10 = f32[] convert(bf16[] %constant_1_12)
  %broadcast.384.48 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.10), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.46.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.766.8)
  %convert.770.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.46.5)
  %exponential.46.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.770.3)
  %convert.771.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.46.1)
  %add.205.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.48, f32[16,3072]{1,0} %convert.771.3)
  %divide.46.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.48, f32[16,3072]{1,0} %add.205.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.350.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.766.8, f32[16,3072]{1,0} %divide.46.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.210.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.653), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.772.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.210.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.351.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.350.5, f32[16,3072]{1,0} %convert.772.1), metadata={op_type="aten__mul" op_name="aten__mul.89/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.773.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.351.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.151 (param_0.640: f32[], param_1.611: bf16[1024], param_2.381: f32[16,1024], param_3.326: bf16[16,1024], param_4.178: bf16[16,14336], param_5.55: bf16[16,1024]) -> bf16[16,1024] {
  %param_4.178 = bf16[16,14336]{1,0} parameter(4)
  %convert.701.108 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_4.178), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.195.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.108), slice={[0:16], [8192:9216]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.55 = bf16[16,1024]{1,0} parameter(5)
  %convert.774.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.55), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.196.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.108), slice={[0:16], [9216:10240]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.326 = bf16[16,1024]{1,0} parameter(3)
  %convert.761.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.326), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.381 = f32[16,1024]{1,0} parameter(2)
  %add.202.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.761.9, f32[16,1024]{1,0} %param_2.381), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.204.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.196.9, f32[16,1024]{1,0} %add.202.9), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.206.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.774.5, f32[16,1024]{1,0} %add.204.7), metadata={op_type="aten__add" op_name="aten__add.90/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.207.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.195.5, f32[16,1024]{1,0} %add.206.5), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.422 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.207.3, f32[16,1024]{1,0} %add.207.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_383 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.41 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.422, f32[] %constant_383), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_382 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.479 = f32[16]{0} broadcast(f32[] %constant_382), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.421 = f32[16]{0} multiply(f32[16]{0} %reduce.41, f32[16]{0} %broadcast.479), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.640 = f32[] parameter(0)
  %broadcast.478 = f32[16]{0} broadcast(f32[] %param_0.640), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.246 = f32[16]{0} add(f32[16]{0} %multiply.421, f32[16]{0} %broadcast.478), metadata={op_type="aten__add" op_name="aten__add.104/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.89 = f32[16]{0} rsqrt(f32[16]{0} %add.246), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.477 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.89), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.105/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.420 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.207.3, f32[16,1024]{1,0} %broadcast.477), metadata={op_type="aten__mul" op_name="aten__mul.105/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.611 = bf16[1024]{0} parameter(1)
  %convert.775.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.611), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.348.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.775.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.106/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.352.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.420, f32[16,1024]{1,0} %broadcast.348.1), metadata={op_type="aten__mul" op_name="aten__mul.106/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.777.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.352.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.8 (param_0.655: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.655 = bf16[16,6144]{1,0} parameter(0)
  %slice.211.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.655), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.778.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.211.1)
  %constant_1_14 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.12 = f32[] convert(bf16[] %constant_1_14)
  %broadcast.384.46 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.12), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.47.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.778.8)
  %convert.784.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.47.5)
  %exponential.47.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.784.3)
  %convert.785.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.47.1)
  %add.208.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.46, f32[16,3072]{1,0} %convert.785.3)
  %divide.47.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.46, f32[16,3072]{1,0} %add.208.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.353.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.778.8, f32[16,3072]{1,0} %divide.47.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.212.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.655), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.786.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.212.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.354.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.353.5, f32[16,3072]{1,0} %convert.786.1), metadata={op_type="aten__mul" op_name="aten__mul.107/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.788.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.354.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.149 (param_0.620: f32[], param_1.587: bf16[1024], param_2.385: bf16[16,1024], param_3.331: bf16[16,14336], param_4.184: f32[16,1024], param_5.64: bf16[16,1024], param_6.54: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.331 = bf16[16,14336]{1,0} parameter(3)
  %convert.701.62 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_3.331), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.194.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.62), slice={[0:16], [7168:8192]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.385 = bf16[16,1024]{1,0} parameter(2)
  %convert.789.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.385), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.195.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.62), slice={[0:16], [8192:9216]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.54 = bf16[16,1024]{1,0} parameter(6)
  %convert.774.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_6.54), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.196.13 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.62), slice={[0:16], [9216:10240]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.64 = bf16[16,1024]{1,0} parameter(5)
  %convert.761.13 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.64), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.184 = f32[16,1024]{1,0} parameter(4)
  %add.202.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.761.13, f32[16,1024]{1,0} %param_4.184), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.204.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.196.13, f32[16,1024]{1,0} %add.202.13), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.206.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.774.9, f32[16,1024]{1,0} %add.204.11), metadata={op_type="aten__add" op_name="aten__add.90/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.207.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.195.9, f32[16,1024]{1,0} %add.206.9), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.209.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.789.5, f32[16,1024]{1,0} %add.207.7), metadata={op_type="aten__add" op_name="aten__add.108/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.210.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.194.5, f32[16,1024]{1,0} %add.209.5), metadata={op_type="aten__add" op_name="aten__add.121/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.428 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.210.3, f32[16,1024]{1,0} %add.210.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_388 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.43 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.428, f32[] %constant_388), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_387 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.487 = f32[16]{0} broadcast(f32[] %constant_387), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.427 = f32[16]{0} multiply(f32[16]{0} %reduce.43, f32[16]{0} %broadcast.487), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.620 = f32[] parameter(0)
  %broadcast.486 = f32[16]{0} broadcast(f32[] %param_0.620), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.248 = f32[16]{0} add(f32[16]{0} %multiply.427, f32[16]{0} %broadcast.486), metadata={op_type="aten__add" op_name="aten__add.122/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.91 = f32[16]{0} rsqrt(f32[16]{0} %add.248), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.485 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.91), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.123/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.426 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.210.3, f32[16,1024]{1,0} %broadcast.485), metadata={op_type="aten__mul" op_name="aten__mul.123/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.587 = bf16[1024]{0} parameter(1)
  %convert.790.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.587), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.351.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.790.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.124/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.355.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.426, f32[16,1024]{1,0} %broadcast.351.1), metadata={op_type="aten__mul" op_name="aten__mul.124/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.791.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.355.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.7 (param_0.643: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.643 = bf16[16,6144]{1,0} parameter(0)
  %slice.213.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.643), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.792.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.213.1)
  %constant_1_1 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.14 = f32[] convert(bf16[] %constant_1_1)
  %broadcast.384.44 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.14), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.48.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.792.8)
  %convert.796.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.48.5)
  %exponential.48.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.796.3)
  %convert.797.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.48.1)
  %add.211.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.44, f32[16,3072]{1,0} %convert.797.3)
  %divide.48.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.44, f32[16,3072]{1,0} %add.211.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.356.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.792.8, f32[16,3072]{1,0} %divide.48.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.214.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.643), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.798.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.214.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.357.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.356.5, f32[16,3072]{1,0} %convert.798.1), metadata={op_type="aten__mul" op_name="aten__mul.125/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.799.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.357.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_add.1 (param_0.509: bf16[16,14336], param_1.589: bf16[16,1024], param_2.383: bf16[16,1024], param_3.329: f32[16,1024], param_4.182: bf16[16,1024], param_5.60: bf16[16,1024]) -> f32[16,1024] {
  %param_0.509 = bf16[16,14336]{1,0} parameter(0)
  %convert.701.30 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_0.509), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.193.3 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.30), slice={[0:16], [6144:7168]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.589 = bf16[16,1024]{1,0} parameter(1)
  %convert.800.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.589), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.194.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.30), slice={[0:16], [7168:8192]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.383 = bf16[16,1024]{1,0} parameter(2)
  %convert.789.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.383), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.195.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.30), slice={[0:16], [8192:9216]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.60 = bf16[16,1024]{1,0} parameter(5)
  %convert.774.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.196.11 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.30), slice={[0:16], [9216:10240]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.182 = bf16[16,1024]{1,0} parameter(4)
  %convert.761.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.182), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.329 = f32[16,1024]{1,0} parameter(3)
  %add.202.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.761.11, f32[16,1024]{1,0} %param_3.329), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.204.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.196.11, f32[16,1024]{1,0} %add.202.11), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.206.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.774.7, f32[16,1024]{1,0} %add.204.9), metadata={op_type="aten__add" op_name="aten__add.90/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.207.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.195.7, f32[16,1024]{1,0} %add.206.7), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.209.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.789.7, f32[16,1024]{1,0} %add.207.5), metadata={op_type="aten__add" op_name="aten__add.108/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.210.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.194.7, f32[16,1024]{1,0} %add.209.7), metadata={op_type="aten__add" op_name="aten__add.121/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.212.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.800.3, f32[16,1024]{1,0} %add.210.5), metadata={op_type="aten__add" op_name="aten__add.126/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %add.213.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.193.3, f32[16,1024]{1,0} %add.212.3), metadata={op_type="aten__add" op_name="aten__add.139/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.147 (param_0.601: f32[16,1024], param_1.563: f32[], param_2.316: bf16[1024]) -> bf16[16,1024] {
  %param_0.601 = f32[16,1024]{1,0} parameter(0)
  %multiply.434 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.601, f32[16,1024]{1,0} %param_0.601), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_393 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.45 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.434, f32[] %constant_393), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_392 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.494 = f32[16]{0} broadcast(f32[] %constant_392), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.433 = f32[16]{0} multiply(f32[16]{0} %reduce.45, f32[16]{0} %broadcast.494), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.563 = f32[] parameter(1)
  %broadcast.493 = f32[16]{0} broadcast(f32[] %param_1.563), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.250 = f32[16]{0} add(f32[16]{0} %multiply.433, f32[16]{0} %broadcast.493), metadata={op_type="aten__add" op_name="aten__add.140/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.94 = f32[16]{0} rsqrt(f32[16]{0} %add.250), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.492 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.94), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.141/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.432 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.601, f32[16,1024]{1,0} %broadcast.492), metadata={op_type="aten__mul" op_name="aten__mul.141/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.316 = bf16[1024]{0} parameter(2)
  %convert.801.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.316), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.354.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.801.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.142/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.358.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.432, f32[16,1024]{1,0} %broadcast.354.1), metadata={op_type="aten__mul" op_name="aten__mul.142/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.803.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.358.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.6 (param_0.648: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.648 = bf16[16,6144]{1,0} parameter(0)
  %slice.215.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.648), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.804.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.215.1)
  %constant_1_7 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.5 = f32[] convert(bf16[] %constant_1_7)
  %broadcast.384.42 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.5), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.49.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.804.8)
  %convert.808.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.49.5)
  %exponential.49.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.808.3)
  %convert.810.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.49.1)
  %add.214.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.42, f32[16,3072]{1,0} %convert.810.3)
  %divide.49.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.42, f32[16,3072]{1,0} %add.214.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.359.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.804.8, f32[16,3072]{1,0} %divide.49.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.216.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.648), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.811.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.216.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.360.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.359.5, f32[16,3072]{1,0} %convert.811.1), metadata={op_type="aten__mul" op_name="aten__mul.143/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.812.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.360.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.145 (param_0.617: f32[], param_1.583: bf16[1024], param_2.338: f32[16,1024], param_3.268: bf16[16,1024], param_4.118: bf16[16,14336]) -> bf16[16,1024] {
  %param_4.118 = bf16[16,14336]{1,0} parameter(4)
  %convert.701.58 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_4.118), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.192.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.58), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.268 = bf16[16,1024]{1,0} parameter(3)
  %convert.813.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.268), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.338 = f32[16,1024]{1,0} parameter(2)
  %add.215.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.813.5, f32[16,1024]{1,0} %param_2.338), metadata={op_type="aten__add" op_name="aten__add.144/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.216.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.192.5, f32[16,1024]{1,0} %add.215.5), metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.440 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.216.3, f32[16,1024]{1,0} %add.216.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_398 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.47 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.440, f32[] %constant_398), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_397 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.500 = f32[16]{0} broadcast(f32[] %constant_397), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.439 = f32[16]{0} multiply(f32[16]{0} %reduce.47, f32[16]{0} %broadcast.500), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.617 = f32[] parameter(0)
  %broadcast.499 = f32[16]{0} broadcast(f32[] %param_0.617), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.252 = f32[16]{0} add(f32[16]{0} %multiply.439, f32[16]{0} %broadcast.499), metadata={op_type="aten__add" op_name="aten__add.158/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.96 = f32[16]{0} rsqrt(f32[16]{0} %add.252), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.498 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.96), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.159/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.438 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.216.3, f32[16,1024]{1,0} %broadcast.498), metadata={op_type="aten__mul" op_name="aten__mul.159/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.583 = bf16[1024]{0} parameter(1)
  %convert.814.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.583), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.357.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.814.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.160/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.361.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.438, f32[16,1024]{1,0} %broadcast.357.1), metadata={op_type="aten__mul" op_name="aten__mul.160/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.815.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.361.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.5 (param_0.652: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.652 = bf16[16,6144]{1,0} parameter(0)
  %slice.217.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.652), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.816.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.217.1)
  %constant_1_11 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.9 = f32[] convert(bf16[] %constant_1_11)
  %broadcast.384.40 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.9), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.50.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.816.8)
  %convert.823.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.50.5)
  %exponential.50.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.823.3)
  %convert.825.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.50.1)
  %add.217.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.40, f32[16,3072]{1,0} %convert.825.3)
  %divide.50.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.40, f32[16,3072]{1,0} %add.217.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.362.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.816.8, f32[16,3072]{1,0} %divide.50.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.218.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.652), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.826.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.218.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.363.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.362.5, f32[16,3072]{1,0} %convert.826.1), metadata={op_type="aten__mul" op_name="aten__mul.161/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.827.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.363.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.143 (param_0.636: f32[], param_1.607: bf16[1024], param_2.374: f32[16,1024], param_3.316: bf16[16,1024], param_4.167: bf16[16,14336], param_5.40: bf16[16,1024]) -> bf16[16,1024] {
  %param_4.167 = bf16[16,14336]{1,0} parameter(4)
  %convert.701.96 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_4.167), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.191.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.96), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.40 = bf16[16,1024]{1,0} parameter(5)
  %convert.829.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.40), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.192.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.96), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.316 = bf16[16,1024]{1,0} parameter(3)
  %convert.813.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.316), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.374 = f32[16,1024]{1,0} parameter(2)
  %add.215.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.813.9, f32[16,1024]{1,0} %param_2.374), metadata={op_type="aten__add" op_name="aten__add.144/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.216.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.192.9, f32[16,1024]{1,0} %add.215.9), metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.218.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.829.5, f32[16,1024]{1,0} %add.216.7), metadata={op_type="aten__add" op_name="aten__add.162/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.219.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.191.5, f32[16,1024]{1,0} %add.218.5), metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.446 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.219.3, f32[16,1024]{1,0} %add.219.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_403 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.49 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.446, f32[] %constant_403), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_402 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.507 = f32[16]{0} broadcast(f32[] %constant_402), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.445 = f32[16]{0} multiply(f32[16]{0} %reduce.49, f32[16]{0} %broadcast.507), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.636 = f32[] parameter(0)
  %broadcast.506 = f32[16]{0} broadcast(f32[] %param_0.636), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.254 = f32[16]{0} add(f32[16]{0} %multiply.445, f32[16]{0} %broadcast.506), metadata={op_type="aten__add" op_name="aten__add.176/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.98 = f32[16]{0} rsqrt(f32[16]{0} %add.254), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.505 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.98), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.177/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.444 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.219.3, f32[16,1024]{1,0} %broadcast.505), metadata={op_type="aten__mul" op_name="aten__mul.177/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.607 = bf16[1024]{0} parameter(1)
  %convert.831.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.607), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.361.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.831.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.178/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.364.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.444, f32[16,1024]{1,0} %broadcast.361.1), metadata={op_type="aten__mul" op_name="aten__mul.178/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.833.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.364.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.4 (param_0.656: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.656 = bf16[16,6144]{1,0} parameter(0)
  %slice.219.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.656), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.834.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.219.1)
  %constant_1_15 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.13 = f32[] convert(bf16[] %constant_1_15)
  %broadcast.384.38 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.13), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.51.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.834.8)
  %convert.840.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.51.5)
  %exponential.51.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.840.3)
  %convert.841.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.51.1)
  %add.220.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.38, f32[16,3072]{1,0} %convert.841.3)
  %divide.51.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.38, f32[16,3072]{1,0} %add.220.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.365.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.834.8, f32[16,3072]{1,0} %divide.51.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.220.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.656), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.842.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.220.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.366.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.365.5, f32[16,3072]{1,0} %convert.842.1), metadata={op_type="aten__mul" op_name="aten__mul.179/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.843.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.366.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.141 (param_0.614: f32[], param_1.579: bf16[1024], param_2.378: bf16[16,1024], param_3.321: bf16[16,14336], param_4.173: f32[16,1024], param_5.49: bf16[16,1024], param_6.37: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.321 = bf16[16,14336]{1,0} parameter(3)
  %convert.701.54 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_3.321), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.190.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.54), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.378 = bf16[16,1024]{1,0} parameter(2)
  %convert.844.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.378), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.191.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.54), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.37 = bf16[16,1024]{1,0} parameter(6)
  %convert.829.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_6.37), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.192.13 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.54), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.49 = bf16[16,1024]{1,0} parameter(5)
  %convert.813.13 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.49), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.173 = f32[16,1024]{1,0} parameter(4)
  %add.215.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.813.13, f32[16,1024]{1,0} %param_4.173), metadata={op_type="aten__add" op_name="aten__add.144/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.216.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.192.13, f32[16,1024]{1,0} %add.215.13), metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.218.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.829.9, f32[16,1024]{1,0} %add.216.11), metadata={op_type="aten__add" op_name="aten__add.162/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.219.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.191.9, f32[16,1024]{1,0} %add.218.9), metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.222.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.844.5, f32[16,1024]{1,0} %add.219.7), metadata={op_type="aten__add" op_name="aten__add.180/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.223.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.190.5, f32[16,1024]{1,0} %add.222.5), metadata={op_type="aten__add" op_name="aten__add.193/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.454 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.223.3, f32[16,1024]{1,0} %add.223.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_409 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.51 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.454, f32[] %constant_409), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_407 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.513 = f32[16]{0} broadcast(f32[] %constant_407), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.453 = f32[16]{0} multiply(f32[16]{0} %reduce.51, f32[16]{0} %broadcast.513), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.614 = f32[] parameter(0)
  %broadcast.512 = f32[16]{0} broadcast(f32[] %param_0.614), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.256 = f32[16]{0} add(f32[16]{0} %multiply.453, f32[16]{0} %broadcast.512), metadata={op_type="aten__add" op_name="aten__add.194/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.100 = f32[16]{0} rsqrt(f32[16]{0} %add.256), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.511 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.100), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.195/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.452 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.223.3, f32[16,1024]{1,0} %broadcast.511), metadata={op_type="aten__mul" op_name="aten__mul.195/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.579 = bf16[1024]{0} parameter(1)
  %convert.845.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.579), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.364.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.845.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.196/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.367.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.452, f32[16,1024]{1,0} %broadcast.364.1), metadata={op_type="aten__mul" op_name="aten__mul.196/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.846.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.367.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.3 (param_0.650: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.650 = bf16[16,6144]{1,0} parameter(0)
  %slice.221.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.650), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.847.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.221.1)
  %constant_1_9 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.7 = f32[] convert(bf16[] %constant_1_9)
  %broadcast.384.36 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.7), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.52.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.847.8)
  %convert.854.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.52.5)
  %exponential.52.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.854.3)
  %convert.855.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.52.1)
  %add.224.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.36, f32[16,3072]{1,0} %convert.855.3)
  %divide.52.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.36, f32[16,3072]{1,0} %add.224.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.368.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.847.8, f32[16,3072]{1,0} %divide.52.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.222.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.650), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.856.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.222.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.369.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.368.5, f32[16,3072]{1,0} %convert.856.1), metadata={op_type="aten__mul" op_name="aten__mul.197/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.857.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.369.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_add.2 (param_0.517: bf16[16,14336], param_1.581: bf16[16,1024], param_2.376: bf16[16,1024], param_3.319: f32[16,1024], param_4.171: bf16[16,1024], param_5.45: bf16[16,1024]) -> f32[16,1024] {
  %param_0.517 = bf16[16,14336]{1,0} parameter(0)
  %convert.701.38 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_0.517), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.189.3 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.38), slice={[0:16], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.581 = bf16[16,1024]{1,0} parameter(1)
  %convert.858.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.581), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.190.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.38), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.376 = bf16[16,1024]{1,0} parameter(2)
  %convert.844.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.376), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.191.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.38), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.45 = bf16[16,1024]{1,0} parameter(5)
  %convert.829.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.45), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.192.11 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.38), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.171 = bf16[16,1024]{1,0} parameter(4)
  %convert.813.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.171), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.319 = f32[16,1024]{1,0} parameter(3)
  %add.215.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.813.11, f32[16,1024]{1,0} %param_3.319), metadata={op_type="aten__add" op_name="aten__add.144/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.216.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.192.11, f32[16,1024]{1,0} %add.215.11), metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.218.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.829.7, f32[16,1024]{1,0} %add.216.9), metadata={op_type="aten__add" op_name="aten__add.162/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.219.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.191.7, f32[16,1024]{1,0} %add.218.7), metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.222.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.844.7, f32[16,1024]{1,0} %add.219.5), metadata={op_type="aten__add" op_name="aten__add.180/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.223.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.190.7, f32[16,1024]{1,0} %add.222.7), metadata={op_type="aten__add" op_name="aten__add.193/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.225.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.858.3, f32[16,1024]{1,0} %add.223.5), metadata={op_type="aten__add" op_name="aten__add.198/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %add.226.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.189.3, f32[16,1024]{1,0} %add.225.3), metadata={op_type="aten__add" op_name="aten__add.211/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.139 (param_0.597: f32[16,1024], param_1.559: f32[], param_2.312: bf16[1024]) -> bf16[16,1024] {
  %param_0.597 = f32[16,1024]{1,0} parameter(0)
  %multiply.462 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.597, f32[16,1024]{1,0} %param_0.597), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_414 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.53 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.462, f32[] %constant_414), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_413 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.520 = f32[16]{0} broadcast(f32[] %constant_413), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.461 = f32[16]{0} multiply(f32[16]{0} %reduce.53, f32[16]{0} %broadcast.520), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.559 = f32[] parameter(1)
  %broadcast.519 = f32[16]{0} broadcast(f32[] %param_1.559), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.258 = f32[16]{0} add(f32[16]{0} %multiply.461, f32[16]{0} %broadcast.519), metadata={op_type="aten__add" op_name="aten__add.212/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.102 = f32[16]{0} rsqrt(f32[16]{0} %add.258), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.517 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.102), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.213/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.459 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.597, f32[16,1024]{1,0} %broadcast.517), metadata={op_type="aten__mul" op_name="aten__mul.213/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.312 = bf16[1024]{0} parameter(2)
  %convert.860.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.312), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.367.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.860.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.214/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.370.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.459, f32[16,1024]{1,0} %broadcast.367.1), metadata={op_type="aten__mul" op_name="aten__mul.214/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.861.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.370.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.2 (param_0.646: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.646 = bf16[16,6144]{1,0} parameter(0)
  %slice.223.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.646), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.862.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.223.1)
  %constant_1_5 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.3 = f32[] convert(bf16[] %constant_1_5)
  %broadcast.384.34 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.3), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.53.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.862.8)
  %convert.866.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.53.5)
  %exponential.53.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.866.3)
  %convert.867.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.53.1)
  %add.227.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.34, f32[16,3072]{1,0} %convert.867.3)
  %divide.53.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.34, f32[16,3072]{1,0} %add.227.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.371.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.862.8, f32[16,3072]{1,0} %divide.53.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.224.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.646), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.868.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.224.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.372.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.371.5, f32[16,3072]{1,0} %convert.868.1), metadata={op_type="aten__mul" op_name="aten__mul.215/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.869.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.372.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.137 (param_0.611: f32[], param_1.575: bf16[1024], param_2.326: f32[16,1024], param_3.252: bf16[16,1024], param_4.104: bf16[16,14336]) -> bf16[16,1024] {
  %param_4.104 = bf16[16,14336]{1,0} parameter(4)
  %convert.701.50 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_4.104), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.188.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.50), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.252 = bf16[16,1024]{1,0} parameter(3)
  %convert.870.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.252), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.326 = f32[16,1024]{1,0} parameter(2)
  %add.228.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.870.5, f32[16,1024]{1,0} %param_2.326), metadata={op_type="aten__add" op_name="aten__add.216/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.229.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.188.5, f32[16,1024]{1,0} %add.228.5), metadata={op_type="aten__add" op_name="aten__add.229/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.470 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.229.3, f32[16,1024]{1,0} %add.229.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_419 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.55 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.470, f32[] %constant_419), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_418 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.528 = f32[16]{0} broadcast(f32[] %constant_418), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.468 = f32[16]{0} multiply(f32[16]{0} %reduce.55, f32[16]{0} %broadcast.528), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.611 = f32[] parameter(0)
  %broadcast.526 = f32[16]{0} broadcast(f32[] %param_0.611), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.261 = f32[16]{0} add(f32[16]{0} %multiply.468, f32[16]{0} %broadcast.526), metadata={op_type="aten__add" op_name="aten__add.230/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.104 = f32[16]{0} rsqrt(f32[16]{0} %add.261), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.525 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.104), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.231/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.466 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.229.3, f32[16,1024]{1,0} %broadcast.525), metadata={op_type="aten__mul" op_name="aten__mul.231/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.575 = bf16[1024]{0} parameter(1)
  %convert.871.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.575), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.370.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.871.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.232/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.373.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.466, f32[16,1024]{1,0} %broadcast.370.1), metadata={op_type="aten__mul" op_name="aten__mul.232/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.872.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.373.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.1 (param_0.654: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.654 = bf16[16,6144]{1,0} parameter(0)
  %slice.225.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.654), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.873.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.225.1)
  %constant_1_13 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.11 = f32[] convert(bf16[] %constant_1_13)
  %broadcast.384.32 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.11), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.54.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.873.8)
  %convert.878.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.54.5)
  %exponential.54.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.878.3)
  %convert.879.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.54.1)
  %add.230.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.32, f32[16,3072]{1,0} %convert.879.3)
  %divide.54.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.32, f32[16,3072]{1,0} %add.230.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.374.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.873.8, f32[16,3072]{1,0} %divide.54.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.226.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.654), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.880.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.226.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.376.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.374.5, f32[16,3072]{1,0} %convert.880.1), metadata={op_type="aten__mul" op_name="aten__mul.233/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.882.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.376.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.135 (param_0.629: f32[], param_1.599: bf16[1024], param_2.362: f32[16,1024], param_3.301: bf16[16,1024], param_4.147: bf16[16,14336], param_5.13: bf16[16,1024]) -> bf16[16,1024] {
  %param_4.147 = bf16[16,14336]{1,0} parameter(4)
  %convert.701.76 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_4.147), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.187.5 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.76), slice={[0:16], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.13 = bf16[16,1024]{1,0} parameter(5)
  %convert.883.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.13), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.188.9 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.76), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.301 = bf16[16,1024]{1,0} parameter(3)
  %convert.870.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.301), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.362 = f32[16,1024]{1,0} parameter(2)
  %add.228.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.870.9, f32[16,1024]{1,0} %param_2.362), metadata={op_type="aten__add" op_name="aten__add.216/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.229.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.188.9, f32[16,1024]{1,0} %add.228.9), metadata={op_type="aten__add" op_name="aten__add.229/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.231.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.883.5, f32[16,1024]{1,0} %add.229.7), metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.232.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.187.5, f32[16,1024]{1,0} %add.231.5), metadata={op_type="aten__add" op_name="aten__add.247/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.477 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.232.3, f32[16,1024]{1,0} %add.232.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_424 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.57 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.477, f32[] %constant_424), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_423 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.535 = f32[16]{0} broadcast(f32[] %constant_423), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.476 = f32[16]{0} multiply(f32[16]{0} %reduce.57, f32[16]{0} %broadcast.535), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.629 = f32[] parameter(0)
  %broadcast.534 = f32[16]{0} broadcast(f32[] %param_0.629), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.263 = f32[16]{0} add(f32[16]{0} %multiply.476, f32[16]{0} %broadcast.534), metadata={op_type="aten__add" op_name="aten__add.248/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.106 = f32[16]{0} rsqrt(f32[16]{0} %add.263), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.533 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.106), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.249/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.475 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.232.3, f32[16,1024]{1,0} %broadcast.533), metadata={op_type="aten__mul" op_name="aten__mul.249/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.599 = bf16[1024]{0} parameter(1)
  %convert.884.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.599), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.373.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.884.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.250/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.377.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.475, f32[16,1024]{1,0} %broadcast.373.1), metadata={op_type="aten__mul" op_name="aten__mul.250/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.885.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.377.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert (param_0.644: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.644 = bf16[16,6144]{1,0} parameter(0)
  %slice.227.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.644), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.886.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.227.1)
  %constant_1_3 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.911.1 = f32[] convert(bf16[] %constant_1_3)
  %broadcast.384.30 = f32[16,3072]{1,0} broadcast(f32[] %convert.911.1), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.55.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.886.8)
  %convert.892.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.55.5)
  %exponential.55.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.892.3)
  %convert.894.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.55.1)
  %add.233.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.384.30, f32[16,3072]{1,0} %convert.894.3)
  %divide.55.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.384.30, f32[16,3072]{1,0} %add.233.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.379.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.886.8, f32[16,3072]{1,0} %divide.55.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.228.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.644), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.895.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.228.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.380.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.379.5, f32[16,3072]{1,0} %convert.895.1), metadata={op_type="aten__mul" op_name="aten__mul.251/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.897.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.380.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.133 (param_0.594: f32[], param_1.601: bf16[16,1024], param_2.364: bf16[1024], param_3.304: f32[16,1024], param_4.151: bf16[16,1024], param_5.18: bf16[16,14336], param_6.11: bf16[16,1024]) -> bf16[16,1024] {
  %param_1.601 = bf16[16,1024]{1,0} parameter(1)
  %convert.898.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.601), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.18 = bf16[16,14336]{1,0} parameter(5)
  %convert.701.80 = f32[16,14336]{1,0} convert(bf16[16,14336]{1,0} %param_5.18), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.187.7 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.80), slice={[0:16], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.11 = bf16[16,1024]{1,0} parameter(6)
  %convert.883.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_6.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.188.11 = f32[16,1024]{1,0} slice(f32[16,14336]{1,0} %convert.701.80), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.151 = bf16[16,1024]{1,0} parameter(4)
  %convert.870.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.151), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.304 = f32[16,1024]{1,0} parameter(3)
  %add.228.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.870.11, f32[16,1024]{1,0} %param_3.304), metadata={op_type="aten__add" op_name="aten__add.216/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.229.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.188.11, f32[16,1024]{1,0} %add.228.11), metadata={op_type="aten__add" op_name="aten__add.229/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.231.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.883.7, f32[16,1024]{1,0} %add.229.9), metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.232.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.187.7, f32[16,1024]{1,0} %add.231.7), metadata={op_type="aten__add" op_name="aten__add.247/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.234.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.898.3, f32[16,1024]{1,0} %add.232.5), metadata={op_type="aten__add" op_name="aten__add.252/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.483 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.234.3, f32[16,1024]{1,0} %add.234.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_431 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.59 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.483, f32[] %constant_431), dimensions={1}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_430 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.541 = f32[16]{0} broadcast(f32[] %constant_430), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.482 = f32[16]{0} multiply(f32[16]{0} %reduce.59, f32[16]{0} %broadcast.541), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.594 = f32[] parameter(0)
  %broadcast.540 = f32[16]{0} broadcast(f32[] %param_0.594), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.265 = f32[16]{0} add(f32[16]{0} %multiply.482, f32[16]{0} %broadcast.540), metadata={op_type="aten__add" op_name="aten__add.253/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.108 = f32[16]{0} rsqrt(f32[16]{0} %add.265), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.539 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.108), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.254/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.481 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.234.3, f32[16,1024]{1,0} %broadcast.539), metadata={op_type="aten__mul" op_name="aten__mul.254/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.364 = bf16[1024]{0} parameter(2)
  %convert.899.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.364), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.377.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.899.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.255/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.381.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.481, f32[16,1024]{1,0} %broadcast.377.1), metadata={op_type="aten__mul" op_name="aten__mul.255/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.901.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.381.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_slice_computation (param_0.658: bf16[16,4096]) -> bf16[16,1024] {
  %param_0.658 = bf16[16,4096]{1,0} parameter(0)
  ROOT %slice.234.1 = bf16[16,1024]{1,0} slice(bf16[16,4096]{1,0} %param_0.658), slice={[0:16], [3072:4096]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%triton_softmax_computation.16 (param_0.523: f32[], param_1.530: bf16[16,4096]) -> f32[16,8,128] {
  %param_1.530 = bf16[16,4096]{1,0} parameter(1)
  %slice.229.1 = bf16[16,1024]{1,0} slice(bf16[16,4096]{1,0} %param_1.530), slice={[0:16], [2048:3072]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.2946.3 = bf16[16,8,128]{2,1,0} bitcast(bf16[16,1024]{1,0} %slice.229.1)
  %convert.903.3 = f32[16,8,128]{2,1,0} convert(bf16[16,8,128]{2,1,0} %bitcast.2946.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.281 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %convert.903.3, f32[16,8,128]{2,1,0} %convert.903.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_188 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.16 = f32[16,8]{1,0} reduce(f32[16,8,128]{2,1,0} %multiply.281, f32[] %constant_188), dimensions={2}, to_apply=%AddComputation.74, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_189 = f32[] constant(0.0078125), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.276 = f32[16,8]{1,0} broadcast(f32[] %constant_189), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.282 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %reduce.16, f32[16,8]{1,0} %broadcast.276), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.523 = f32[] parameter(0)
  %broadcast.277 = f32[16,8]{1,0} broadcast(f32[] %param_0.523), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.256/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.173 = f32[16,8]{1,0} add(f32[16,8]{1,0} %multiply.282, f32[16,8]{1,0} %broadcast.277), metadata={op_type="aten__add" op_name="aten__add.256/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.64 = f32[16,8]{1,0} rsqrt(f32[16,8]{1,0} %add.173), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.278 = f32[16,8,128]{2,1,0} broadcast(f32[16,8]{1,0} %rsqrt.64), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.257/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %multiply.283 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %convert.903.3, f32[16,8,128]{2,1,0} %broadcast.278), metadata={op_type="aten__mul" op_name="aten__mul.257/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_concatenate (param_0.609: f32[16,8,128], param_1.573: bf16[128], param_2.323: bf16[40960,128], param_3.248: s32[16]) -> bf16[16,8,128] {
  %param_0.609 = f32[16,8,128]{2,1,0} parameter(0)
  %param_1.573 = bf16[128]{0} parameter(1)
  %convert.905.11 = f32[128]{0} convert(bf16[128]{0} %param_1.573), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.378.14 = f32[16,8,128]{2,1,0} broadcast(f32[128]{0} %convert.905.11), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.258/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.382.14 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %param_0.609, f32[16,8,128]{2,1,0} %broadcast.378.14), metadata={op_type="aten__mul" op_name="aten__mul.258/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.230.7 = f32[16,8,64]{2,1,0} slice(f32[16,8,128]{2,1,0} %multiply.382.14), slice={[0:16], [0:8], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.323 = bf16[40960,128]{1,0} parameter(2)
  %param_3.248 = s32[16]{0} parameter(3)
  %bitcast.2962.3 = s32[16,1]{1,0} bitcast(s32[16]{0} %param_3.248)
  %gather.1.3 = bf16[16,1,128]{2,0,1} gather(bf16[40960,128]{1,0} %param_2.323, s32[16,1]{1,0} %bitcast.2962.3), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.2965.17 = bf16[16,128]{1,0} bitcast(bf16[16,1,128]{2,0,1} %gather.1.3)
  %convert.906.17 = f32[16,128]{1,0} convert(bf16[16,128]{1,0} %bitcast.2965.17), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.231.7 = f32[16,64]{1,0} slice(f32[16,128]{1,0} %convert.906.17), slice={[0:16], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.380.12 = f32[16,8,64]{2,1,0} broadcast(f32[16,64]{1,0} %slice.231.7), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.259/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.383.7 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.230.7, f32[16,8,64]{2,1,0} %broadcast.380.12), metadata={op_type="aten__mul" op_name="aten__mul.259/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.232.7 = f32[16,8,64]{2,1,0} slice(f32[16,8,128]{2,1,0} %multiply.382.14), slice={[0:16], [0:8], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.233.7 = f32[16,64]{1,0} slice(f32[16,128]{1,0} %convert.906.17), slice={[0:16], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.381.8 = f32[16,8,64]{2,1,0} broadcast(f32[16,64]{1,0} %slice.233.7), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.260/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.385.5 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.232.7, f32[16,8,64]{2,1,0} %broadcast.381.8), metadata={op_type="aten__mul" op_name="aten__mul.260/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %subtract.2.5 = f32[16,8,64]{2,1,0} subtract(f32[16,8,64]{2,1,0} %multiply.383.7, f32[16,8,64]{2,1,0} %multiply.385.5), metadata={op_type="aten__sub" op_name="aten__sub.261/aten__sub" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.907.3 = bf16[16,8,64]{2,1,0} convert(f32[16,8,64]{2,1,0} %subtract.2.5)
  %multiply.386.7 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.232.7, f32[16,8,64]{2,1,0} %broadcast.380.12), metadata={op_type="aten__mul" op_name="aten__mul.262/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.387.5 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.230.7, f32[16,8,64]{2,1,0} %broadcast.381.8), metadata={op_type="aten__mul" op_name="aten__mul.263/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.235.5 = f32[16,8,64]{2,1,0} add(f32[16,8,64]{2,1,0} %multiply.386.7, f32[16,8,64]{2,1,0} %multiply.387.5), metadata={op_type="aten__add" op_name="aten__add.264/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.910.3 = bf16[16,8,64]{2,1,0} convert(f32[16,8,64]{2,1,0} %add.235.5)
  ROOT %concatenate.32.1 = bf16[16,8,128]{2,1,0} concatenate(bf16[16,8,64]{2,1,0} %convert.907.3, bf16[16,8,64]{2,1,0} %convert.910.3), dimensions={2}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_slice (param_0.1: bf16[2,4233,16,8,128]) -> bf16[69353472] {
  %param_0.1 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  %bitcast.3006.1 = bf16[138706944]{0} bitcast(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.1)
  ROOT %slice.236.1 = bf16[69353472]{0} slice(bf16[138706944]{0} %bitcast.3006.1), slice={[69353472:138706944]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%wrapped_slice_computation.1 (param_0.659: bf16[2,4233,16,8,128]) -> bf16[1,4233,16,8,128] {
  %param_0.659 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  ROOT %slice.235.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} slice(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.659), slice={[0:1], [0:4233], [0:16], [0:8], [0:128]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%command_buffer (p: bf16[151936,1024], p.1: s32[16], p.2: bf16[1024,2048], p.3: bf16[1024,2048], p.4: bf16[1024,2048], p.5: bf16[1024,2048], p.6: bf16[1024,2048], p.7: bf16[1024,2048], p.8: bf16[1024,2048], p.9: bf16[1024,2048], p.10: bf16[1024,2048], p.11: bf16[1024,2048], p.12: bf16[1024,2048], p.13: bf16[1024,2048], p.14: bf16[1024,2048], p.15: bf16[1024,2048], p.16: f32[], p.17: bf16[1024], p.18: bf16[6144,1024], p.19: bf16[1024,3072], p.20: bf16[1024], p.21: bf16[6144,1024], p.22: bf16[1024,3072], p.23: bf16[1024], p.24: bf16[6144,1024], p.25: bf16[1024,3072], p.26: bf16[1024], p.27: bf16[6144,1024], p.28: bf16[1024,3072], p.29: bf16[1024], p.30: bf16[6144,1024], p.31: bf16[1024,3072], p.32: bf16[1024], p.33: bf16[6144,1024], p.34: bf16[1024,3072], p.35: bf16[1024], p.36: bf16[6144,1024], p.37: bf16[1024,3072], p.38: bf16[1024], p.39: bf16[6144,1024], p.40: bf16[1024,3072], p.41: bf16[1024], p.42: bf16[6144,1024], p.43: bf16[1024,3072], p.44: bf16[1024], p.45: bf16[6144,1024], p.46: bf16[1024,3072], p.47: bf16[1024], p.48: bf16[6144,1024], p.49: bf16[1024,3072], p.50: bf16[1024], p.51: bf16[6144,1024], p.52: bf16[1024,3072], p.53: bf16[1024], p.54: bf16[6144,1024], p.55: bf16[1024,3072], p.56: bf16[1024], p.57: bf16[6144,1024], p.58: bf16[1024,3072], p.59: bf16[1024], p.60: bf16[4096,1024], p.61: bf16[128], p.62: bf16[40960,128], p.63: s32[16], p.64: bf16[2,4233,16,8,128]) -> (bf16[16,8,128], bf16[16,8,128], bf16[4233,16,8,128], bf16[1,4233,16,8,128]) {
  %p = bf16[151936,1024]{1,0} parameter(0)
  %p.1 = s32[16]{0} parameter(1)
  %p.2 = bf16[1024,2048]{1,0} parameter(2)
  %p.3 = bf16[1024,2048]{1,0} parameter(3)
  %p.4 = bf16[1024,2048]{1,0} parameter(4)
  %p.5 = bf16[1024,2048]{1,0} parameter(5)
  %p.6 = bf16[1024,2048]{1,0} parameter(6)
  %p.7 = bf16[1024,2048]{1,0} parameter(7)
  %p.8 = bf16[1024,2048]{1,0} parameter(8)
  %p.9 = bf16[1024,2048]{1,0} parameter(9)
  %p.10 = bf16[1024,2048]{1,0} parameter(10)
  %p.11 = bf16[1024,2048]{1,0} parameter(11)
  %p.12 = bf16[1024,2048]{1,0} parameter(12)
  %p.13 = bf16[1024,2048]{1,0} parameter(13)
  %p.14 = bf16[1024,2048]{1,0} parameter(14)
  %p.15 = bf16[1024,2048]{1,0} parameter(15)
  %p.16 = f32[] parameter(16)
  %p.17 = bf16[1024]{0} parameter(17)
  %p.18 = bf16[6144,1024]{1,0} parameter(18)
  %p.19 = bf16[1024,3072]{1,0} parameter(19)
  %p.20 = bf16[1024]{0} parameter(20)
  %p.21 = bf16[6144,1024]{1,0} parameter(21)
  %p.22 = bf16[1024,3072]{1,0} parameter(22)
  %p.23 = bf16[1024]{0} parameter(23)
  %p.24 = bf16[6144,1024]{1,0} parameter(24)
  %p.25 = bf16[1024,3072]{1,0} parameter(25)
  %p.26 = bf16[1024]{0} parameter(26)
  %p.27 = bf16[6144,1024]{1,0} parameter(27)
  %p.28 = bf16[1024,3072]{1,0} parameter(28)
  %p.29 = bf16[1024]{0} parameter(29)
  %p.30 = bf16[6144,1024]{1,0} parameter(30)
  %p.31 = bf16[1024,3072]{1,0} parameter(31)
  %p.32 = bf16[1024]{0} parameter(32)
  %p.33 = bf16[6144,1024]{1,0} parameter(33)
  %p.34 = bf16[1024,3072]{1,0} parameter(34)
  %p.35 = bf16[1024]{0} parameter(35)
  %p.36 = bf16[6144,1024]{1,0} parameter(36)
  %p.37 = bf16[1024,3072]{1,0} parameter(37)
  %p.38 = bf16[1024]{0} parameter(38)
  %p.39 = bf16[6144,1024]{1,0} parameter(39)
  %p.40 = bf16[1024,3072]{1,0} parameter(40)
  %p.41 = bf16[1024]{0} parameter(41)
  %p.42 = bf16[6144,1024]{1,0} parameter(42)
  %p.43 = bf16[1024,3072]{1,0} parameter(43)
  %p.44 = bf16[1024]{0} parameter(44)
  %p.45 = bf16[6144,1024]{1,0} parameter(45)
  %p.46 = bf16[1024,3072]{1,0} parameter(46)
  %p.47 = bf16[1024]{0} parameter(47)
  %p.48 = bf16[6144,1024]{1,0} parameter(48)
  %p.49 = bf16[1024,3072]{1,0} parameter(49)
  %p.50 = bf16[1024]{0} parameter(50)
  %p.51 = bf16[6144,1024]{1,0} parameter(51)
  %p.52 = bf16[1024,3072]{1,0} parameter(52)
  %p.53 = bf16[1024]{0} parameter(53)
  %p.54 = bf16[6144,1024]{1,0} parameter(54)
  %p.55 = bf16[1024,3072]{1,0} parameter(55)
  %p.56 = bf16[1024]{0} parameter(56)
  %p.57 = bf16[6144,1024]{1,0} parameter(57)
  %p.58 = bf16[1024,3072]{1,0} parameter(58)
  %p.59 = bf16[1024]{0} parameter(59)
  %p.60 = bf16[4096,1024]{1,0} parameter(60)
  %p.61 = bf16[128]{0} parameter(61)
  %p.62 = bf16[40960,128]{1,0} parameter(62)
  %p.63 = s32[16]{0} parameter(63)
  %p.64 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(64)
  %loop_gather_fusion = bf16[16,1,1024]{2,0,1} fusion(bf16[151936,1024]{1,0} %p, s32[16]{0} %p.1), kind=kLoop, calls=%fused_gather, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_concatenate = bf16[14336,2048]{1,0} fusion(bf16[1024,2048]{1,0} %p.2, bf16[1024,2048]{1,0} %p.3, bf16[1024,2048]{1,0} %p.4, bf16[1024,2048]{1,0} %p.5, bf16[1024,2048]{1,0} %p.6, /*index=5*/bf16[1024,2048]{1,0} %p.7, bf16[1024,2048]{1,0} %p.8, bf16[1024,2048]{1,0} %p.9, bf16[1024,2048]{1,0} %p.10, bf16[1024,2048]{1,0} %p.11, /*index=10*/bf16[1024,2048]{1,0} %p.12, bf16[1024,2048]{1,0} %p.13, bf16[1024,2048]{1,0} %p.14, bf16[1024,2048]{1,0} %p.15), kind=kLoop, calls=%wrapped_concatenate_computation, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %gemm_fusion_dot.56.0 = bf16[16,14336]{1,0} fusion(bf16[14336,2048]{1,0} %wrapped_concatenate), kind=kCustom, calls=%gemm_fusion_dot.56_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton_gemm","triton_gemm_config":{"block_m":"64","block_n":"16","block_k":"128","split_k":"1","num_stages":"4","num_warps":"4","num_ctas":"1"}},"force_earliest_schedule":false}
  %fusion.194 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[1024]{0} %p.17), kind=kCustom, calls=%fused_computation.161, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","256"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.29.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.194, bf16[6144,1024]{1,0} %p.18), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.29 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.29.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.13 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.29), kind=kLoop, calls=%fused_convert.13, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.30.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.13, bf16[1024,3072]{1,0} %p.19), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.1.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.30.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.192 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.20, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.159, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.31.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.192, bf16[6144,1024]{1,0} %p.21), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.2.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.31.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.12 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.2.0), kind=kLoop, calls=%fused_convert.12, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.32.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.12, bf16[1024,3072]{1,0} %p.22), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.3.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.32.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.190 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.23, bf16[16,1024]{1,0} %get-tuple-element.3.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.157, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.33.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.190, bf16[6144,1024]{1,0} %p.24), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.4.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.33.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.11 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.4.0), kind=kLoop, calls=%fused_convert.11, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.34.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.11, bf16[1024,3072]{1,0} %p.25), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.5.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.34.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_add_fusion = f32[16,1024]{1,0} fusion(bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[16,1024]{1,0} %get-tuple-element.5.0, bf16[16,1024]{1,0} %get-tuple-element.3.0, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kLoop, calls=%fused_add, metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.188 = bf16[16,1024]{1,0} fusion(f32[16,1024]{1,0} %loop_add_fusion, f32[] %p.16, bf16[1024]{0} %p.26), kind=kCustom, calls=%fused_computation.155, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="fusion.172"}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","128"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.35.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.188, bf16[6144,1024]{1,0} %p.27), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.6.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.35.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.10 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.6.0), kind=kLoop, calls=%fused_convert.10, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.36.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.10, bf16[1024,3072]{1,0} %p.28), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.7.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.36.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.186 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.29, f32[16,1024]{1,0} %loop_add_fusion, bf16[16,1024]{1,0} %get-tuple-element.7.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0), kind=kCustom, calls=%fused_computation.153, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.37.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.186, bf16[6144,1024]{1,0} %p.30), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.8.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.37.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.9 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.8.0), kind=kLoop, calls=%fused_convert.9, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.38.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.9, bf16[1024,3072]{1,0} %p.31), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.9.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.38.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.184 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.32, f32[16,1024]{1,0} %loop_add_fusion, bf16[16,1024]{1,0} %get-tuple-element.7.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.9.0), kind=kCustom, calls=%fused_computation.151, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.39.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.184, bf16[6144,1024]{1,0} %p.33), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.10.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.39.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.8 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.10.0), kind=kLoop, calls=%fused_convert.8, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.40.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.8, bf16[1024,3072]{1,0} %p.34), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.11.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.40.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.182 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.35, bf16[16,1024]{1,0} %get-tuple-element.11.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, f32[16,1024]{1,0} %loop_add_fusion, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.7.0, bf16[16,1024]{1,0} %get-tuple-element.9.0), kind=kCustom, calls=%fused_computation.149, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.41.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.182, bf16[6144,1024]{1,0} %p.36), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.12.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.41.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.7 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.12.0), kind=kLoop, calls=%fused_convert.7, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.42.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.7, bf16[1024,3072]{1,0} %p.37), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.13.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.42.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_add_fusion.1 = f32[16,1024]{1,0} fusion(bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[16,1024]{1,0} %get-tuple-element.13.0, bf16[16,1024]{1,0} %get-tuple-element.11.0, f32[16,1024]{1,0} %loop_add_fusion, bf16[16,1024]{1,0} %get-tuple-element.7.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.9.0), kind=kLoop, calls=%fused_add.1, metadata={op_type="aten__add" op_name="aten__add.139/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.180 = bf16[16,1024]{1,0} fusion(f32[16,1024]{1,0} %loop_add_fusion.1, f32[] %p.16, bf16[1024]{0} %p.38), kind=kCustom, calls=%fused_computation.147, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="fusion.172"}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","128"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.43.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.180, bf16[6144,1024]{1,0} %p.39), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.14.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.43.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.6 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.14.0), kind=kLoop, calls=%fused_convert.6, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.44.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.6, bf16[1024,3072]{1,0} %p.40), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.15.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.44.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.178 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.41, f32[16,1024]{1,0} %loop_add_fusion.1, bf16[16,1024]{1,0} %get-tuple-element.15.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0), kind=kCustom, calls=%fused_computation.145, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.45.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.178, bf16[6144,1024]{1,0} %p.42), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.16.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.45.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.5 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.16.0), kind=kLoop, calls=%fused_convert.5, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.46.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.5, bf16[1024,3072]{1,0} %p.43), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.17.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.46.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.176 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.44, f32[16,1024]{1,0} %loop_add_fusion.1, bf16[16,1024]{1,0} %get-tuple-element.15.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.17.0), kind=kCustom, calls=%fused_computation.143, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.47.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.176, bf16[6144,1024]{1,0} %p.45), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.18.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.47.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.4 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.18.0), kind=kLoop, calls=%fused_convert.4, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.48.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.4, bf16[1024,3072]{1,0} %p.46), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.19.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.48.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.174 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.47, bf16[16,1024]{1,0} %get-tuple-element.19.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, f32[16,1024]{1,0} %loop_add_fusion.1, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.15.0, bf16[16,1024]{1,0} %get-tuple-element.17.0), kind=kCustom, calls=%fused_computation.141, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.49.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.174, bf16[6144,1024]{1,0} %p.48), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.20.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.49.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.3 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.20.0), kind=kLoop, calls=%fused_convert.3, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.50.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.3, bf16[1024,3072]{1,0} %p.49), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.21.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.50.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_add_fusion.2 = f32[16,1024]{1,0} fusion(bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[16,1024]{1,0} %get-tuple-element.21.0, bf16[16,1024]{1,0} %get-tuple-element.19.0, f32[16,1024]{1,0} %loop_add_fusion.1, bf16[16,1024]{1,0} %get-tuple-element.15.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.17.0), kind=kLoop, calls=%fused_add.2, metadata={op_type="aten__add" op_name="aten__add.211/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.172 = bf16[16,1024]{1,0} fusion(f32[16,1024]{1,0} %loop_add_fusion.2, f32[] %p.16, bf16[1024]{0} %p.50), kind=kCustom, calls=%fused_computation.139, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="fusion.172"}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","128"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.51.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.172, bf16[6144,1024]{1,0} %p.51), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.22.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.51.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.2 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.22.0), kind=kLoop, calls=%fused_convert.2, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.52.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.2, bf16[1024,3072]{1,0} %p.52), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.23.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.52.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.170 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.53, f32[16,1024]{1,0} %loop_add_fusion.2, bf16[16,1024]{1,0} %get-tuple-element.23.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0), kind=kCustom, calls=%fused_computation.137, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.53.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.170, bf16[6144,1024]{1,0} %p.54), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.24.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.53.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.1 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.24.0), kind=kLoop, calls=%fused_convert.1, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.54.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.1, bf16[1024,3072]{1,0} %p.55), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.25.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.54.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.168 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[1024]{0} %p.56, f32[16,1024]{1,0} %loop_add_fusion.2, bf16[16,1024]{1,0} %get-tuple-element.23.0, bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.25.0), kind=kCustom, calls=%fused_computation.135, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.55.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.168, bf16[6144,1024]{1,0} %p.57), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.26.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.55.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.26.0), kind=kLoop, calls=%fused_convert, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.56.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion, bf16[1024,3072]{1,0} %p.58), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.27.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.56.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.166 = bf16[16,1024]{1,0} fusion(f32[] %p.16, bf16[16,1024]{1,0} %get-tuple-element.27.0, bf16[1024]{0} %p.59, f32[16,1024]{1,0} %loop_add_fusion.2, bf16[16,1024]{1,0} %get-tuple-element.23.0, /*index=5*/bf16[16,14336]{1,0} %gemm_fusion_dot.56.0, bf16[16,1024]{1,0} %get-tuple-element.25.0), kind=kCustom, calls=%fused_computation.133, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.57.0 = (bf16[16,4096]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.166, bf16[4096,1024]{1,0} %p.60), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"4194304","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.28.0 = bf16[16,4096]{1,0} get-tuple-element((bf16[16,4096]{1,0}, s8[4194304]{0}) %custom-call.57.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_slice = bf16[16,1024]{1,0} fusion(bf16[16,4096]{1,0} %get-tuple-element.28.0), kind=kLoop, calls=%wrapped_slice_computation, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %triton_softmax.16.0 = f32[16,8,128]{2,1,0} fusion(f32[] %p.16, bf16[16,4096]{1,0} %get-tuple-element.28.0), kind=kCustom, calls=%triton_softmax_computation.16, metadata={op_type="aten__mul" op_name="aten__mul.257/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1","128"]}],"num_warps":"1"}},"force_earliest_schedule":false}
  %input_concatenate_fusion = bf16[16,8,128]{2,1,0} fusion(f32[16,8,128]{2,1,0} %triton_softmax.16.0, bf16[128]{0} %p.61, bf16[40960,128]{1,0} %p.62, s32[16]{0} %p.63), kind=kInput, calls=%fused_concatenate, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.2998.0 = bf16[16,8,128]{2,1,0} bitcast(bf16[16,1024]{1,0} %wrapped_slice)
  %loop_slice_fusion = bf16[69353472]{0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.64), kind=kLoop, calls=%fused_slice, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  %bitcast.3010.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[69353472]{0} %loop_slice_fusion)
  %wrapped_slice.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.64), kind=kLoop, calls=%wrapped_slice_computation.1, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  ROOT %tuple = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) tuple(bf16[16,8,128]{2,1,0} %input_concatenate_fusion, bf16[16,8,128]{2,1,0} %bitcast.2998.0, bf16[4233,16,8,128]{3,2,1,0} %bitcast.3010.0, bf16[1,4233,16,8,128]{4,3,2,1,0} %wrapped_slice.1)
}

ENTRY %SyncTensorsGraph.1181 (p0.1.0: bf16[128], p1.4.0: f32[], p2.6.0: bf16[4096,1024], p3.8.0: bf16[1024], p4.40.0: s32[16], p5.42.0: bf16[151936,1024], p6.46.0: bf16[1024,2048], p7.62.0: bf16[1024,3072], p8.64.0: bf16[6144,1024], p9.66.0: bf16[1024], p10.118.0: bf16[1024,2048], p11.134.0: bf16[1024,3072], p12.136.0: bf16[6144,1024], p13.138.0: bf16[1024], p14.190.0: bf16[1024,2048], p15.206.0: bf16[1024,3072], p16.208.0: bf16[6144,1024], p17.210.0: bf16[1024], p18.262.0: bf16[1024,2048], p19.278.0: bf16[1024,3072], p20.280.0: bf16[6144,1024], p21.282.0: bf16[1024], p22.334.0: bf16[1024,2048], p23.350.0: bf16[1024,3072], p24.352.0: bf16[6144,1024], p25.354.0: bf16[1024], p26.406.0: bf16[1024,2048], p27.422.0: bf16[1024,3072], p28.424.0: bf16[6144,1024], p29.426.0: bf16[1024], p30.478.0: bf16[1024,2048], p31.494.0: bf16[1024,3072], p32.496.0: bf16[6144,1024], p33.498.0: bf16[1024], p34.550.0: bf16[1024,2048], p35.566.0: bf16[1024,3072], p36.568.0: bf16[6144,1024], p37.570.0: bf16[1024], p38.622.0: bf16[1024,2048], p39.638.0: bf16[1024,3072], p40.640.0: bf16[6144,1024], p41.642.0: bf16[1024], p42.694.0: bf16[1024,2048], p43.710.0: bf16[1024,3072], p44.712.0: bf16[6144,1024], p45.714.0: bf16[1024], p46.766.0: bf16[1024,2048], p47.782.0: bf16[1024,3072], p48.784.0: bf16[6144,1024], p49.786.0: bf16[1024], p50.838.0: bf16[1024,2048], p51.854.0: bf16[1024,3072], p52.856.0: bf16[6144,1024], p53.858.0: bf16[1024], p54.910.0: bf16[1024,2048], p55.926.0: bf16[1024,3072], p56.928.0: bf16[6144,1024], p57.930.0: bf16[1024], p58.982.0: bf16[1024,2048], p59.998.0: bf16[1024,3072], p60.1000.0: bf16[6144,1024], p61.1002.0: bf16[1024], p62.1126.0: s32[16], p63.1127.0: bf16[40960,128], p64.1171.0: bf16[2,4233,16,8,128]) -> (bf16[16,8,128], bf16[16,8,128], bf16[4233,16,8,128], bf16[4233,16,8,128]) {
  %p1.4.0 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %p64.1171.0 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(64), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p63.1127.0 = bf16[40960,128]{1,0} parameter(63), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p62.1126.0 = s32[16]{0} parameter(62), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p61.1002.0 = bf16[1024]{0} parameter(61), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p60.1000.0 = bf16[6144,1024]{1,0} parameter(60), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p59.998.0 = bf16[1024,3072]{1,0} parameter(59), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p58.982.0 = bf16[1024,2048]{1,0} parameter(58), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p57.930.0 = bf16[1024]{0} parameter(57), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p56.928.0 = bf16[6144,1024]{1,0} parameter(56), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p55.926.0 = bf16[1024,3072]{1,0} parameter(55), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p54.910.0 = bf16[1024,2048]{1,0} parameter(54), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p53.858.0 = bf16[1024]{0} parameter(53), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p52.856.0 = bf16[6144,1024]{1,0} parameter(52), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p51.854.0 = bf16[1024,3072]{1,0} parameter(51), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p50.838.0 = bf16[1024,2048]{1,0} parameter(50), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p49.786.0 = bf16[1024]{0} parameter(49), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p48.784.0 = bf16[6144,1024]{1,0} parameter(48), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p47.782.0 = bf16[1024,3072]{1,0} parameter(47), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p46.766.0 = bf16[1024,2048]{1,0} parameter(46), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p45.714.0 = bf16[1024]{0} parameter(45), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p44.712.0 = bf16[6144,1024]{1,0} parameter(44), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p43.710.0 = bf16[1024,3072]{1,0} parameter(43), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p42.694.0 = bf16[1024,2048]{1,0} parameter(42), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p41.642.0 = bf16[1024]{0} parameter(41), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p40.640.0 = bf16[6144,1024]{1,0} parameter(40), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p39.638.0 = bf16[1024,3072]{1,0} parameter(39), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p38.622.0 = bf16[1024,2048]{1,0} parameter(38), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p37.570.0 = bf16[1024]{0} parameter(37), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p36.568.0 = bf16[6144,1024]{1,0} parameter(36), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p35.566.0 = bf16[1024,3072]{1,0} parameter(35), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p34.550.0 = bf16[1024,2048]{1,0} parameter(34), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p33.498.0 = bf16[1024]{0} parameter(33), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p32.496.0 = bf16[6144,1024]{1,0} parameter(32), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p31.494.0 = bf16[1024,3072]{1,0} parameter(31), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p30.478.0 = bf16[1024,2048]{1,0} parameter(30), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p29.426.0 = bf16[1024]{0} parameter(29), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p28.424.0 = bf16[6144,1024]{1,0} parameter(28), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p27.422.0 = bf16[1024,3072]{1,0} parameter(27), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p26.406.0 = bf16[1024,2048]{1,0} parameter(26), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p25.354.0 = bf16[1024]{0} parameter(25), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p24.352.0 = bf16[6144,1024]{1,0} parameter(24), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p23.350.0 = bf16[1024,3072]{1,0} parameter(23), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p22.334.0 = bf16[1024,2048]{1,0} parameter(22), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p21.282.0 = bf16[1024]{0} parameter(21), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p20.280.0 = bf16[6144,1024]{1,0} parameter(20), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p19.278.0 = bf16[1024,3072]{1,0} parameter(19), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p18.262.0 = bf16[1024,2048]{1,0} parameter(18), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p17.210.0 = bf16[1024]{0} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p16.208.0 = bf16[6144,1024]{1,0} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p15.206.0 = bf16[1024,3072]{1,0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p14.190.0 = bf16[1024,2048]{1,0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p13.138.0 = bf16[1024]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p12.136.0 = bf16[6144,1024]{1,0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p11.134.0 = bf16[1024,3072]{1,0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p10.118.0 = bf16[1024,2048]{1,0} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p9.66.0 = bf16[1024]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p8.64.0 = bf16[6144,1024]{1,0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p7.62.0 = bf16[1024,3072]{1,0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p6.46.0 = bf16[1024,2048]{1,0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p5.42.0 = bf16[151936,1024]{1,0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p4.40.0 = s32[16]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p3.8.0 = bf16[1024]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p2.6.0 = bf16[4096,1024]{1,0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p0.1.0 = bf16[128]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %call = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) call(bf16[151936,1024]{1,0} %p5.42.0, s32[16]{0} %p4.40.0, bf16[1024,2048]{1,0} %p58.982.0, bf16[1024,2048]{1,0} %p54.910.0, bf16[1024,2048]{1,0} %p50.838.0, /*index=5*/bf16[1024,2048]{1,0} %p46.766.0, bf16[1024,2048]{1,0} %p42.694.0, bf16[1024,2048]{1,0} %p38.622.0, bf16[1024,2048]{1,0} %p34.550.0, bf16[1024,2048]{1,0} %p30.478.0, /*index=10*/bf16[1024,2048]{1,0} %p26.406.0, bf16[1024,2048]{1,0} %p22.334.0, bf16[1024,2048]{1,0} %p18.262.0, bf16[1024,2048]{1,0} %p14.190.0, bf16[1024,2048]{1,0} %p10.118.0, /*index=15*/bf16[1024,2048]{1,0} %p6.46.0, f32[] %p1.4.0, bf16[1024]{0} %p9.66.0, bf16[6144,1024]{1,0} %p8.64.0, bf16[1024,3072]{1,0} %p7.62.0, /*index=20*/bf16[1024]{0} %p13.138.0, bf16[6144,1024]{1,0} %p12.136.0, bf16[1024,3072]{1,0} %p11.134.0, bf16[1024]{0} %p17.210.0, bf16[6144,1024]{1,0} %p16.208.0, /*index=25*/bf16[1024,3072]{1,0} %p15.206.0, bf16[1024]{0} %p21.282.0, bf16[6144,1024]{1,0} %p20.280.0, bf16[1024,3072]{1,0} %p19.278.0, bf16[1024]{0} %p25.354.0, /*index=30*/bf16[6144,1024]{1,0} %p24.352.0, bf16[1024,3072]{1,0} %p23.350.0, bf16[1024]{0} %p29.426.0, bf16[6144,1024]{1,0} %p28.424.0, bf16[1024,3072]{1,0} %p27.422.0, /*index=35*/bf16[1024]{0} %p33.498.0, bf16[6144,1024]{1,0} %p32.496.0, bf16[1024,3072]{1,0} %p31.494.0, bf16[1024]{0} %p37.570.0, bf16[6144,1024]{1,0} %p36.568.0, /*index=40*/bf16[1024,3072]{1,0} %p35.566.0, bf16[1024]{0} %p41.642.0, bf16[6144,1024]{1,0} %p40.640.0, bf16[1024,3072]{1,0} %p39.638.0, bf16[1024]{0} %p45.714.0, /*index=45*/bf16[6144,1024]{1,0} %p44.712.0, bf16[1024,3072]{1,0} %p43.710.0, bf16[1024]{0} %p49.786.0, bf16[6144,1024]{1,0} %p48.784.0, bf16[1024,3072]{1,0} %p47.782.0, /*index=50*/bf16[1024]{0} %p53.858.0, bf16[6144,1024]{1,0} %p52.856.0, bf16[1024,3072]{1,0} %p51.854.0, bf16[1024]{0} %p57.930.0, bf16[6144,1024]{1,0} %p56.928.0, /*index=55*/bf16[1024,3072]{1,0} %p55.926.0, bf16[1024]{0} %p61.1002.0, bf16[6144,1024]{1,0} %p60.1000.0, bf16[1024,3072]{1,0} %p59.998.0, bf16[1024]{0} %p3.8.0, /*index=60*/bf16[4096,1024]{1,0} %p2.6.0, bf16[128]{0} %p0.1.0, bf16[40960,128]{1,0} %p63.1127.0, s32[16]{0} %p62.1126.0, bf16[2,4233,16,8,128]{4,3,2,1,0} %p64.1171.0), to_apply=%command_buffer
  %get-tuple-element.31 = bf16[16,8,128]{2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=0
  %get-tuple-element.32 = bf16[16,8,128]{2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=1
  %get-tuple-element.33 = bf16[4233,16,8,128]{3,2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=2
  %get-tuple-element.34 = bf16[1,4233,16,8,128]{4,3,2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=3
  %bitcast.3003.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[1,4233,16,8,128]{4,3,2,1,0} %get-tuple-element.34)
  ROOT %tuple.1180.0 = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0}) tuple(bf16[16,8,128]{2,1,0} %get-tuple-element.31, bf16[16,8,128]{2,1,0} %get-tuple-element.32, bf16[4233,16,8,128]{3,2,1,0} %bitcast.3003.0, bf16[4233,16,8,128]{3,2,1,0} %get-tuple-element.33)
}

