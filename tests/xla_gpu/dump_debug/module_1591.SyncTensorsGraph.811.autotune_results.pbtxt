version: 3
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[1024,2048]{1,0} parameter(2)\n  tmp_3 = bf16[1024,2048]{1,0} parameter(3)\n  tmp_4 = bf16[4096,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1, bf16[1024,2048]{1,0} tmp_2, bf16[1024,2048]{1,0} tmp_3), dimensions={0}\n  tmp_5 = bf16[] constant(0)\n  tmp_6 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_5), dimensions={}\n  tmp_7 = bf16[4096,16]{0,1} dot(bf16[4096,2048]{1,0} tmp_4, bf16[16,2048]{1,0} tmp_6), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_8 = bf16[16,4096]{1,0} bitcast(bf16[4096,16]{0,1} tmp_7)\n}"
  result {
    run_time {
      nanos: 29696
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[1024,2048]{1,0} parameter(2)\n  tmp_3 = bf16[1024,2048]{1,0} parameter(3)\n  tmp_4 = bf16[4096,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1, bf16[1024,2048]{1,0} tmp_2, bf16[1024,2048]{1,0} tmp_3), dimensions={0}\n  tmp_5 = bf16[] constant(0)\n  tmp_6 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_5), dimensions={}\n  tmp_7 = bf16[4096,32]{0,1} dot(bf16[4096,2048]{1,0} tmp_4, bf16[32,2048]{1,0} tmp_6), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_8 = bf16[32,4096]{1,0} bitcast(bf16[4096,32]{0,1} tmp_7)\n}"
  result {
    run_time {
      nanos: 34816
    }
    triton {
      block_m: 64
      block_n: 32
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[1024,2048]{1,0} parameter(2)\n  tmp_3 = bf16[3072,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1, bf16[1024,2048]{1,0} tmp_2), dimensions={0}\n  tmp_4 = bf16[] constant(0)\n  tmp_5 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_4), dimensions={}\n  tmp_6 = bf16[3072,16]{0,1} dot(bf16[3072,2048]{1,0} tmp_3, bf16[16,2048]{1,0} tmp_5), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_7 = bf16[16,3072]{1,0} bitcast(bf16[3072,16]{0,1} tmp_6)\n}"
  result {
    run_time {
      nanos: 30720
    }
    triton {
      block_m: 64
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[1024,2048]{1,0} parameter(2)\n  tmp_3 = bf16[3072,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1, bf16[1024,2048]{1,0} tmp_2), dimensions={0}\n  tmp_4 = bf16[] constant(0)\n  tmp_5 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_4), dimensions={}\n  tmp_6 = bf16[3072,32]{0,1} dot(bf16[3072,2048]{1,0} tmp_3, bf16[32,2048]{1,0} tmp_5), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_7 = bf16[32,3072]{1,0} bitcast(bf16[3072,32]{0,1} tmp_6)\n}"
  result {
    run_time {
      nanos: 33792
    }
    triton {
      block_m: 64
      block_n: 32
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[2048,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1), dimensions={0}\n  tmp_3 = bf16[] constant(0)\n  tmp_4 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_3), dimensions={}\n  tmp_5 = bf16[2048,16]{0,1} dot(bf16[2048,2048]{1,0} tmp_2, bf16[16,2048]{1,0} tmp_4), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_6 = bf16[16,2048]{1,0} bitcast(bf16[2048,16]{0,1} tmp_5)\n}"
  result {
    run_time {
      nanos: 22528
    }
    triton {
      block_m: 16
      block_n: 16
      block_k: 256
      split_k: 1
      num_stages: 3
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[2048,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1), dimensions={0}\n  tmp_3 = bf16[] constant(0)\n  tmp_4 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_3), dimensions={}\n  tmp_5 = bf16[2048,32]{0,1} dot(bf16[2048,2048]{1,0} tmp_2, bf16[32,2048]{1,0} tmp_4), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_6 = bf16[32,2048]{1,0} bitcast(bf16[2048,32]{0,1} tmp_5)\n}"
  result {
    run_time {
      nanos: 34816
    }
    triton {
      block_m: 32
      block_n: 32
      block_k: 256
      split_k: 1
      num_stages: 1
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[1024,16]{0,1} dot(bf16[1024,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,1024]{1,0} bitcast(bf16[1024,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 32768
    }
    triton {
      block_m: 16
      block_n: 16
      block_k: 256
      split_k: 1
      num_stages: 3
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[1024,32]{0,1} dot(bf16[1024,2048]{1,0} tmp_0, bf16[32,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[32,1024]{1,0} bitcast(bf16[1024,32]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 22528
    }
    triton {
      block_m: 32
      block_n: 16
      block_k: 512
      split_k: 1
      num_stages: 1
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[10240,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[10240,16]{0,1} dot(bf16[10240,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,10240]{1,0} bitcast(bf16[10240,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 54272
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[11264,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[11264,16]{0,1} dot(bf16[11264,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,11264]{1,0} bitcast(bf16[11264,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 54272
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[12288,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[12288,16]{0,1} dot(bf16[12288,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,12288]{1,0} bitcast(bf16[12288,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 50176
    }
    triton {
      block_m: 32
      block_n: 16
      block_k: 256
      split_k: 1
      num_stages: 1
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[13312,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[13312,16]{0,1} dot(bf16[13312,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,13312]{1,0} bitcast(bf16[13312,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 59392
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[14336,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[14336,16]{0,1} dot(bf16[14336,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,14336]{1,0} bitcast(bf16[14336,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 60416
    }
    triton {
      block_m: 64
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[15360,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[15360,16]{0,1} dot(bf16[15360,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,15360]{1,0} bitcast(bf16[15360,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 63488
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[16384,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[16384,16]{0,1} dot(bf16[16384,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,16384]{1,0} bitcast(bf16[16384,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 64512
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[17408,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[17408,16]{0,1} dot(bf16[17408,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,17408]{1,0} bitcast(bf16[17408,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 67584
    }
    triton {
      block_m: 64
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[18432,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[18432,16]{0,1} dot(bf16[18432,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,18432]{1,0} bitcast(bf16[18432,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 67584
    }
    triton {
      block_m: 64
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[19456,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[19456,16]{0,1} dot(bf16[19456,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,19456]{1,0} bitcast(bf16[19456,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 70656
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[20480,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[20480,16]{0,1} dot(bf16[20480,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,20480]{1,0} bitcast(bf16[20480,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 72704
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[21504,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[21504,16]{0,1} dot(bf16[21504,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,21504]{1,0} bitcast(bf16[21504,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 74752
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[22528,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[22528,16]{0,1} dot(bf16[22528,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,22528]{1,0} bitcast(bf16[22528,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 69632
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[23552,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[23552,16]{0,1} dot(bf16[23552,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,23552]{1,0} bitcast(bf16[23552,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 78848
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[24576,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[24576,16]{0,1} dot(bf16[24576,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,24576]{1,0} bitcast(bf16[24576,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 77824
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[25600,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[25600,16]{0,1} dot(bf16[25600,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,25600]{1,0} bitcast(bf16[25600,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 81920
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[26624,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[26624,16]{0,1} dot(bf16[26624,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,26624]{1,0} bitcast(bf16[26624,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 82944
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[27648,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[27648,16]{0,1} dot(bf16[27648,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,27648]{1,0} bitcast(bf16[27648,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 90112
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[28672,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[28672,16]{0,1} dot(bf16[28672,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,28672]{1,0} bitcast(bf16[28672,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 94208
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[5120,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[5120,16]{0,1} dot(bf16[5120,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,5120]{1,0} bitcast(bf16[5120,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 32768
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[5120,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[5120,32]{0,1} dot(bf16[5120,2048]{1,0} tmp_0, bf16[32,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[32,5120]{1,0} bitcast(bf16[5120,32]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 39936
    }
    triton {
      block_m: 16
      block_n: 32
      block_k: 256
      split_k: 1
      num_stages: 1
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[6144,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[6144,16]{0,1} dot(bf16[6144,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,6144]{1,0} bitcast(bf16[6144,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 36864
    }
    triton {
      block_m: 64
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[6144,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[6144,32]{0,1} dot(bf16[6144,2048]{1,0} tmp_0, bf16[32,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[32,6144]{1,0} bitcast(bf16[6144,32]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 27648
    }
    triton {
      block_m: 64
      block_n: 32
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[7168,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[7168,16]{0,1} dot(bf16[7168,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,7168]{1,0} bitcast(bf16[7168,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 40960
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[7168,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[7168,32]{0,1} dot(bf16[7168,2048]{1,0} tmp_0, bf16[32,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[32,7168]{1,0} bitcast(bf16[7168,32]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 39936
    }
    triton {
      block_m: 128
      block_n: 32
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[8192,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[8192,16]{0,1} dot(bf16[8192,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,8192]{1,0} bitcast(bf16[8192,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 47104
    }
    triton {
      block_m: 128
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[8192,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[8192,32]{0,1} dot(bf16[8192,2048]{1,0} tmp_0, bf16[32,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[32,8192]{1,0} bitcast(bf16[8192,32]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 47104
    }
    triton {
      block_m: 128
      block_n: 32
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[9216,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[9216,16]{0,1} dot(bf16[9216,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,9216]{1,0} bitcast(bf16[9216,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 51200
    }
    triton {
      block_m: 256
      block_n: 16
      block_k: 128
      split_k: 1
      num_stages: 3
      num_warps: 8
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[9216,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[32,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[9216,32]{0,1} dot(bf16[9216,2048]{1,0} tmp_0, bf16[32,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[32,9216]{1,0} bitcast(bf16[9216,32]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 54272
    }
    triton {
      block_m: 128
      block_n: 32
      block_k: 128
      split_k: 1
      num_stages: 4
      num_warps: 4
      num_ctas: 1
    }
  }
}
