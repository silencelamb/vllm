HloModule SyncTensorsGraph.589, is_scheduled=true, entry_computation_layout={(bf16[128]{0}, f32[], bf16[4096,1024]{1,0}, bf16[1024]{0}, s32[64]{0}, /*index=5*/bf16[151936,1024]{1,0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=10*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=15*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=20*/bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, /*index=25*/bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=30*/s32[64]{0}, bf16[40960,128]{1,0}, bf16[2,4233,16,8,128]{4,3,2,1,0})->(bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0})}, frontend_attributes={fingerprint_before_lhs="89c2f23b72a33e2470cfd27e938a8850"}

%fused_gather (param_0.9: bf16[151936,1024], param_1.245: s32[64]) -> bf16[64,1,1024] {
  %param_0.9 = bf16[151936,1024]{1,0} parameter(0)
  %param_1.245 = s32[64]{0} parameter(1)
  %convert.343.1 = s64[64]{0} convert(s32[64]{0} %param_1.245), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.344.1 = u32[64]{0} convert(s64[64]{0} %convert.343.1), metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1167.1 = u32[64,1]{1,0} bitcast(u32[64]{0} %convert.344.1)
  ROOT %gather.3 = bf16[64,1,1024]{2,0,1} gather(bf16[151936,1024]{1,0} %param_0.9, u32[64,1]{1,0} %bitcast.1167.1), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,1024}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_concatenate_computation (param_0.320: bf16[1024,2048], param_1.262: bf16[1024,2048], param_2.174: bf16[1024,2048], param_3.165: bf16[1024,2048], param_4.99: bf16[1024,2048], param_5.49: bf16[1024,2048]) -> bf16[6144,2048] {
  %param_0.320 = bf16[1024,2048]{1,0} parameter(0)
  %param_1.262 = bf16[1024,2048]{1,0} parameter(1)
  %param_2.174 = bf16[1024,2048]{1,0} parameter(2)
  %param_3.165 = bf16[1024,2048]{1,0} parameter(3)
  %param_4.99 = bf16[1024,2048]{1,0} parameter(4)
  %param_5.49 = bf16[1024,2048]{1,0} parameter(5)
  ROOT %concatenate.15.1 = bf16[6144,2048]{1,0} concatenate(bf16[1024,2048]{1,0} %param_0.320, bf16[1024,2048]{1,0} %param_1.262, bf16[1024,2048]{1,0} %param_2.174, bf16[1024,2048]{1,0} %param_3.165, bf16[1024,2048]{1,0} %param_4.99, /*index=5*/bf16[1024,2048]{1,0} %param_5.49), dimensions={0}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
}

%gemm_fusion_dot.23_computation (parameter_0: bf16[6144,2048]) -> bf16[64,6144] {
  %constant_75 = bf16[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.65 = bf16[64,2048]{1,0} broadcast(bf16[] %constant_75), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %parameter_0 = bf16[6144,2048]{1,0} parameter(0)
  ROOT %dot.24 = bf16[64,6144]{1,0} dot(bf16[64,2048]{1,0} %broadcast.65, bf16[6144,2048]{1,0} %parameter_0), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%AddComputation.58 (x.59: f32[], y.60: f32[]) -> f32[] {
  %y.60 = f32[] parameter(1)
  %x.59 = f32[] parameter(0)
  ROOT %add.89 = f32[] add(f32[] %x.59, f32[] %y.60)
}

%fused_computation.70 (param_0.295: f32[], param_1.242: bf16[64,1,1024], param_2.149: bf16[64,6144], param_3.130: bf16[1024]) -> bf16[64,1024] {
  %param_2.149 = bf16[64,6144]{1,0} parameter(2)
  %convert.342.24 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_2.149), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.9 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.24), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.242 = bf16[64,1,1024]{2,0,1} parameter(1)
  %bitcast.1170.9 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_1.242)
  %convert.345.9 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.9), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.9, f32[64,1024]{1,0} %convert.345.9), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.198 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.90.7, f32[64,1024]{1,0} %add.90.7), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_167 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.17 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.198, f32[] %constant_167), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_166 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.226 = f32[64]{0} broadcast(f32[] %constant_166), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.197 = f32[64]{0} multiply(f32[64]{0} %reduce.17, f32[64]{0} %broadcast.226), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.295 = f32[] parameter(0)
  %broadcast.225 = f32[64]{0} broadcast(f32[] %param_0.295), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.111 = f32[64]{0} add(f32[64]{0} %multiply.197, f32[64]{0} %broadcast.225), metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.41 = f32[64]{0} rsqrt(f32[64]{0} %add.111), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.224 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.41), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1029/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.196 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.90.7, f32[64,1024]{1,0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul.1029/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.130 = bf16[1024]{0} parameter(3)
  %convert.346.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.130), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.167.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.346.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1030/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.167.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.196, f32[64,1024]{1,0} %broadcast.167.1), metadata={op_type="aten__mul" op_name="aten__mul.1030/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.347.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.167.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.5 (param_0.280: bf16[64,6144]) -> bf16[64,3072] {
  %param_0.280 = bf16[64,6144]{1,0} parameter(0)
  %slice.95.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.280), slice={[0:64], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.348.6 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.95.1)
  %constant_1_4 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.2 = f32[] convert(bf16[] %constant_1_4)
  %broadcast.194.48 = f32[64,3072]{1,0} broadcast(f32[] %convert.436.2), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.18.7 = f32[64,3072]{1,0} negate(f32[64,3072]{1,0} %convert.348.6)
  %convert.352.5 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %negate.18.7)
  %exponential.18.3 = bf16[64,3072]{1,0} exponential(bf16[64,3072]{1,0} %convert.352.5)
  %convert.353.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %exponential.18.3)
  %add.91.5 = f32[64,3072]{1,0} add(f32[64,3072]{1,0} %broadcast.194.48, f32[64,3072]{1,0} %convert.353.1)
  %divide.18.3 = f32[64,3072]{1,0} divide(f32[64,3072]{1,0} %broadcast.194.48, f32[64,3072]{1,0} %add.91.5), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.168.3 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %convert.348.6, f32[64,3072]{1,0} %divide.18.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.96.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.280), slice={[0:64], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.355.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.96.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.169.1 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %multiply.168.3, f32[64,3072]{1,0} %convert.355.1), metadata={op_type="aten__mul" op_name="aten__mul.1031/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.356.1 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %multiply.169.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.69 (param_0.311: f32[], param_1.251: bf16[1024], param_2.160: bf16[64,1,1024], param_3.148: bf16[64,6144], param_4.79: bf16[64,1024]) -> bf16[64,1024] {
  %param_3.148 = bf16[64,6144]{1,0} parameter(3)
  %convert.342.44 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_3.148), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.5 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.44), slice={[0:64], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.79 = bf16[64,1024]{1,0} parameter(4)
  %convert.357.3 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_4.79), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.11 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.44), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.160 = bf16[64,1,1024]{2,0,1} parameter(2)
  %bitcast.1170.11 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_2.160)
  %convert.345.11 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.11, f32[64,1024]{1,0} %convert.345.11), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.357.3, f32[64,1024]{1,0} %add.90.9), metadata={op_type="aten__add" op_name="aten__add.1032/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.93.5, f32[64,1024]{1,0} %add.92.3), metadata={op_type="aten__add" op_name="aten__add.1045/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.204 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.93.3, f32[64,1024]{1,0} %add.93.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_172 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.19 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.204, f32[] %constant_172), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_171 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.233 = f32[64]{0} broadcast(f32[] %constant_171), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.203 = f32[64]{0} multiply(f32[64]{0} %reduce.19, f32[64]{0} %broadcast.233), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.311 = f32[] parameter(0)
  %broadcast.232 = f32[64]{0} broadcast(f32[] %param_0.311), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.113 = f32[64]{0} add(f32[64]{0} %multiply.203, f32[64]{0} %broadcast.232), metadata={op_type="aten__add" op_name="aten__add.1046/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.43 = f32[64]{0} rsqrt(f32[64]{0} %add.113), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.231 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.43), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1047/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.202 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.93.3, f32[64,1024]{1,0} %broadcast.231), metadata={op_type="aten__mul" op_name="aten__mul.1047/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.251 = bf16[1024]{0} parameter(1)
  %convert.358.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.251), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.171.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.358.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1048/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.171.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.202, f32[64,1024]{1,0} %broadcast.171.1), metadata={op_type="aten__mul" op_name="aten__mul.1048/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.359.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.171.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.4 (param_0.282: bf16[64,6144]) -> bf16[64,3072] {
  %param_0.282 = bf16[64,6144]{1,0} parameter(0)
  %slice.97.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.282), slice={[0:64], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.360.6 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.97.1)
  %constant_1_6 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.4 = f32[] convert(bf16[] %constant_1_6)
  %broadcast.194.44 = f32[64,3072]{1,0} broadcast(f32[] %convert.436.4), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.19.7 = f32[64,3072]{1,0} negate(f32[64,3072]{1,0} %convert.360.6)
  %convert.365.5 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %negate.19.7)
  %exponential.19.3 = bf16[64,3072]{1,0} exponential(bf16[64,3072]{1,0} %convert.365.5)
  %convert.366.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %exponential.19.3)
  %add.94.5 = f32[64,3072]{1,0} add(f32[64,3072]{1,0} %broadcast.194.44, f32[64,3072]{1,0} %convert.366.1)
  %divide.19.3 = f32[64,3072]{1,0} divide(f32[64,3072]{1,0} %broadcast.194.44, f32[64,3072]{1,0} %add.94.5), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.172.3 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %convert.360.6, f32[64,3072]{1,0} %divide.19.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.98.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.282), slice={[0:64], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.367.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.98.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.173.1 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %multiply.172.3, f32[64,3072]{1,0} %convert.367.1), metadata={op_type="aten__mul" op_name="aten__mul.1049/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.368.1 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %multiply.173.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.68 (param_0.293: f32[], param_1.254: bf16[64,1024], param_2.164: bf16[64,6144], param_3.151: bf16[1024], param_4.85: bf16[64,1,1024], param_5.35: bf16[64,1024]) -> bf16[64,1024] {
  %param_2.164 = bf16[64,6144]{1,0} parameter(2)
  %convert.342.30 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_2.164), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.5 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.30), slice={[0:64], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.254 = bf16[64,1024]{1,0} parameter(1)
  %convert.371.3 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_1.254), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.9 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.30), slice={[0:64], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.35 = bf16[64,1024]{1,0} parameter(5)
  %convert.357.7 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_5.35), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.15 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.30), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.85 = bf16[64,1,1024]{2,0,1} parameter(4)
  %bitcast.1170.15 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_4.85)
  %convert.345.15 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.15), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.13 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.15, f32[64,1024]{1,0} %convert.345.15), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.357.7, f32[64,1024]{1,0} %add.90.13), metadata={op_type="aten__add" op_name="aten__add.1032/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.93.9, f32[64,1024]{1,0} %add.92.7), metadata={op_type="aten__add" op_name="aten__add.1045/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.371.3, f32[64,1024]{1,0} %add.93.7), metadata={op_type="aten__add" op_name="aten__add.1050/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.92.5, f32[64,1024]{1,0} %add.95.3), metadata={op_type="aten__add" op_name="aten__add.1063/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.210 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.96.3, f32[64,1024]{1,0} %add.96.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_178 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.21 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.210, f32[] %constant_178), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_177 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.239 = f32[64]{0} broadcast(f32[] %constant_177), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.209 = f32[64]{0} multiply(f32[64]{0} %reduce.21, f32[64]{0} %broadcast.239), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.293 = f32[] parameter(0)
  %broadcast.238 = f32[64]{0} broadcast(f32[] %param_0.293), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.116 = f32[64]{0} add(f32[64]{0} %multiply.209, f32[64]{0} %broadcast.238), metadata={op_type="aten__add" op_name="aten__add.1064/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.45 = f32[64]{0} rsqrt(f32[64]{0} %add.116), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.237 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.45), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1065/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.208 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.96.3, f32[64,1024]{1,0} %broadcast.237), metadata={op_type="aten__mul" op_name="aten__mul.1065/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.151 = bf16[1024]{0} parameter(3)
  %convert.372.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.151), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.174.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.372.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1066/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.174.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.208, f32[64,1024]{1,0} %broadcast.174.1), metadata={op_type="aten__mul" op_name="aten__mul.1066/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.374.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.174.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.3 (param_0.284: bf16[64,6144]) -> bf16[64,3072] {
  %param_0.284 = bf16[64,6144]{1,0} parameter(0)
  %slice.99.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.284), slice={[0:64], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.375.6 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.99.1)
  %constant_1_1 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.6 = f32[] convert(bf16[] %constant_1_1)
  %broadcast.194.40 = f32[64,3072]{1,0} broadcast(f32[] %convert.436.6), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.20.7 = f32[64,3072]{1,0} negate(f32[64,3072]{1,0} %convert.375.6)
  %convert.381.5 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %negate.20.7)
  %exponential.20.3 = bf16[64,3072]{1,0} exponential(bf16[64,3072]{1,0} %convert.381.5)
  %convert.383.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %exponential.20.3)
  %add.97.5 = f32[64,3072]{1,0} add(f32[64,3072]{1,0} %broadcast.194.40, f32[64,3072]{1,0} %convert.383.1)
  %divide.20.3 = f32[64,3072]{1,0} divide(f32[64,3072]{1,0} %broadcast.194.40, f32[64,3072]{1,0} %add.97.5), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.175.3 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %convert.375.6, f32[64,3072]{1,0} %divide.20.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.100.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.284), slice={[0:64], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.385.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.100.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.176.1 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %multiply.175.3, f32[64,3072]{1,0} %convert.385.1), metadata={op_type="aten__mul" op_name="aten__mul.1067/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.386.1 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %multiply.176.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.67 (param_0.316: f32[], param_1.257: bf16[1024], param_2.168: bf16[64,1,1024], param_3.158: bf16[64,6144], param_4.91: bf16[64,1024], param_5.41: bf16[64,1024], param_6.28: bf16[64,1024]) -> bf16[64,1024] {
  %param_3.158 = bf16[64,6144]{1,0} parameter(3)
  %convert.342.60 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_3.158), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.5 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.60), slice={[0:64], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.28 = bf16[64,1024]{1,0} parameter(6)
  %convert.387.3 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_6.28), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.9 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.60), slice={[0:64], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.41 = bf16[64,1024]{1,0} parameter(5)
  %convert.371.7 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_5.41), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.11 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.60), slice={[0:64], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.91 = bf16[64,1024]{1,0} parameter(4)
  %convert.357.9 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_4.91), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.17 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.60), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.168 = bf16[64,1,1024]{2,0,1} parameter(2)
  %bitcast.1170.17 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_2.168)
  %convert.345.17 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.17), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.15 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.17, f32[64,1024]{1,0} %convert.345.17), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.357.9, f32[64,1024]{1,0} %add.90.15), metadata={op_type="aten__add" op_name="aten__add.1032/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.93.11, f32[64,1024]{1,0} %add.92.9), metadata={op_type="aten__add" op_name="aten__add.1045/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.371.7, f32[64,1024]{1,0} %add.93.9), metadata={op_type="aten__add" op_name="aten__add.1050/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.92.9, f32[64,1024]{1,0} %add.95.7), metadata={op_type="aten__add" op_name="aten__add.1063/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.387.3, f32[64,1024]{1,0} %add.96.7), metadata={op_type="aten__add" op_name="aten__add.1068/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.100.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.91.5, f32[64,1024]{1,0} %add.98.3), metadata={op_type="aten__add" op_name="aten__add.1081/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.217 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.100.3, f32[64,1024]{1,0} %add.100.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_183 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.23 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.217, f32[] %constant_183), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_182 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.246 = f32[64]{0} broadcast(f32[] %constant_182), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.216 = f32[64]{0} multiply(f32[64]{0} %reduce.23, f32[64]{0} %broadcast.246), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.316 = f32[] parameter(0)
  %broadcast.245 = f32[64]{0} broadcast(f32[] %param_0.316), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.118 = f32[64]{0} add(f32[64]{0} %multiply.216, f32[64]{0} %broadcast.245), metadata={op_type="aten__add" op_name="aten__add.1082/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.47 = f32[64]{0} rsqrt(f32[64]{0} %add.118), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.244 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.47), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1083/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.214 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.100.3, f32[64,1024]{1,0} %broadcast.244), metadata={op_type="aten__mul" op_name="aten__mul.1083/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.257 = bf16[1024]{0} parameter(1)
  %convert.390.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.257), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.177.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.390.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1084/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.177.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.214, f32[64,1024]{1,0} %broadcast.177.1), metadata={op_type="aten__mul" op_name="aten__mul.1084/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.391.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.177.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.2 (param_0.283: bf16[64,6144]) -> bf16[64,3072] {
  %param_0.283 = bf16[64,6144]{1,0} parameter(0)
  %slice.101.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.283), slice={[0:64], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.392.6 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.101.1)
  %constant_1_7 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.5 = f32[] convert(bf16[] %constant_1_7)
  %broadcast.194.36 = f32[64,3072]{1,0} broadcast(f32[] %convert.436.5), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.21.7 = f32[64,3072]{1,0} negate(f32[64,3072]{1,0} %convert.392.6)
  %convert.396.5 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %negate.21.7)
  %exponential.21.3 = bf16[64,3072]{1,0} exponential(bf16[64,3072]{1,0} %convert.396.5)
  %convert.397.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %exponential.21.3)
  %add.101.5 = f32[64,3072]{1,0} add(f32[64,3072]{1,0} %broadcast.194.36, f32[64,3072]{1,0} %convert.397.1)
  %divide.21.3 = f32[64,3072]{1,0} divide(f32[64,3072]{1,0} %broadcast.194.36, f32[64,3072]{1,0} %add.101.5), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.178.3 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %convert.392.6, f32[64,3072]{1,0} %divide.21.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.102.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.283), slice={[0:64], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.398.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.102.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.179.1 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %multiply.178.3, f32[64,3072]{1,0} %convert.398.1), metadata={op_type="aten__mul" op_name="aten__mul.1085/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.399.1 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %multiply.179.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.66 (param_0.291: f32[], param_1.260: bf16[64,1024], param_2.171: bf16[64,6144], param_3.162: bf16[1024], param_4.96: bf16[64,1,1024], param_5.46: bf16[64,1024], param_6.35: bf16[64,1024], param_7.27: bf16[64,1024]) -> bf16[64,1024] {
  %param_2.171 = bf16[64,6144]{1,0} parameter(2)
  %convert.342.26 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_2.171), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.5 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.26), slice={[0:64], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.260 = bf16[64,1024]{1,0} parameter(1)
  %convert.401.3 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_1.260), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.9 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.26), slice={[0:64], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_7.27 = bf16[64,1024]{1,0} parameter(7)
  %convert.387.7 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_7.27), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.13 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.26), slice={[0:64], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.35 = bf16[64,1024]{1,0} parameter(6)
  %convert.371.11 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_6.35), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.15 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.26), slice={[0:64], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.46 = bf16[64,1024]{1,0} parameter(5)
  %convert.357.13 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_5.46), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.21 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.26), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.96 = bf16[64,1,1024]{2,0,1} parameter(4)
  %bitcast.1170.21 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_4.96)
  %convert.345.21 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.21), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.19 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.21, f32[64,1024]{1,0} %convert.345.21), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.13 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.357.13, f32[64,1024]{1,0} %add.90.19), metadata={op_type="aten__add" op_name="aten__add.1032/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.13 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.93.15, f32[64,1024]{1,0} %add.92.13), metadata={op_type="aten__add" op_name="aten__add.1045/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.11 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.371.11, f32[64,1024]{1,0} %add.93.13), metadata={op_type="aten__add" op_name="aten__add.1050/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.11 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.92.13, f32[64,1024]{1,0} %add.95.11), metadata={op_type="aten__add" op_name="aten__add.1063/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.387.7, f32[64,1024]{1,0} %add.96.11), metadata={op_type="aten__add" op_name="aten__add.1068/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.100.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.91.9, f32[64,1024]{1,0} %add.98.7), metadata={op_type="aten__add" op_name="aten__add.1081/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.102.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.401.3, f32[64,1024]{1,0} %add.100.7), metadata={op_type="aten__add" op_name="aten__add.1086/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.90.5, f32[64,1024]{1,0} %add.102.3), metadata={op_type="aten__add" op_name="aten__add.1099/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.225 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.103.3, f32[64,1024]{1,0} %add.103.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_188 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.25 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.225, f32[] %constant_188), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_187 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.254 = f32[64]{0} broadcast(f32[] %constant_187), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.223 = f32[64]{0} multiply(f32[64]{0} %reduce.25, f32[64]{0} %broadcast.254), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.291 = f32[] parameter(0)
  %broadcast.253 = f32[64]{0} broadcast(f32[] %param_0.291), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.120 = f32[64]{0} add(f32[64]{0} %multiply.223, f32[64]{0} %broadcast.253), metadata={op_type="aten__add" op_name="aten__add.1100/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.49 = f32[64]{0} rsqrt(f32[64]{0} %add.120), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.251 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.49), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1101/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.222 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.103.3, f32[64,1024]{1,0} %broadcast.251), metadata={op_type="aten__mul" op_name="aten__mul.1101/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.162 = bf16[1024]{0} parameter(3)
  %convert.402.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.162), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.182.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.402.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1102/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.180.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.222, f32[64,1024]{1,0} %broadcast.182.1), metadata={op_type="aten__mul" op_name="aten__mul.1102/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.403.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.180.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.1 (param_0.281: bf16[64,6144]) -> bf16[64,3072] {
  %param_0.281 = bf16[64,6144]{1,0} parameter(0)
  %slice.103.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.281), slice={[0:64], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.406.6 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.103.1)
  %constant_1_5 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.3 = f32[] convert(bf16[] %constant_1_5)
  %broadcast.194.32 = f32[64,3072]{1,0} broadcast(f32[] %convert.436.3), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.22.7 = f32[64,3072]{1,0} negate(f32[64,3072]{1,0} %convert.406.6)
  %convert.410.5 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %negate.22.7)
  %exponential.22.3 = bf16[64,3072]{1,0} exponential(bf16[64,3072]{1,0} %convert.410.5)
  %convert.412.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %exponential.22.3)
  %add.104.5 = f32[64,3072]{1,0} add(f32[64,3072]{1,0} %broadcast.194.32, f32[64,3072]{1,0} %convert.412.1)
  %divide.22.3 = f32[64,3072]{1,0} divide(f32[64,3072]{1,0} %broadcast.194.32, f32[64,3072]{1,0} %add.104.5), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.181.3 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %convert.406.6, f32[64,3072]{1,0} %divide.22.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.104.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.281), slice={[0:64], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.413.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.104.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.182.1 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %multiply.181.3, f32[64,3072]{1,0} %convert.413.1), metadata={op_type="aten__mul" op_name="aten__mul.1103/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.414.1 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %multiply.182.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.65 (param_0.308: f32[], param_1.247: bf16[1024], param_2.173: bf16[64,1024], param_3.164: bf16[64,6144], param_4.98: bf16[64,1024], param_5.48: bf16[64,1,1024], param_6.39: bf16[64,1024], param_7.32: bf16[64,1024], param_8.24: bf16[64,1024]) -> bf16[64,1024] {
  %param_3.164 = bf16[64,6144]{1,0} parameter(3)
  %convert.342.36 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_3.164), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.88.5 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.36), slice={[0:64], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.98 = bf16[64,1024]{1,0} parameter(4)
  %convert.415.3 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_4.98), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.9 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.36), slice={[0:64], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.173 = bf16[64,1024]{1,0} parameter(2)
  %convert.401.7 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_2.173), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.11 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.36), slice={[0:64], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_8.24 = bf16[64,1024]{1,0} parameter(8)
  %convert.387.9 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_8.24), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.15 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.36), slice={[0:64], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_7.32 = bf16[64,1024]{1,0} parameter(7)
  %convert.371.13 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_7.32), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.17 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.36), slice={[0:64], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.39 = bf16[64,1024]{1,0} parameter(6)
  %convert.357.15 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_6.39), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.23 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.36), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.48 = bf16[64,1,1024]{2,0,1} parameter(5)
  %bitcast.1170.23 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_5.48)
  %convert.345.23 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.23), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.21 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.23, f32[64,1024]{1,0} %convert.345.23), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.15 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.357.15, f32[64,1024]{1,0} %add.90.21), metadata={op_type="aten__add" op_name="aten__add.1032/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.15 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.93.17, f32[64,1024]{1,0} %add.92.15), metadata={op_type="aten__add" op_name="aten__add.1045/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.13 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.371.13, f32[64,1024]{1,0} %add.93.15), metadata={op_type="aten__add" op_name="aten__add.1050/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.13 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.92.15, f32[64,1024]{1,0} %add.95.13), metadata={op_type="aten__add" op_name="aten__add.1063/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.387.9, f32[64,1024]{1,0} %add.96.13), metadata={op_type="aten__add" op_name="aten__add.1068/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.100.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.91.11, f32[64,1024]{1,0} %add.98.9), metadata={op_type="aten__add" op_name="aten__add.1081/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.102.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.401.7, f32[64,1024]{1,0} %add.100.9), metadata={op_type="aten__add" op_name="aten__add.1086/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.7 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.90.9, f32[64,1024]{1,0} %add.102.7), metadata={op_type="aten__add" op_name="aten__add.1099/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.105.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.415.3, f32[64,1024]{1,0} %add.103.7), metadata={op_type="aten__add" op_name="aten__add.1104/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106.3 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.88.5, f32[64,1024]{1,0} %add.105.3), metadata={op_type="aten__add" op_name="aten__add.1117/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.232 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.106.3, f32[64,1024]{1,0} %add.106.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_193 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.27 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.232, f32[] %constant_193), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_192 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.261 = f32[64]{0} broadcast(f32[] %constant_192), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.231 = f32[64]{0} multiply(f32[64]{0} %reduce.27, f32[64]{0} %broadcast.261), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.308 = f32[] parameter(0)
  %broadcast.260 = f32[64]{0} broadcast(f32[] %param_0.308), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.122 = f32[64]{0} add(f32[64]{0} %multiply.231, f32[64]{0} %broadcast.260), metadata={op_type="aten__add" op_name="aten__add.1118/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.51 = f32[64]{0} rsqrt(f32[64]{0} %add.122), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.259 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.51), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1119/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.230 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.106.3, f32[64,1024]{1,0} %broadcast.259), metadata={op_type="aten__mul" op_name="aten__mul.1119/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.247 = bf16[1024]{0} parameter(1)
  %convert.416.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.247), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.186.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.416.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1120/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.183.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.230, f32[64,1024]{1,0} %broadcast.186.1), metadata={op_type="aten__mul" op_name="aten__mul.1120/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.417.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.183.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert (param_0.279: bf16[64,6144]) -> bf16[64,3072] {
  %param_0.279 = bf16[64,6144]{1,0} parameter(0)
  %slice.105.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.279), slice={[0:64], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.418.6 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.105.1)
  %constant_1_3 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.1 = f32[] convert(bf16[] %constant_1_3)
  %broadcast.194.28 = f32[64,3072]{1,0} broadcast(f32[] %convert.436.1), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.23.7 = f32[64,3072]{1,0} negate(f32[64,3072]{1,0} %convert.418.6)
  %convert.422.5 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %negate.23.7)
  %exponential.23.3 = bf16[64,3072]{1,0} exponential(bf16[64,3072]{1,0} %convert.422.5)
  %convert.423.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %exponential.23.3)
  %add.107.5 = f32[64,3072]{1,0} add(f32[64,3072]{1,0} %broadcast.194.28, f32[64,3072]{1,0} %convert.423.1)
  %divide.23.3 = f32[64,3072]{1,0} divide(f32[64,3072]{1,0} %broadcast.194.28, f32[64,3072]{1,0} %add.107.5), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.184.3 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %convert.418.6, f32[64,3072]{1,0} %divide.23.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.106.1 = bf16[64,3072]{1,0} slice(bf16[64,6144]{1,0} %param_0.279), slice={[0:64], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.424.1 = f32[64,3072]{1,0} convert(bf16[64,3072]{1,0} %slice.106.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.185.1 = f32[64,3072]{1,0} multiply(f32[64,3072]{1,0} %multiply.184.3, f32[64,3072]{1,0} %convert.424.1), metadata={op_type="aten__mul" op_name="aten__mul.1121/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.425.1 = bf16[64,3072]{1,0} convert(f32[64,3072]{1,0} %multiply.185.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.63 (param_0.289: f32[], param_1.249: bf16[64,1024], param_2.157: bf16[1024], param_3.160: bf16[64,1024], param_4.93: bf16[64,6144], param_5.42: bf16[64,1024], param_6.30: bf16[64,1,1024], param_7.21: bf16[64,1024], param_8.11: bf16[64,1024], param_9.12: bf16[64,1024]) -> bf16[64,1024] {
  %param_1.249 = bf16[64,1024]{1,0} parameter(1)
  %convert.427.5 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_1.249), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.93 = bf16[64,6144]{1,0} parameter(4)
  %convert.342.40 = f32[64,6144]{1,0} convert(bf16[64,6144]{1,0} %param_4.93), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.88.7 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.40), slice={[0:64], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.42 = bf16[64,1024]{1,0} parameter(5)
  %convert.415.5 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_5.42), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.11 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.40), slice={[0:64], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.160 = bf16[64,1024]{1,0} parameter(3)
  %convert.401.9 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_3.160), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.7 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.40), slice={[0:64], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_9.12 = bf16[64,1024]{1,0} parameter(9)
  %convert.387.5 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_9.12), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.11 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.40), slice={[0:64], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_8.11 = bf16[64,1024]{1,0} parameter(8)
  %convert.371.9 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_8.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.13 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.40), slice={[0:64], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_7.21 = bf16[64,1024]{1,0} parameter(7)
  %convert.357.11 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %param_7.21), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.19 = f32[64,1024]{1,0} slice(f32[64,6144]{1,0} %convert.342.40), slice={[0:64], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.30 = bf16[64,1,1024]{2,0,1} parameter(6)
  %bitcast.1170.19 = bf16[64,1024]{1,0} bitcast(bf16[64,1,1024]{2,0,1} %param_6.30)
  %convert.345.19 = f32[64,1024]{1,0} convert(bf16[64,1024]{1,0} %bitcast.1170.19), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.17 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.94.19, f32[64,1024]{1,0} %convert.345.19), metadata={op_type="aten__add" op_name="aten__add.1027/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.11 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.357.11, f32[64,1024]{1,0} %add.90.17), metadata={op_type="aten__add" op_name="aten__add.1032/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.11 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.93.13, f32[64,1024]{1,0} %add.92.11), metadata={op_type="aten__add" op_name="aten__add.1045/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.371.9, f32[64,1024]{1,0} %add.93.11), metadata={op_type="aten__add" op_name="aten__add.1050/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.92.11, f32[64,1024]{1,0} %add.95.9), metadata={op_type="aten__add" op_name="aten__add.1063/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98.5 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.387.5, f32[64,1024]{1,0} %add.96.9), metadata={op_type="aten__add" op_name="aten__add.1068/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.100.5 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.91.7, f32[64,1024]{1,0} %add.98.5), metadata={op_type="aten__add" op_name="aten__add.1081/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.102.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.401.9, f32[64,1024]{1,0} %add.100.5), metadata={op_type="aten__add" op_name="aten__add.1086/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.9 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.90.11, f32[64,1024]{1,0} %add.102.9), metadata={op_type="aten__add" op_name="aten__add.1099/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.105.5 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.415.5, f32[64,1024]{1,0} %add.103.9), metadata={op_type="aten__add" op_name="aten__add.1104/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106.5 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %slice.88.7, f32[64,1024]{1,0} %add.105.5), metadata={op_type="aten__add" op_name="aten__add.1117/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.108.5 = f32[64,1024]{1,0} add(f32[64,1024]{1,0} %convert.427.5, f32[64,1024]{1,0} %add.106.5), metadata={op_type="aten__add" op_name="aten__add.1122/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.240 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.108.5, f32[64,1024]{1,0} %add.108.5), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_202 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.29 = f32[64]{0} reduce(f32[64,1024]{1,0} %multiply.240, f32[] %constant_202), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_199 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.267 = f32[64]{0} broadcast(f32[] %constant_199), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.239 = f32[64]{0} multiply(f32[64]{0} %reduce.29, f32[64]{0} %broadcast.267), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.289 = f32[] parameter(0)
  %broadcast.266 = f32[64]{0} broadcast(f32[] %param_0.289), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1028/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.124 = f32[64]{0} add(f32[64]{0} %multiply.239, f32[64]{0} %broadcast.266), metadata={op_type="aten__add" op_name="aten__add.1123/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.53 = f32[64]{0} rsqrt(f32[64]{0} %add.124), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.265 = f32[64,1024]{1,0} broadcast(f32[64]{0} %rsqrt.53), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.1124/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.238 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %add.108.5, f32[64,1024]{1,0} %broadcast.265), metadata={op_type="aten__mul" op_name="aten__mul.1124/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.157 = bf16[1024]{0} parameter(2)
  %convert.428.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.157), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.189.1 = f32[64,1024]{1,0} broadcast(f32[1024]{0} %convert.428.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.1125/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.187.1 = f32[64,1024]{1,0} multiply(f32[64,1024]{1,0} %multiply.238, f32[64,1024]{1,0} %broadcast.189.1), metadata={op_type="aten__mul" op_name="aten__mul.1125/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.429.1 = bf16[64,1024]{1,0} convert(f32[64,1024]{1,0} %multiply.187.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_slice_computation (param_0.321: bf16[64,4096]) -> bf16[64,1024] {
  %param_0.321 = bf16[64,4096]{1,0} parameter(0)
  ROOT %slice.112.1 = bf16[64,1024]{1,0} slice(bf16[64,4096]{1,0} %param_0.321), slice={[0:64], [3072:4096]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%triton_softmax_computation.8 (param_0.187: f32[], param_1.191: bf16[64,4096]) -> f32[64,8,128] {
  %param_1.191 = bf16[64,4096]{1,0} parameter(1)
  %slice.107.1 = bf16[64,1024]{1,0} slice(bf16[64,4096]{1,0} %param_1.191), slice={[0:64], [2048:3072]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1457.3 = bf16[64,8,128]{2,1,0} bitcast(bf16[64,1024]{1,0} %slice.107.1)
  %convert.430.3 = f32[64,8,128]{2,1,0} convert(bf16[64,8,128]{2,1,0} %bitcast.1457.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.137 = f32[64,8,128]{2,1,0} multiply(f32[64,8,128]{2,1,0} %convert.430.3, f32[64,8,128]{2,1,0} %convert.430.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_92 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.8 = f32[64,8]{1,0} reduce(f32[64,8,128]{2,1,0} %multiply.137, f32[] %constant_92), dimensions={2}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_93 = f32[] constant(0.0078125), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.139 = f32[64,8]{1,0} broadcast(f32[] %constant_93), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.138 = f32[64,8]{1,0} multiply(f32[64,8]{1,0} %reduce.8, f32[64,8]{1,0} %broadcast.139), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.187 = f32[] parameter(0)
  %broadcast.140 = f32[64,8]{1,0} broadcast(f32[] %param_0.187), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1126/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81 = f32[64,8]{1,0} add(f32[64,8]{1,0} %multiply.138, f32[64,8]{1,0} %broadcast.140), metadata={op_type="aten__add" op_name="aten__add.1126/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.32 = f32[64,8]{1,0} rsqrt(f32[64,8]{1,0} %add.81), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.141 = f32[64,8,128]{2,1,0} broadcast(f32[64,8]{1,0} %rsqrt.32), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.1127/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %multiply.139 = f32[64,8,128]{2,1,0} multiply(f32[64,8,128]{2,1,0} %convert.430.3, f32[64,8,128]{2,1,0} %broadcast.141), metadata={op_type="aten__mul" op_name="aten__mul.1127/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_concatenate (param_0.306: f32[64,8,128], param_1.243: bf16[128], param_2.165: bf16[40960,128], param_3.153: s32[64]) -> bf16[64,8,128] {
  %param_0.306 = f32[64,8,128]{2,1,0} parameter(0)
  %param_1.243 = bf16[128]{0} parameter(1)
  %convert.431.1 = f32[128]{0} convert(bf16[128]{0} %param_1.243), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.190.18 = f32[64,8,128]{2,1,0} broadcast(f32[128]{0} %convert.431.1), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.1128/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.188.18 = f32[64,8,128]{2,1,0} multiply(f32[64,8,128]{2,1,0} %param_0.306, f32[64,8,128]{2,1,0} %broadcast.190.18), metadata={op_type="aten__mul" op_name="aten__mul.1128/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.108.9 = f32[64,8,64]{2,1,0} slice(f32[64,8,128]{2,1,0} %multiply.188.18), slice={[0:64], [0:8], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.165 = bf16[40960,128]{1,0} parameter(2)
  %param_3.153 = s32[64]{0} parameter(3)
  %bitcast.1473.3 = s32[64,1]{1,0} bitcast(s32[64]{0} %param_3.153)
  %gather.1.3 = bf16[64,1,128]{2,0,1} gather(bf16[40960,128]{1,0} %param_2.165, s32[64,1]{1,0} %bitcast.1473.3), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1476.7 = bf16[64,128]{1,0} bitcast(bf16[64,1,128]{2,0,1} %gather.1.3)
  %convert.432.7 = f32[64,128]{1,0} convert(bf16[64,128]{1,0} %bitcast.1476.7), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.109.3 = f32[64,64]{1,0} slice(f32[64,128]{1,0} %convert.432.7), slice={[0:64], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.191.14 = f32[64,8,64]{2,1,0} broadcast(f32[64,64]{1,0} %slice.109.3), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.1129/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.189.7 = f32[64,8,64]{2,1,0} multiply(f32[64,8,64]{2,1,0} %slice.108.9, f32[64,8,64]{2,1,0} %broadcast.191.14), metadata={op_type="aten__mul" op_name="aten__mul.1129/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.110.9 = f32[64,8,64]{2,1,0} slice(f32[64,8,128]{2,1,0} %multiply.188.18), slice={[0:64], [0:8], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.111.3 = f32[64,64]{1,0} slice(f32[64,128]{1,0} %convert.432.7), slice={[0:64], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.192.10 = f32[64,8,64]{2,1,0} broadcast(f32[64,64]{1,0} %slice.111.3), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.1130/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.190.5 = f32[64,8,64]{2,1,0} multiply(f32[64,8,64]{2,1,0} %slice.110.9, f32[64,8,64]{2,1,0} %broadcast.192.10), metadata={op_type="aten__mul" op_name="aten__mul.1130/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %subtract.2.5 = f32[64,8,64]{2,1,0} subtract(f32[64,8,64]{2,1,0} %multiply.189.7, f32[64,8,64]{2,1,0} %multiply.190.5), metadata={op_type="aten__sub" op_name="aten__sub.1131/aten__sub" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.434.3 = bf16[64,8,64]{2,1,0} convert(f32[64,8,64]{2,1,0} %subtract.2.5)
  %multiply.191.7 = f32[64,8,64]{2,1,0} multiply(f32[64,8,64]{2,1,0} %slice.110.9, f32[64,8,64]{2,1,0} %broadcast.191.14), metadata={op_type="aten__mul" op_name="aten__mul.1132/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.192.5 = f32[64,8,64]{2,1,0} multiply(f32[64,8,64]{2,1,0} %slice.108.9, f32[64,8,64]{2,1,0} %broadcast.192.10), metadata={op_type="aten__mul" op_name="aten__mul.1133/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.109.5 = f32[64,8,64]{2,1,0} add(f32[64,8,64]{2,1,0} %multiply.191.7, f32[64,8,64]{2,1,0} %multiply.192.5), metadata={op_type="aten__add" op_name="aten__add.1134/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.435.3 = bf16[64,8,64]{2,1,0} convert(f32[64,8,64]{2,1,0} %add.109.5)
  ROOT %concatenate.16.1 = bf16[64,8,128]{2,1,0} concatenate(bf16[64,8,64]{2,1,0} %convert.434.3, bf16[64,8,64]{2,1,0} %convert.435.3), dimensions={2}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_slice (param_0.1: bf16[2,4233,16,8,128]) -> bf16[69353472] {
  %param_0.1 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  %bitcast.1517.1 = bf16[138706944]{0} bitcast(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.1)
  ROOT %slice.114.1 = bf16[69353472]{0} slice(bf16[138706944]{0} %bitcast.1517.1), slice={[69353472:138706944]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%wrapped_slice_computation.1 (param_0.322: bf16[2,4233,16,8,128]) -> bf16[1,4233,16,8,128] {
  %param_0.322 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  ROOT %slice.113.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} slice(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.322), slice={[0:1], [0:4233], [0:16], [0:8], [0:128]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%command_buffer (p: bf16[151936,1024], p.1: s32[64], p.2: bf16[1024,2048], p.3: bf16[1024,2048], p.4: bf16[1024,2048], p.5: bf16[1024,2048], p.6: bf16[1024,2048], p.7: bf16[1024,2048], p.8: f32[], p.9: bf16[1024], p.10: bf16[6144,1024], p.11: bf16[1024,3072], p.12: bf16[1024], p.13: bf16[6144,1024], p.14: bf16[1024,3072], p.15: bf16[1024], p.16: bf16[6144,1024], p.17: bf16[1024,3072], p.18: bf16[1024], p.19: bf16[6144,1024], p.20: bf16[1024,3072], p.21: bf16[1024], p.22: bf16[6144,1024], p.23: bf16[1024,3072], p.24: bf16[1024], p.25: bf16[6144,1024], p.26: bf16[1024,3072], p.27: bf16[1024], p.28: bf16[4096,1024], p.29: bf16[128], p.30: bf16[40960,128], p.31: s32[64], p.32: bf16[2,4233,16,8,128]) -> (bf16[64,8,128], bf16[64,8,128], bf16[4233,16,8,128], bf16[1,4233,16,8,128]) {
  %p = bf16[151936,1024]{1,0} parameter(0)
  %p.1 = s32[64]{0} parameter(1)
  %p.2 = bf16[1024,2048]{1,0} parameter(2)
  %p.3 = bf16[1024,2048]{1,0} parameter(3)
  %p.4 = bf16[1024,2048]{1,0} parameter(4)
  %p.5 = bf16[1024,2048]{1,0} parameter(5)
  %p.6 = bf16[1024,2048]{1,0} parameter(6)
  %p.7 = bf16[1024,2048]{1,0} parameter(7)
  %p.8 = f32[] parameter(8)
  %p.9 = bf16[1024]{0} parameter(9)
  %p.10 = bf16[6144,1024]{1,0} parameter(10)
  %p.11 = bf16[1024,3072]{1,0} parameter(11)
  %p.12 = bf16[1024]{0} parameter(12)
  %p.13 = bf16[6144,1024]{1,0} parameter(13)
  %p.14 = bf16[1024,3072]{1,0} parameter(14)
  %p.15 = bf16[1024]{0} parameter(15)
  %p.16 = bf16[6144,1024]{1,0} parameter(16)
  %p.17 = bf16[1024,3072]{1,0} parameter(17)
  %p.18 = bf16[1024]{0} parameter(18)
  %p.19 = bf16[6144,1024]{1,0} parameter(19)
  %p.20 = bf16[1024,3072]{1,0} parameter(20)
  %p.21 = bf16[1024]{0} parameter(21)
  %p.22 = bf16[6144,1024]{1,0} parameter(22)
  %p.23 = bf16[1024,3072]{1,0} parameter(23)
  %p.24 = bf16[1024]{0} parameter(24)
  %p.25 = bf16[6144,1024]{1,0} parameter(25)
  %p.26 = bf16[1024,3072]{1,0} parameter(26)
  %p.27 = bf16[1024]{0} parameter(27)
  %p.28 = bf16[4096,1024]{1,0} parameter(28)
  %p.29 = bf16[128]{0} parameter(29)
  %p.30 = bf16[40960,128]{1,0} parameter(30)
  %p.31 = s32[64]{0} parameter(31)
  %p.32 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(32)
  %loop_gather_fusion = bf16[64,1,1024]{2,0,1} fusion(bf16[151936,1024]{1,0} %p, s32[64]{0} %p.1), kind=kLoop, calls=%fused_gather, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_concatenate = bf16[6144,2048]{1,0} fusion(bf16[1024,2048]{1,0} %p.2, bf16[1024,2048]{1,0} %p.3, bf16[1024,2048]{1,0} %p.4, bf16[1024,2048]{1,0} %p.5, bf16[1024,2048]{1,0} %p.6, /*index=5*/bf16[1024,2048]{1,0} %p.7), kind=kLoop, calls=%wrapped_concatenate_computation, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %gemm_fusion_dot.23.0 = bf16[64,6144]{1,0} fusion(bf16[6144,2048]{1,0} %wrapped_concatenate), kind=kCustom, calls=%gemm_fusion_dot.23_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton_gemm","triton_gemm_config":{"block_m":"64","block_n":"32","block_k":"64","split_k":"1","num_stages":"4","num_warps":"4","num_ctas":"1"}},"force_earliest_schedule":false}
  %fusion.87 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[64,1,1024]{2,0,1} %loop_gather_fusion, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, bf16[1024]{0} %p.9), kind=kCustom, calls=%fused_computation.70, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.13.0 = (bf16[64,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.87, bf16[6144,1024]{1,0} %p.10), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.13 = bf16[64,6144]{1,0} get-tuple-element((bf16[64,6144]{1,0}, s8[4194304]{0}) %custom-call.13.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.5 = bf16[64,3072]{1,0} fusion(bf16[64,6144]{1,0} %get-tuple-element.13), kind=kLoop, calls=%fused_convert.5, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.14.0 = (bf16[64,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[64,3072]{1,0} %loop_convert_fusion.5, bf16[1024,3072]{1,0} %p.11), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"196608","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.1.0 = bf16[64,1024]{1,0} get-tuple-element((bf16[64,1024]{1,0}, s8[4194304]{0}) %custom-call.14.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.86 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.12, bf16[64,1,1024]{2,0,1} %loop_gather_fusion, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, bf16[64,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.69, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.15.0 = (bf16[64,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.86, bf16[6144,1024]{1,0} %p.13), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.2.0 = bf16[64,6144]{1,0} get-tuple-element((bf16[64,6144]{1,0}, s8[4194304]{0}) %custom-call.15.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.4 = bf16[64,3072]{1,0} fusion(bf16[64,6144]{1,0} %get-tuple-element.2.0), kind=kLoop, calls=%fused_convert.4, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.16.0 = (bf16[64,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[64,3072]{1,0} %loop_convert_fusion.4, bf16[1024,3072]{1,0} %p.14), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"196608","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.3.0 = bf16[64,1024]{1,0} get-tuple-element((bf16[64,1024]{1,0}, s8[4194304]{0}) %custom-call.16.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.85 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[64,1024]{1,0} %get-tuple-element.3.0, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, bf16[1024]{0} %p.15, bf16[64,1,1024]{2,0,1} %loop_gather_fusion, /*index=5*/bf16[64,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.68, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.17.0 = (bf16[64,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.85, bf16[6144,1024]{1,0} %p.16), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.4.0 = bf16[64,6144]{1,0} get-tuple-element((bf16[64,6144]{1,0}, s8[4194304]{0}) %custom-call.17.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.3 = bf16[64,3072]{1,0} fusion(bf16[64,6144]{1,0} %get-tuple-element.4.0), kind=kLoop, calls=%fused_convert.3, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.18.0 = (bf16[64,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[64,3072]{1,0} %loop_convert_fusion.3, bf16[1024,3072]{1,0} %p.17), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"196608","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.5.0 = bf16[64,1024]{1,0} get-tuple-element((bf16[64,1024]{1,0}, s8[4194304]{0}) %custom-call.18.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.84 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.18, bf16[64,1,1024]{2,0,1} %loop_gather_fusion, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, bf16[64,1024]{1,0} %get-tuple-element.1.0, /*index=5*/bf16[64,1024]{1,0} %get-tuple-element.3.0, bf16[64,1024]{1,0} %get-tuple-element.5.0), kind=kCustom, calls=%fused_computation.67, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.19.0 = (bf16[64,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.84, bf16[6144,1024]{1,0} %p.19), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.6.0 = bf16[64,6144]{1,0} get-tuple-element((bf16[64,6144]{1,0}, s8[4194304]{0}) %custom-call.19.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.2 = bf16[64,3072]{1,0} fusion(bf16[64,6144]{1,0} %get-tuple-element.6.0), kind=kLoop, calls=%fused_convert.2, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.20.0 = (bf16[64,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[64,3072]{1,0} %loop_convert_fusion.2, bf16[1024,3072]{1,0} %p.20), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"196608","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.7.0 = bf16[64,1024]{1,0} get-tuple-element((bf16[64,1024]{1,0}, s8[4194304]{0}) %custom-call.20.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.83 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[64,1024]{1,0} %get-tuple-element.7.0, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, bf16[1024]{0} %p.21, bf16[64,1,1024]{2,0,1} %loop_gather_fusion, /*index=5*/bf16[64,1024]{1,0} %get-tuple-element.1.0, bf16[64,1024]{1,0} %get-tuple-element.3.0, bf16[64,1024]{1,0} %get-tuple-element.5.0), kind=kCustom, calls=%fused_computation.66, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.21.0 = (bf16[64,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.83, bf16[6144,1024]{1,0} %p.22), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.8.0 = bf16[64,6144]{1,0} get-tuple-element((bf16[64,6144]{1,0}, s8[4194304]{0}) %custom-call.21.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.1 = bf16[64,3072]{1,0} fusion(bf16[64,6144]{1,0} %get-tuple-element.8.0), kind=kLoop, calls=%fused_convert.1, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.22.0 = (bf16[64,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[64,3072]{1,0} %loop_convert_fusion.1, bf16[1024,3072]{1,0} %p.23), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"196608","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.9.0 = bf16[64,1024]{1,0} get-tuple-element((bf16[64,1024]{1,0}, s8[4194304]{0}) %custom-call.22.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.82 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.24, bf16[64,1024]{1,0} %get-tuple-element.7.0, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, bf16[64,1024]{1,0} %get-tuple-element.9.0, /*index=5*/bf16[64,1,1024]{2,0,1} %loop_gather_fusion, bf16[64,1024]{1,0} %get-tuple-element.1.0, bf16[64,1024]{1,0} %get-tuple-element.3.0, bf16[64,1024]{1,0} %get-tuple-element.5.0), kind=kCustom, calls=%fused_computation.65, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.23.0 = (bf16[64,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.82, bf16[6144,1024]{1,0} %p.25), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.10.0 = bf16[64,6144]{1,0} get-tuple-element((bf16[64,6144]{1,0}, s8[4194304]{0}) %custom-call.23.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion = bf16[64,3072]{1,0} fusion(bf16[64,6144]{1,0} %get-tuple-element.10.0), kind=kLoop, calls=%fused_convert, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.24.0 = (bf16[64,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[64,3072]{1,0} %loop_convert_fusion, bf16[1024,3072]{1,0} %p.26), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"196608","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.11.0 = bf16[64,1024]{1,0} get-tuple-element((bf16[64,1024]{1,0}, s8[4194304]{0}) %custom-call.24.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.80 = bf16[64,1024]{1,0} fusion(f32[] %p.8, bf16[64,1024]{1,0} %get-tuple-element.11.0, bf16[1024]{0} %p.27, bf16[64,1024]{1,0} %get-tuple-element.7.0, bf16[64,6144]{1,0} %gemm_fusion_dot.23.0, /*index=5*/bf16[64,1024]{1,0} %get-tuple-element.9.0, bf16[64,1,1024]{2,0,1} %loop_gather_fusion, bf16[64,1024]{1,0} %get-tuple-element.1.0, bf16[64,1024]{1,0} %get-tuple-element.3.0, bf16[64,1024]{1,0} %get-tuple-element.5.0), kind=kCustom, calls=%fused_computation.63, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.25.0 = (bf16[64,4096]{1,0}, s8[4194304]{0}) custom-call(bf16[64,1024]{1,0} %fusion.80, bf16[4096,1024]{1,0} %p.28), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"65536","rhs_stride":"4194304","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.12.0 = bf16[64,4096]{1,0} get-tuple-element((bf16[64,4096]{1,0}, s8[4194304]{0}) %custom-call.25.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_slice = bf16[64,1024]{1,0} fusion(bf16[64,4096]{1,0} %get-tuple-element.12.0), kind=kLoop, calls=%wrapped_slice_computation, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %triton_softmax.8.0 = f32[64,8,128]{2,1,0} fusion(f32[] %p.8, bf16[64,4096]{1,0} %get-tuple-element.12.0), kind=kCustom, calls=%triton_softmax_computation.8, metadata={op_type="aten__mul" op_name="aten__mul.1127/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","4","128"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %input_concatenate_fusion = bf16[64,8,128]{2,1,0} fusion(f32[64,8,128]{2,1,0} %triton_softmax.8.0, bf16[128]{0} %p.29, bf16[40960,128]{1,0} %p.30, s32[64]{0} %p.31), kind=kInput, calls=%fused_concatenate, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1509.0 = bf16[64,8,128]{2,1,0} bitcast(bf16[64,1024]{1,0} %wrapped_slice)
  %loop_slice_fusion = bf16[69353472]{0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.32), kind=kLoop, calls=%fused_slice, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  %bitcast.1521.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[69353472]{0} %loop_slice_fusion)
  %wrapped_slice.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.32), kind=kLoop, calls=%wrapped_slice_computation.1, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  ROOT %tuple = (bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) tuple(bf16[64,8,128]{2,1,0} %input_concatenate_fusion, bf16[64,8,128]{2,1,0} %bitcast.1509.0, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1521.0, bf16[1,4233,16,8,128]{4,3,2,1,0} %wrapped_slice.1)
}

ENTRY %SyncTensorsGraph.589 (p0.1.0: bf16[128], p1.4.0: f32[], p2.6.0: bf16[4096,1024], p3.8.0: bf16[1024], p4.24.0: s32[64], p5.26.0: bf16[151936,1024], p6.30.0: bf16[1024,2048], p7.46.0: bf16[1024,3072], p8.48.0: bf16[6144,1024], p9.50.0: bf16[1024], p10.102.0: bf16[1024,2048], p11.118.0: bf16[1024,3072], p12.120.0: bf16[6144,1024], p13.122.0: bf16[1024], p14.174.0: bf16[1024,2048], p15.190.0: bf16[1024,3072], p16.192.0: bf16[6144,1024], p17.194.0: bf16[1024], p18.246.0: bf16[1024,2048], p19.262.0: bf16[1024,3072], p20.264.0: bf16[6144,1024], p21.266.0: bf16[1024], p22.318.0: bf16[1024,2048], p23.334.0: bf16[1024,3072], p24.336.0: bf16[6144,1024], p25.338.0: bf16[1024], p26.390.0: bf16[1024,2048], p27.406.0: bf16[1024,3072], p28.408.0: bf16[6144,1024], p29.410.0: bf16[1024], p30.534.0: s32[64], p31.535.0: bf16[40960,128], p32.579.0: bf16[2,4233,16,8,128]) -> (bf16[64,8,128], bf16[64,8,128], bf16[4233,16,8,128], bf16[4233,16,8,128]) {
  %p1.4.0 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %p32.579.0 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(32), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p31.535.0 = bf16[40960,128]{1,0} parameter(31), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p30.534.0 = s32[64]{0} parameter(30), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p29.410.0 = bf16[1024]{0} parameter(29), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p28.408.0 = bf16[6144,1024]{1,0} parameter(28), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p27.406.0 = bf16[1024,3072]{1,0} parameter(27), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p26.390.0 = bf16[1024,2048]{1,0} parameter(26), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p25.338.0 = bf16[1024]{0} parameter(25), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p24.336.0 = bf16[6144,1024]{1,0} parameter(24), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p23.334.0 = bf16[1024,3072]{1,0} parameter(23), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p22.318.0 = bf16[1024,2048]{1,0} parameter(22), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p21.266.0 = bf16[1024]{0} parameter(21), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p20.264.0 = bf16[6144,1024]{1,0} parameter(20), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p19.262.0 = bf16[1024,3072]{1,0} parameter(19), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p18.246.0 = bf16[1024,2048]{1,0} parameter(18), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p17.194.0 = bf16[1024]{0} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p16.192.0 = bf16[6144,1024]{1,0} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p15.190.0 = bf16[1024,3072]{1,0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p14.174.0 = bf16[1024,2048]{1,0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p13.122.0 = bf16[1024]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p12.120.0 = bf16[6144,1024]{1,0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p11.118.0 = bf16[1024,3072]{1,0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p10.102.0 = bf16[1024,2048]{1,0} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p9.50.0 = bf16[1024]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p8.48.0 = bf16[6144,1024]{1,0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p7.46.0 = bf16[1024,3072]{1,0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p6.30.0 = bf16[1024,2048]{1,0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p5.26.0 = bf16[151936,1024]{1,0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p4.24.0 = s32[64]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p3.8.0 = bf16[1024]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p2.6.0 = bf16[4096,1024]{1,0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p0.1.0 = bf16[128]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %call = (bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) call(bf16[151936,1024]{1,0} %p5.26.0, s32[64]{0} %p4.24.0, bf16[1024,2048]{1,0} %p26.390.0, bf16[1024,2048]{1,0} %p22.318.0, bf16[1024,2048]{1,0} %p18.246.0, /*index=5*/bf16[1024,2048]{1,0} %p14.174.0, bf16[1024,2048]{1,0} %p10.102.0, bf16[1024,2048]{1,0} %p6.30.0, f32[] %p1.4.0, bf16[1024]{0} %p9.50.0, /*index=10*/bf16[6144,1024]{1,0} %p8.48.0, bf16[1024,3072]{1,0} %p7.46.0, bf16[1024]{0} %p13.122.0, bf16[6144,1024]{1,0} %p12.120.0, bf16[1024,3072]{1,0} %p11.118.0, /*index=15*/bf16[1024]{0} %p17.194.0, bf16[6144,1024]{1,0} %p16.192.0, bf16[1024,3072]{1,0} %p15.190.0, bf16[1024]{0} %p21.266.0, bf16[6144,1024]{1,0} %p20.264.0, /*index=20*/bf16[1024,3072]{1,0} %p19.262.0, bf16[1024]{0} %p25.338.0, bf16[6144,1024]{1,0} %p24.336.0, bf16[1024,3072]{1,0} %p23.334.0, bf16[1024]{0} %p29.410.0, /*index=25*/bf16[6144,1024]{1,0} %p28.408.0, bf16[1024,3072]{1,0} %p27.406.0, bf16[1024]{0} %p3.8.0, bf16[4096,1024]{1,0} %p2.6.0, bf16[128]{0} %p0.1.0, /*index=30*/bf16[40960,128]{1,0} %p31.535.0, s32[64]{0} %p30.534.0, bf16[2,4233,16,8,128]{4,3,2,1,0} %p32.579.0), to_apply=%command_buffer
  %get-tuple-element.15 = bf16[64,8,128]{2,1,0} get-tuple-element((bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=0
  %get-tuple-element.16 = bf16[64,8,128]{2,1,0} get-tuple-element((bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=1
  %get-tuple-element.17 = bf16[4233,16,8,128]{3,2,1,0} get-tuple-element((bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=2
  %get-tuple-element.18 = bf16[1,4233,16,8,128]{4,3,2,1,0} get-tuple-element((bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=3
  %bitcast.1514.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[1,4233,16,8,128]{4,3,2,1,0} %get-tuple-element.18)
  ROOT %tuple.588.0 = (bf16[64,8,128]{2,1,0}, bf16[64,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0}) tuple(bf16[64,8,128]{2,1,0} %get-tuple-element.15, bf16[64,8,128]{2,1,0} %get-tuple-element.16, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1514.0, bf16[4233,16,8,128]{3,2,1,0} %get-tuple-element.17)
}

