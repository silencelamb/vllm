HloModule SyncTensorsGraph.515, is_scheduled=true, entry_computation_layout={(bf16[128]{0}, f32[], bf16[4096,1024]{1,0}, bf16[1024]{0}, s32[16]{0}, /*index=5*/bf16[151936,1024]{1,0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=10*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=15*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=20*/bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, /*index=25*/bf16[1024]{0}, s32[16]{0}, bf16[40960,128]{1,0}, bf16[2,4233,16,8,128]{4,3,2,1,0})->(bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0})}, frontend_attributes={fingerprint_before_lhs="942f2fe6bf652018bc9cea6779a4feb9"}

%fused_gather (param_0.9: bf16[151936,1024], param_1.237: s32[16]) -> bf16[16,1,1024] {
  %param_0.9 = bf16[151936,1024]{1,0} parameter(0)
  %param_1.237 = s32[16]{0} parameter(1)
  %convert.294.1 = s64[16]{0} convert(s32[16]{0} %param_1.237), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.297.1 = u32[16]{0} convert(s64[16]{0} %convert.294.1), metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1027.1 = u32[16,1]{1,0} bitcast(u32[16]{0} %convert.297.1)
  ROOT %gather.3 = bf16[16,1,1024]{2,0,1} gather(bf16[151936,1024]{1,0} %param_0.9, u32[16,1]{1,0} %bitcast.1027.1), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,1024}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_concatenate_computation (param_0.287: bf16[1024,2048], param_1.257: bf16[1024,2048], param_2.164: bf16[1024,2048], param_3.153: bf16[1024,2048], param_4.91: bf16[1024,2048]) -> bf16[5120,2048] {
  %param_0.287 = bf16[1024,2048]{1,0} parameter(0)
  %param_1.257 = bf16[1024,2048]{1,0} parameter(1)
  %param_2.164 = bf16[1024,2048]{1,0} parameter(2)
  %param_3.153 = bf16[1024,2048]{1,0} parameter(3)
  %param_4.91 = bf16[1024,2048]{1,0} parameter(4)
  ROOT %concatenate.13.1 = bf16[5120,2048]{1,0} concatenate(bf16[1024,2048]{1,0} %param_0.287, bf16[1024,2048]{1,0} %param_1.257, bf16[1024,2048]{1,0} %param_2.164, bf16[1024,2048]{1,0} %param_3.153, bf16[1024,2048]{1,0} %param_4.91), dimensions={0}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
}

%gemm_fusion_dot.19_computation (parameter_0: bf16[5120,2048]) -> bf16[16,5120] {
  %parameter_0 = bf16[5120,2048]{1,0} parameter(0)
  %constant_66 = bf16[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.58 = bf16[16,2048]{1,0} broadcast(bf16[] %constant_66), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %dot.21 = bf16[5120,16]{0,1} dot(bf16[5120,2048]{1,0} %parameter_0, bf16[16,2048]{1,0} %broadcast.58), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %bitcast.499 = bf16[16,5120]{1,0} bitcast(bf16[5120,16]{0,1} %dot.21), metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%AddComputation.56 (x.57: f32[], y.58: f32[]) -> f32[] {
  %y.58 = f32[] parameter(1)
  %x.57 = f32[] parameter(0)
  ROOT %add.77 = f32[] add(f32[] %x.57, f32[] %y.58)
}

%fused_computation.62 (param_0.259: f32[], param_1.221: bf16[16,1,1024], param_2.123: bf16[16,5120], param_3.98: bf16[1024]) -> bf16[16,1024] {
  %param_2.123 = bf16[16,5120]{1,0} parameter(2)
  %convert.293.21 = f32[16,5120]{1,0} convert(bf16[16,5120]{1,0} %param_2.123), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.79.9 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.21), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.221 = bf16[16,1,1024]{2,0,1} parameter(1)
  %bitcast.1030.9 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_1.221)
  %convert.298.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1030.9), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.78.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.79.9, f32[16,1024]{1,0} %convert.298.9), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.206 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.78.7, f32[16,1024]{1,0} %add.78.7), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_182 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.25 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.206, f32[] %constant_182), dimensions={1}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_181 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.232 = f32[16]{0} broadcast(f32[] %constant_181), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.205 = f32[16]{0} multiply(f32[16]{0} %reduce.25, f32[16]{0} %broadcast.232), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.259 = f32[] parameter(0)
  %broadcast.231 = f32[16]{0} broadcast(f32[] %param_0.259), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106 = f32[16]{0} add(f32[16]{0} %multiply.205, f32[16]{0} %broadcast.231), metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.46 = f32[16]{0} rsqrt(f32[16]{0} %add.106), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.230 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.46), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.15/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.204 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.78.7, f32[16,1024]{1,0} %broadcast.230), metadata={op_type="aten__mul" op_name="aten__mul.15/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.98 = bf16[1024]{0} parameter(3)
  %convert.300.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.98), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.147.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.300.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.16/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.143.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.204, f32[16,1024]{1,0} %broadcast.147.1), metadata={op_type="aten__mul" op_name="aten__mul.16/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.301.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.143.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.4 (param_0.201: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.201 = bf16[16,6144]{1,0} parameter(0)
  %slice.80.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.201), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.303.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.80.1)
  %constant_1_4 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.379.2 = f32[] convert(bf16[] %constant_1_4)
  %broadcast.170.20 = f32[16,3072]{1,0} broadcast(f32[] %convert.379.2), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.15.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.303.8)
  %convert.309.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.15.5)
  %exponential.15.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.309.3)
  %convert.311.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.15.1)
  %add.79.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.170.20, f32[16,3072]{1,0} %convert.311.3)
  %divide.15.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.170.20, f32[16,3072]{1,0} %add.79.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.145.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.303.8, f32[16,3072]{1,0} %divide.15.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.81.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.201), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.312.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.81.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.146.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.145.5, f32[16,3072]{1,0} %convert.312.1), metadata={op_type="aten__mul" op_name="aten__mul.17/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.313.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.146.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.60 (param_0.277: f32[], param_1.245: bf16[1024], param_2.147: bf16[16,1,1024], param_3.129: bf16[16,5120], param_4.67: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.129 = bf16[16,5120]{1,0} parameter(3)
  %convert.293.29 = f32[16,5120]{1,0} convert(bf16[16,5120]{1,0} %param_3.129), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.78.5 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.29), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.67 = bf16[16,1024]{1,0} parameter(4)
  %convert.316.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.67), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.79.11 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.29), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.147 = bf16[16,1,1024]{2,0,1} parameter(2)
  %bitcast.1030.11 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_2.147)
  %convert.298.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1030.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.78.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.79.11, f32[16,1024]{1,0} %convert.298.11), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.80.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.316.5, f32[16,1024]{1,0} %add.78.9), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.78.5, f32[16,1024]{1,0} %add.80.5), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.175 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.81.3, f32[16,1024]{1,0} %add.81.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_150 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.15 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.175, f32[] %constant_150), dimensions={1}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_149 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.198 = f32[16]{0} broadcast(f32[] %constant_149), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.174 = f32[16]{0} multiply(f32[16]{0} %reduce.15, f32[16]{0} %broadcast.198), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.277 = f32[] parameter(0)
  %broadcast.197 = f32[16]{0} broadcast(f32[] %param_0.277), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95 = f32[16]{0} add(f32[16]{0} %multiply.174, f32[16]{0} %broadcast.197), metadata={op_type="aten__add" op_name="aten__add.32/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.36 = f32[16]{0} rsqrt(f32[16]{0} %add.95), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.195 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.36), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.33/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.173 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.81.3, f32[16,1024]{1,0} %broadcast.195), metadata={op_type="aten__mul" op_name="aten__mul.33/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.245 = bf16[1024]{0} parameter(1)
  %convert.317.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.245), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.151.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.317.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.34/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.147.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.173, f32[16,1024]{1,0} %broadcast.151.1), metadata={op_type="aten__mul" op_name="aten__mul.34/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.318.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.147.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.3 (param_0.203: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.203 = bf16[16,6144]{1,0} parameter(0)
  %slice.82.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.203), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.319.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.82.1)
  %constant_1_6 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.379.4 = f32[] convert(bf16[] %constant_1_6)
  %broadcast.170.18 = f32[16,3072]{1,0} broadcast(f32[] %convert.379.4), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.16.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.319.8)
  %convert.323.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.16.5)
  %exponential.16.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.323.3)
  %convert.324.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.16.1)
  %add.82.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.170.18, f32[16,3072]{1,0} %convert.324.3)
  %divide.16.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.170.18, f32[16,3072]{1,0} %add.82.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.148.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.319.8, f32[16,3072]{1,0} %divide.16.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.83.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.203), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.325.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.83.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.149.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.148.5, f32[16,3072]{1,0} %convert.325.1), metadata={op_type="aten__mul" op_name="aten__mul.35/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.327.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.149.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.58 (param_0.283: f32[], param_1.253: bf16[1024], param_2.158: bf16[16,1,1024], param_3.146: bf16[16,5120], param_4.86: bf16[16,1024], param_5.35: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.146 = bf16[16,5120]{1,0} parameter(3)
  %convert.293.47 = f32[16,5120]{1,0} convert(bf16[16,5120]{1,0} %param_3.146), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.77.5 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.47), slice={[0:16], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.35 = bf16[16,1024]{1,0} parameter(5)
  %convert.328.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.35), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.78.9 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.47), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.86 = bf16[16,1024]{1,0} parameter(4)
  %convert.316.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.86), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.79.15 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.47), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.158 = bf16[16,1,1024]{2,0,1} parameter(2)
  %bitcast.1030.15 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_2.158)
  %convert.298.15 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1030.15), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.78.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.79.15, f32[16,1024]{1,0} %convert.298.15), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.80.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.316.9, f32[16,1024]{1,0} %add.78.13), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.78.9, f32[16,1024]{1,0} %add.80.9), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.83.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.328.5, f32[16,1024]{1,0} %add.81.7), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.84.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.77.5, f32[16,1024]{1,0} %add.83.5), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.181 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.84.3, f32[16,1024]{1,0} %add.84.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_155 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.17 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.181, f32[] %constant_155), dimensions={1}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_154 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.204 = f32[16]{0} broadcast(f32[] %constant_154), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.180 = f32[16]{0} multiply(f32[16]{0} %reduce.17, f32[16]{0} %broadcast.204), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.283 = f32[] parameter(0)
  %broadcast.203 = f32[16]{0} broadcast(f32[] %param_0.283), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98 = f32[16]{0} add(f32[16]{0} %multiply.180, f32[16]{0} %broadcast.203), metadata={op_type="aten__add" op_name="aten__add.50/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.38 = f32[16]{0} rsqrt(f32[16]{0} %add.98), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.202 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.38), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.51/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.179 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.84.3, f32[16,1024]{1,0} %broadcast.202), metadata={op_type="aten__mul" op_name="aten__mul.51/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.253 = bf16[1024]{0} parameter(1)
  %convert.329.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.253), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.155.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.329.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.52/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.151.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.179, f32[16,1024]{1,0} %broadcast.155.1), metadata={op_type="aten__mul" op_name="aten__mul.52/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.332.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.151.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.2 (param_0.202: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.202 = bf16[16,6144]{1,0} parameter(0)
  %slice.84.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.202), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.333.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.84.1)
  %constant_1_5 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.379.3 = f32[] convert(bf16[] %constant_1_5)
  %broadcast.170.16 = f32[16,3072]{1,0} broadcast(f32[] %convert.379.3), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.17.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.333.8)
  %convert.338.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.17.5)
  %exponential.17.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.338.3)
  %convert.339.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.17.1)
  %add.85.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.170.16, f32[16,3072]{1,0} %convert.339.3)
  %divide.17.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.170.16, f32[16,3072]{1,0} %add.85.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.152.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.333.8, f32[16,3072]{1,0} %divide.17.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.86.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.202), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.340.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.86.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.153.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.152.5, f32[16,3072]{1,0} %convert.340.1), metadata={op_type="aten__mul" op_name="aten__mul.53/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.341.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.153.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.56 (param_0.274: f32[], param_1.241: bf16[1024], param_2.161: bf16[16,1024], param_3.150: bf16[16,5120], param_4.89: bf16[16,1,1024], param_5.40: bf16[16,1024], param_6.25: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.150 = bf16[16,5120]{1,0} parameter(3)
  %convert.293.23 = f32[16,5120]{1,0} convert(bf16[16,5120]{1,0} %param_3.150), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.76.5 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.23), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.161 = bf16[16,1024]{1,0} parameter(2)
  %convert.342.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.161), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.77.9 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.23), slice={[0:16], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.25 = bf16[16,1024]{1,0} parameter(6)
  %convert.328.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_6.25), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.78.13 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.23), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.40 = bf16[16,1024]{1,0} parameter(5)
  %convert.316.13 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.40), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.79.19 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.23), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.89 = bf16[16,1,1024]{2,0,1} parameter(4)
  %bitcast.1030.19 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_4.89)
  %convert.298.19 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1030.19), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.78.17 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.79.19, f32[16,1024]{1,0} %convert.298.19), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.80.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.316.13, f32[16,1024]{1,0} %add.78.17), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.78.13, f32[16,1024]{1,0} %add.80.13), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.83.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.328.9, f32[16,1024]{1,0} %add.81.11), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.84.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.77.9, f32[16,1024]{1,0} %add.83.9), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.86.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.342.5, f32[16,1024]{1,0} %add.84.7), metadata={op_type="aten__add" op_name="aten__add.54/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.87.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.76.5, f32[16,1024]{1,0} %add.86.5), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.188 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.87.3, f32[16,1024]{1,0} %add.87.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_160 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.19 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.188, f32[] %constant_160), dimensions={1}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_159 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.210 = f32[16]{0} broadcast(f32[] %constant_159), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.187 = f32[16]{0} multiply(f32[16]{0} %reduce.19, f32[16]{0} %broadcast.210), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.274 = f32[] parameter(0)
  %broadcast.209 = f32[16]{0} broadcast(f32[] %param_0.274), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.100 = f32[16]{0} add(f32[16]{0} %multiply.187, f32[16]{0} %broadcast.209), metadata={op_type="aten__add" op_name="aten__add.68/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.40 = f32[16]{0} rsqrt(f32[16]{0} %add.100), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.208 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.69/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.186 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.87.3, f32[16,1024]{1,0} %broadcast.208), metadata={op_type="aten__mul" op_name="aten__mul.69/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.241 = bf16[1024]{0} parameter(1)
  %convert.343.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.241), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.158.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.343.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.70/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.155.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.186, f32[16,1024]{1,0} %broadcast.158.1), metadata={op_type="aten__mul" op_name="aten__mul.70/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.344.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.155.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.1 (param_0.204: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.204 = bf16[16,6144]{1,0} parameter(0)
  %slice.88.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.204), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.345.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.88.1)
  %constant_1_1 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.379.5 = f32[] convert(bf16[] %constant_1_1)
  %broadcast.170.14 = f32[16,3072]{1,0} broadcast(f32[] %convert.379.5), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.18.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.345.8)
  %convert.349.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.18.5)
  %exponential.18.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.349.3)
  %convert.350.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.18.1)
  %add.88.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.170.14, f32[16,3072]{1,0} %convert.350.3)
  %divide.18.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.170.14, f32[16,3072]{1,0} %add.88.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.156.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.345.8, f32[16,3072]{1,0} %divide.18.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.89.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.204), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.351.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.89.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.157.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.156.5, f32[16,3072]{1,0} %convert.351.1), metadata={op_type="aten__mul" op_name="aten__mul.71/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.353.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.157.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.54 (param_0.280: f32[], param_1.249: bf16[1024], param_2.163: bf16[16,1024], param_3.152: bf16[16,5120], param_4.90: bf16[16,1024], param_5.42: bf16[16,1,1024], param_6.29: bf16[16,1024], param_7.27: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.152 = bf16[16,5120]{1,0} parameter(3)
  %convert.293.37 = f32[16,5120]{1,0} convert(bf16[16,5120]{1,0} %param_3.152), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.75.5 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.37), slice={[0:16], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.90 = bf16[16,1024]{1,0} parameter(4)
  %convert.354.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.90), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.76.9 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.37), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.163 = bf16[16,1024]{1,0} parameter(2)
  %convert.342.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.163), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.77.11 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.37), slice={[0:16], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_7.27 = bf16[16,1024]{1,0} parameter(7)
  %convert.328.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_7.27), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.78.15 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.37), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.29 = bf16[16,1024]{1,0} parameter(6)
  %convert.316.15 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_6.29), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.79.21 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.37), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.42 = bf16[16,1,1024]{2,0,1} parameter(5)
  %bitcast.1030.21 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_5.42)
  %convert.298.21 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1030.21), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.78.19 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.79.21, f32[16,1024]{1,0} %convert.298.21), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.80.15 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.316.15, f32[16,1024]{1,0} %add.78.19), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.78.15, f32[16,1024]{1,0} %add.80.15), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.83.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.328.11, f32[16,1024]{1,0} %add.81.13), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.84.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.77.11, f32[16,1024]{1,0} %add.83.11), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.86.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.342.9, f32[16,1024]{1,0} %add.84.9), metadata={op_type="aten__add" op_name="aten__add.54/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.87.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.76.9, f32[16,1024]{1,0} %add.86.9), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.89.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.354.5, f32[16,1024]{1,0} %add.87.7), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.75.5, f32[16,1024]{1,0} %add.89.5), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.194 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.90.3, f32[16,1024]{1,0} %add.90.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_165 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.21 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.194, f32[] %constant_165), dimensions={1}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_164 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.218 = f32[16]{0} broadcast(f32[] %constant_164), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.193 = f32[16]{0} multiply(f32[16]{0} %reduce.21, f32[16]{0} %broadcast.218), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.280 = f32[] parameter(0)
  %broadcast.216 = f32[16]{0} broadcast(f32[] %param_0.280), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.102 = f32[16]{0} add(f32[16]{0} %multiply.193, f32[16]{0} %broadcast.216), metadata={op_type="aten__add" op_name="aten__add.86/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.42 = f32[16]{0} rsqrt(f32[16]{0} %add.102), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.215 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.42), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.87/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.192 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.90.3, f32[16,1024]{1,0} %broadcast.215), metadata={op_type="aten__mul" op_name="aten__mul.87/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.249 = bf16[1024]{0} parameter(1)
  %convert.355.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.249), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.161.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.355.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.88/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.158.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.192, f32[16,1024]{1,0} %broadcast.161.1), metadata={op_type="aten__mul" op_name="aten__mul.88/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.356.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.158.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert (param_0.200: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.200 = bf16[16,6144]{1,0} parameter(0)
  %slice.90.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.200), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.357.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.90.1)
  %constant_1_3 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.379.1 = f32[] convert(bf16[] %constant_1_3)
  %broadcast.170.12 = f32[16,3072]{1,0} broadcast(f32[] %convert.379.1), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.19.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.357.8)
  %convert.362.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.19.5)
  %exponential.19.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.362.3)
  %convert.363.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.19.1)
  %add.91.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.170.12, f32[16,3072]{1,0} %convert.363.3)
  %divide.19.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.170.12, f32[16,3072]{1,0} %add.91.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.159.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.357.8, f32[16,3072]{1,0} %divide.19.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.200), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.364.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.91.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.160.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.159.5, f32[16,3072]{1,0} %convert.364.1), metadata={op_type="aten__mul" op_name="aten__mul.89/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.365.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.160.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.52 (param_0.266: f32[], param_1.251: bf16[16,1024], param_2.155: bf16[1024], param_3.148: bf16[16,1024], param_4.87: bf16[16,5120], param_5.36: bf16[16,1024], param_6.20: bf16[16,1,1024], param_7.16: bf16[16,1024], param_8.4: bf16[16,1024]) -> bf16[16,1024] {
  %param_1.251 = bf16[16,1024]{1,0} parameter(1)
  %convert.366.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.251), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.87 = bf16[16,5120]{1,0} parameter(4)
  %convert.293.41 = f32[16,5120]{1,0} convert(bf16[16,5120]{1,0} %param_4.87), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.75.7 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.41), slice={[0:16], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.36 = bf16[16,1024]{1,0} parameter(5)
  %convert.354.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.36), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.76.11 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.41), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.148 = bf16[16,1024]{1,0} parameter(3)
  %convert.342.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.148), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.77.7 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.41), slice={[0:16], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_8.4 = bf16[16,1024]{1,0} parameter(8)
  %convert.328.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_8.4), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.78.11 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.41), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_7.16 = bf16[16,1024]{1,0} parameter(7)
  %convert.316.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_7.16), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.79.17 = f32[16,1024]{1,0} slice(f32[16,5120]{1,0} %convert.293.41), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.20 = bf16[16,1,1024]{2,0,1} parameter(6)
  %bitcast.1030.17 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_6.20)
  %convert.298.17 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1030.17), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.78.15 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.79.17, f32[16,1024]{1,0} %convert.298.17), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.80.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.316.11, f32[16,1024]{1,0} %add.78.15), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.78.11, f32[16,1024]{1,0} %add.80.11), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.83.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.328.7, f32[16,1024]{1,0} %add.81.9), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.84.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.77.7, f32[16,1024]{1,0} %add.83.7), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.86.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.342.11, f32[16,1024]{1,0} %add.84.5), metadata={op_type="aten__add" op_name="aten__add.54/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.87.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.76.11, f32[16,1024]{1,0} %add.86.11), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.89.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.354.7, f32[16,1024]{1,0} %add.87.9), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.75.7, f32[16,1024]{1,0} %add.89.7), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.366.3, f32[16,1024]{1,0} %add.90.5), metadata={op_type="aten__add" op_name="aten__add.90/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.200 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.92.3, f32[16,1024]{1,0} %add.92.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_170 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.23 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.200, f32[] %constant_170), dimensions={1}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_169 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.226 = f32[16]{0} broadcast(f32[] %constant_169), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.199 = f32[16]{0} multiply(f32[16]{0} %reduce.23, f32[16]{0} %broadcast.226), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.266 = f32[] parameter(0)
  %broadcast.224 = f32[16]{0} broadcast(f32[] %param_0.266), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.104 = f32[16]{0} add(f32[16]{0} %multiply.199, f32[16]{0} %broadcast.224), metadata={op_type="aten__add" op_name="aten__add.91/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.44 = f32[16]{0} rsqrt(f32[16]{0} %add.104), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.223 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.44), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.92/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.198 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.92.3, f32[16,1024]{1,0} %broadcast.223), metadata={op_type="aten__mul" op_name="aten__mul.92/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.155 = bf16[1024]{0} parameter(2)
  %convert.369.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.155), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.164.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.369.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.93/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.162.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.198, f32[16,1024]{1,0} %broadcast.164.1), metadata={op_type="aten__mul" op_name="aten__mul.93/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.370.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.162.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_slice_computation (param_0.288: bf16[16,4096]) -> bf16[16,1024] {
  %param_0.288 = bf16[16,4096]{1,0} parameter(0)
  ROOT %slice.97.1 = bf16[16,1024]{1,0} slice(bf16[16,4096]{1,0} %param_0.288), slice={[0:16], [3072:4096]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%triton_softmax_computation.7 (param_0.199: f32[], param_1.205: bf16[16,4096]) -> f32[16,8,128] {
  %param_1.205 = bf16[16,4096]{1,0} parameter(1)
  %slice.92.1 = bf16[16,1024]{1,0} slice(bf16[16,4096]{1,0} %param_1.205), slice={[0:16], [2048:3072]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1272.3 = bf16[16,8,128]{2,1,0} bitcast(bf16[16,1024]{1,0} %slice.92.1)
  %convert.372.3 = f32[16,8,128]{2,1,0} convert(bf16[16,8,128]{2,1,0} %bitcast.1272.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.121 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %convert.372.3, f32[16,8,128]{2,1,0} %convert.372.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_81 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.7 = f32[16,8]{1,0} reduce(f32[16,8,128]{2,1,0} %multiply.121, f32[] %constant_81), dimensions={2}, to_apply=%AddComputation.56, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_82 = f32[] constant(0.0078125), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.123 = f32[16,8]{1,0} broadcast(f32[] %constant_82), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.122 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %reduce.7, f32[16,8]{1,0} %broadcast.123), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.199 = f32[] parameter(0)
  %broadcast.125 = f32[16,8]{1,0} broadcast(f32[] %param_0.199), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.94/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.69 = f32[16,8]{1,0} add(f32[16,8]{1,0} %multiply.122, f32[16,8]{1,0} %broadcast.125), metadata={op_type="aten__add" op_name="aten__add.94/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.28 = f32[16,8]{1,0} rsqrt(f32[16,8]{1,0} %add.69), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.126 = f32[16,8,128]{2,1,0} broadcast(f32[16,8]{1,0} %rsqrt.28), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.95/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %multiply.123 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %convert.372.3, f32[16,8,128]{2,1,0} %broadcast.126), metadata={op_type="aten__mul" op_name="aten__mul.95/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_concatenate (param_0.272: f32[16,8,128], param_1.239: bf16[128], param_2.138: bf16[40960,128], param_3.117: s32[16]) -> bf16[16,8,128] {
  %param_0.272 = f32[16,8,128]{2,1,0} parameter(0)
  %param_1.239 = bf16[128]{0} parameter(1)
  %convert.373.11 = f32[128]{0} convert(bf16[128]{0} %param_1.239), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.165.14 = f32[16,8,128]{2,1,0} broadcast(f32[128]{0} %convert.373.11), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.96/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.164.14 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %param_0.272, f32[16,8,128]{2,1,0} %broadcast.165.14), metadata={op_type="aten__mul" op_name="aten__mul.96/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.7 = f32[16,8,64]{2,1,0} slice(f32[16,8,128]{2,1,0} %multiply.164.14), slice={[0:16], [0:8], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.138 = bf16[40960,128]{1,0} parameter(2)
  %param_3.117 = s32[16]{0} parameter(3)
  %bitcast.1288.3 = s32[16,1]{1,0} bitcast(s32[16]{0} %param_3.117)
  %gather.1.3 = bf16[16,1,128]{2,0,1} gather(bf16[40960,128]{1,0} %param_2.138, s32[16,1]{1,0} %bitcast.1288.3), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1291.17 = bf16[16,128]{1,0} bitcast(bf16[16,1,128]{2,0,1} %gather.1.3)
  %convert.375.17 = f32[16,128]{1,0} convert(bf16[16,128]{1,0} %bitcast.1291.17), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.7 = f32[16,64]{1,0} slice(f32[16,128]{1,0} %convert.375.17), slice={[0:16], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.166.12 = f32[16,8,64]{2,1,0} broadcast(f32[16,64]{1,0} %slice.94.7), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.97/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.165.7 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.93.7, f32[16,8,64]{2,1,0} %broadcast.166.12), metadata={op_type="aten__mul" op_name="aten__mul.97/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.95.7 = f32[16,8,64]{2,1,0} slice(f32[16,8,128]{2,1,0} %multiply.164.14), slice={[0:16], [0:8], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.96.7 = f32[16,64]{1,0} slice(f32[16,128]{1,0} %convert.375.17), slice={[0:16], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.168.8 = f32[16,8,64]{2,1,0} broadcast(f32[16,64]{1,0} %slice.96.7), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.98/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.166.5 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.95.7, f32[16,8,64]{2,1,0} %broadcast.168.8), metadata={op_type="aten__mul" op_name="aten__mul.98/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %subtract.2.5 = f32[16,8,64]{2,1,0} subtract(f32[16,8,64]{2,1,0} %multiply.165.7, f32[16,8,64]{2,1,0} %multiply.166.5), metadata={op_type="aten__sub" op_name="aten__sub.99/aten__sub" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.376.3 = bf16[16,8,64]{2,1,0} convert(f32[16,8,64]{2,1,0} %subtract.2.5)
  %multiply.167.7 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.95.7, f32[16,8,64]{2,1,0} %broadcast.166.12), metadata={op_type="aten__mul" op_name="aten__mul.100/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.169.5 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.93.7, f32[16,8,64]{2,1,0} %broadcast.168.8), metadata={op_type="aten__mul" op_name="aten__mul.101/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.5 = f32[16,8,64]{2,1,0} add(f32[16,8,64]{2,1,0} %multiply.167.7, f32[16,8,64]{2,1,0} %multiply.169.5), metadata={op_type="aten__add" op_name="aten__add.102/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.377.3 = bf16[16,8,64]{2,1,0} convert(f32[16,8,64]{2,1,0} %add.93.5)
  ROOT %concatenate.14.1 = bf16[16,8,128]{2,1,0} concatenate(bf16[16,8,64]{2,1,0} %convert.376.3, bf16[16,8,64]{2,1,0} %convert.377.3), dimensions={2}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_slice (param_0.1: bf16[2,4233,16,8,128]) -> bf16[69353472] {
  %param_0.1 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  %bitcast.1332.1 = bf16[138706944]{0} bitcast(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.1)
  ROOT %slice.99.1 = bf16[69353472]{0} slice(bf16[138706944]{0} %bitcast.1332.1), slice={[69353472:138706944]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%wrapped_slice_computation.1 (param_0.289: bf16[2,4233,16,8,128]) -> bf16[1,4233,16,8,128] {
  %param_0.289 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  ROOT %slice.98.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} slice(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.289), slice={[0:1], [0:4233], [0:16], [0:8], [0:128]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%command_buffer (p: bf16[151936,1024], p.1: s32[16], p.2: bf16[1024,2048], p.3: bf16[1024,2048], p.4: bf16[1024,2048], p.5: bf16[1024,2048], p.6: bf16[1024,2048], p.7: f32[], p.8: bf16[1024], p.9: bf16[6144,1024], p.10: bf16[1024,3072], p.11: bf16[1024], p.12: bf16[6144,1024], p.13: bf16[1024,3072], p.14: bf16[1024], p.15: bf16[6144,1024], p.16: bf16[1024,3072], p.17: bf16[1024], p.18: bf16[6144,1024], p.19: bf16[1024,3072], p.20: bf16[1024], p.21: bf16[6144,1024], p.22: bf16[1024,3072], p.23: bf16[1024], p.24: bf16[4096,1024], p.25: bf16[128], p.26: bf16[40960,128], p.27: s32[16], p.28: bf16[2,4233,16,8,128]) -> (bf16[16,8,128], bf16[16,8,128], bf16[4233,16,8,128], bf16[1,4233,16,8,128]) {
  %p = bf16[151936,1024]{1,0} parameter(0)
  %p.1 = s32[16]{0} parameter(1)
  %p.2 = bf16[1024,2048]{1,0} parameter(2)
  %p.3 = bf16[1024,2048]{1,0} parameter(3)
  %p.4 = bf16[1024,2048]{1,0} parameter(4)
  %p.5 = bf16[1024,2048]{1,0} parameter(5)
  %p.6 = bf16[1024,2048]{1,0} parameter(6)
  %p.7 = f32[] parameter(7)
  %p.8 = bf16[1024]{0} parameter(8)
  %p.9 = bf16[6144,1024]{1,0} parameter(9)
  %p.10 = bf16[1024,3072]{1,0} parameter(10)
  %p.11 = bf16[1024]{0} parameter(11)
  %p.12 = bf16[6144,1024]{1,0} parameter(12)
  %p.13 = bf16[1024,3072]{1,0} parameter(13)
  %p.14 = bf16[1024]{0} parameter(14)
  %p.15 = bf16[6144,1024]{1,0} parameter(15)
  %p.16 = bf16[1024,3072]{1,0} parameter(16)
  %p.17 = bf16[1024]{0} parameter(17)
  %p.18 = bf16[6144,1024]{1,0} parameter(18)
  %p.19 = bf16[1024,3072]{1,0} parameter(19)
  %p.20 = bf16[1024]{0} parameter(20)
  %p.21 = bf16[6144,1024]{1,0} parameter(21)
  %p.22 = bf16[1024,3072]{1,0} parameter(22)
  %p.23 = bf16[1024]{0} parameter(23)
  %p.24 = bf16[4096,1024]{1,0} parameter(24)
  %p.25 = bf16[128]{0} parameter(25)
  %p.26 = bf16[40960,128]{1,0} parameter(26)
  %p.27 = s32[16]{0} parameter(27)
  %p.28 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(28)
  %loop_gather_fusion = bf16[16,1,1024]{2,0,1} fusion(bf16[151936,1024]{1,0} %p, s32[16]{0} %p.1), kind=kLoop, calls=%fused_gather, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_concatenate = bf16[5120,2048]{1,0} fusion(bf16[1024,2048]{1,0} %p.2, bf16[1024,2048]{1,0} %p.3, bf16[1024,2048]{1,0} %p.4, bf16[1024,2048]{1,0} %p.5, bf16[1024,2048]{1,0} %p.6), kind=kLoop, calls=%wrapped_concatenate_computation, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %gemm_fusion_dot.19.0 = bf16[16,5120]{1,0} fusion(bf16[5120,2048]{1,0} %wrapped_concatenate), kind=kCustom, calls=%gemm_fusion_dot.19_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton_gemm","triton_gemm_config":{"block_m":"128","block_n":"16","block_k":"128","split_k":"1","num_stages":"4","num_warps":"4","num_ctas":"1"}},"force_earliest_schedule":false}
  %fusion.77 = bf16[16,1024]{1,0} fusion(f32[] %p.7, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,5120]{1,0} %gemm_fusion_dot.19.0, bf16[1024]{0} %p.8), kind=kCustom, calls=%fused_computation.62, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","256"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.11.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.77, bf16[6144,1024]{1,0} %p.9), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.11 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.11.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.4 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.11), kind=kLoop, calls=%fused_convert.4, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.12.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.4, bf16[1024,3072]{1,0} %p.10), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.1.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.12.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.75 = bf16[16,1024]{1,0} fusion(f32[] %p.7, bf16[1024]{0} %p.11, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,5120]{1,0} %gemm_fusion_dot.19.0, bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.60, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","256"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.13.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.75, bf16[6144,1024]{1,0} %p.12), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.2.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.13.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.3 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.2.0), kind=kLoop, calls=%fused_convert.3, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.14.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.3, bf16[1024,3072]{1,0} %p.13), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.3.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.14.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.73 = bf16[16,1024]{1,0} fusion(f32[] %p.7, bf16[1024]{0} %p.14, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,5120]{1,0} %gemm_fusion_dot.19.0, bf16[16,1024]{1,0} %get-tuple-element.1.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.3.0), kind=kCustom, calls=%fused_computation.58, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.15.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.73, bf16[6144,1024]{1,0} %p.15), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.4.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.15.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.2 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.4.0), kind=kLoop, calls=%fused_convert.2, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.16.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.2, bf16[1024,3072]{1,0} %p.16), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.5.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.16.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.71 = bf16[16,1024]{1,0} fusion(f32[] %p.7, bf16[1024]{0} %p.17, bf16[16,1024]{1,0} %get-tuple-element.5.0, bf16[16,5120]{1,0} %gemm_fusion_dot.19.0, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.1.0, bf16[16,1024]{1,0} %get-tuple-element.3.0), kind=kCustom, calls=%fused_computation.56, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.17.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.71, bf16[6144,1024]{1,0} %p.18), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.6.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.17.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.1 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.6.0), kind=kLoop, calls=%fused_convert.1, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.18.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.1, bf16[1024,3072]{1,0} %p.19), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.7.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.18.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.69 = bf16[16,1024]{1,0} fusion(f32[] %p.7, bf16[1024]{0} %p.20, bf16[16,1024]{1,0} %get-tuple-element.5.0, bf16[16,5120]{1,0} %gemm_fusion_dot.19.0, bf16[16,1024]{1,0} %get-tuple-element.7.0, /*index=5*/bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,1024]{1,0} %get-tuple-element.1.0, bf16[16,1024]{1,0} %get-tuple-element.3.0), kind=kCustom, calls=%fused_computation.54, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.19.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.69, bf16[6144,1024]{1,0} %p.21), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.8.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.19.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.8.0), kind=kLoop, calls=%fused_convert, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.20.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion, bf16[1024,3072]{1,0} %p.22), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.9.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.20.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.67 = bf16[16,1024]{1,0} fusion(f32[] %p.7, bf16[16,1024]{1,0} %get-tuple-element.9.0, bf16[1024]{0} %p.23, bf16[16,1024]{1,0} %get-tuple-element.5.0, bf16[16,5120]{1,0} %gemm_fusion_dot.19.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.7.0, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,1024]{1,0} %get-tuple-element.1.0, bf16[16,1024]{1,0} %get-tuple-element.3.0), kind=kCustom, calls=%fused_computation.52, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.21.0 = (bf16[16,4096]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.67, bf16[4096,1024]{1,0} %p.24), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"4194304","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.10.0 = bf16[16,4096]{1,0} get-tuple-element((bf16[16,4096]{1,0}, s8[4194304]{0}) %custom-call.21.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_slice = bf16[16,1024]{1,0} fusion(bf16[16,4096]{1,0} %get-tuple-element.10.0), kind=kLoop, calls=%wrapped_slice_computation, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %triton_softmax.7.0 = f32[16,8,128]{2,1,0} fusion(f32[] %p.7, bf16[16,4096]{1,0} %get-tuple-element.10.0), kind=kCustom, calls=%triton_softmax_computation.7, metadata={op_type="aten__mul" op_name="aten__mul.95/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1","128"]}],"num_warps":"1"}},"force_earliest_schedule":false}
  %input_concatenate_fusion = bf16[16,8,128]{2,1,0} fusion(f32[16,8,128]{2,1,0} %triton_softmax.7.0, bf16[128]{0} %p.25, bf16[40960,128]{1,0} %p.26, s32[16]{0} %p.27), kind=kInput, calls=%fused_concatenate, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1324.0 = bf16[16,8,128]{2,1,0} bitcast(bf16[16,1024]{1,0} %wrapped_slice)
  %loop_slice_fusion = bf16[69353472]{0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.28), kind=kLoop, calls=%fused_slice, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  %bitcast.1336.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[69353472]{0} %loop_slice_fusion)
  %wrapped_slice.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.28), kind=kLoop, calls=%wrapped_slice_computation.1, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  ROOT %tuple = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) tuple(bf16[16,8,128]{2,1,0} %input_concatenate_fusion, bf16[16,8,128]{2,1,0} %bitcast.1324.0, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1336.0, bf16[1,4233,16,8,128]{4,3,2,1,0} %wrapped_slice.1)
}

ENTRY %SyncTensorsGraph.515 (p0.1.0: bf16[128], p1.4.0: f32[], p2.6.0: bf16[4096,1024], p3.8.0: bf16[1024], p4.22.0: s32[16], p5.24.0: bf16[151936,1024], p6.28.0: bf16[1024,2048], p7.44.0: bf16[1024,3072], p8.46.0: bf16[6144,1024], p9.48.0: bf16[1024], p10.100.0: bf16[1024,2048], p11.116.0: bf16[1024,3072], p12.118.0: bf16[6144,1024], p13.120.0: bf16[1024], p14.172.0: bf16[1024,2048], p15.188.0: bf16[1024,3072], p16.190.0: bf16[6144,1024], p17.192.0: bf16[1024], p18.244.0: bf16[1024,2048], p19.260.0: bf16[1024,3072], p20.262.0: bf16[6144,1024], p21.264.0: bf16[1024], p22.316.0: bf16[1024,2048], p23.332.0: bf16[1024,3072], p24.334.0: bf16[6144,1024], p25.336.0: bf16[1024], p26.460.0: s32[16], p27.461.0: bf16[40960,128], p28.505.0: bf16[2,4233,16,8,128]) -> (bf16[16,8,128], bf16[16,8,128], bf16[4233,16,8,128], bf16[4233,16,8,128]) {
  %p1.4.0 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %p28.505.0 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(28), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p27.461.0 = bf16[40960,128]{1,0} parameter(27), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p26.460.0 = s32[16]{0} parameter(26), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p25.336.0 = bf16[1024]{0} parameter(25), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p24.334.0 = bf16[6144,1024]{1,0} parameter(24), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p23.332.0 = bf16[1024,3072]{1,0} parameter(23), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p22.316.0 = bf16[1024,2048]{1,0} parameter(22), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p21.264.0 = bf16[1024]{0} parameter(21), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p20.262.0 = bf16[6144,1024]{1,0} parameter(20), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p19.260.0 = bf16[1024,3072]{1,0} parameter(19), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p18.244.0 = bf16[1024,2048]{1,0} parameter(18), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p17.192.0 = bf16[1024]{0} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p16.190.0 = bf16[6144,1024]{1,0} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p15.188.0 = bf16[1024,3072]{1,0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p14.172.0 = bf16[1024,2048]{1,0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p13.120.0 = bf16[1024]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p12.118.0 = bf16[6144,1024]{1,0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p11.116.0 = bf16[1024,3072]{1,0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p10.100.0 = bf16[1024,2048]{1,0} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p9.48.0 = bf16[1024]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p8.46.0 = bf16[6144,1024]{1,0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p7.44.0 = bf16[1024,3072]{1,0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p6.28.0 = bf16[1024,2048]{1,0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p5.24.0 = bf16[151936,1024]{1,0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p4.22.0 = s32[16]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p3.8.0 = bf16[1024]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p2.6.0 = bf16[4096,1024]{1,0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p0.1.0 = bf16[128]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %call = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) call(bf16[151936,1024]{1,0} %p5.24.0, s32[16]{0} %p4.22.0, bf16[1024,2048]{1,0} %p22.316.0, bf16[1024,2048]{1,0} %p18.244.0, bf16[1024,2048]{1,0} %p14.172.0, /*index=5*/bf16[1024,2048]{1,0} %p10.100.0, bf16[1024,2048]{1,0} %p6.28.0, f32[] %p1.4.0, bf16[1024]{0} %p9.48.0, bf16[6144,1024]{1,0} %p8.46.0, /*index=10*/bf16[1024,3072]{1,0} %p7.44.0, bf16[1024]{0} %p13.120.0, bf16[6144,1024]{1,0} %p12.118.0, bf16[1024,3072]{1,0} %p11.116.0, bf16[1024]{0} %p17.192.0, /*index=15*/bf16[6144,1024]{1,0} %p16.190.0, bf16[1024,3072]{1,0} %p15.188.0, bf16[1024]{0} %p21.264.0, bf16[6144,1024]{1,0} %p20.262.0, bf16[1024,3072]{1,0} %p19.260.0, /*index=20*/bf16[1024]{0} %p25.336.0, bf16[6144,1024]{1,0} %p24.334.0, bf16[1024,3072]{1,0} %p23.332.0, bf16[1024]{0} %p3.8.0, bf16[4096,1024]{1,0} %p2.6.0, /*index=25*/bf16[128]{0} %p0.1.0, bf16[40960,128]{1,0} %p27.461.0, s32[16]{0} %p26.460.0, bf16[2,4233,16,8,128]{4,3,2,1,0} %p28.505.0), to_apply=%command_buffer
  %get-tuple-element.13 = bf16[16,8,128]{2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=0
  %get-tuple-element.14 = bf16[16,8,128]{2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=1
  %get-tuple-element.15 = bf16[4233,16,8,128]{3,2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=2
  %get-tuple-element.16 = bf16[1,4233,16,8,128]{4,3,2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=3
  %bitcast.1329.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[1,4233,16,8,128]{4,3,2,1,0} %get-tuple-element.16)
  ROOT %tuple.514.0 = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0}) tuple(bf16[16,8,128]{2,1,0} %get-tuple-element.13, bf16[16,8,128]{2,1,0} %get-tuple-element.14, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1329.0, bf16[4233,16,8,128]{3,2,1,0} %get-tuple-element.15)
}

