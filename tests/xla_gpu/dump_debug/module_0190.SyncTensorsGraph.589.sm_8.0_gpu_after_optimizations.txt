HloModule SyncTensorsGraph.589, is_scheduled=true, entry_computation_layout={(bf16[128]{0}, f32[], bf16[4096,1024]{1,0}, bf16[1024]{0}, s32[16]{0}, /*index=5*/bf16[151936,1024]{1,0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=10*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=15*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=20*/bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, /*index=25*/bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=30*/s32[16]{0}, bf16[40960,128]{1,0}, bf16[2,4233,16,8,128]{4,3,2,1,0})->(bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0})}, frontend_attributes={fingerprint_before_lhs="f4571593db8ad5e4cafeb056918d9897"}

%fused_gather (param_0.9: bf16[151936,1024], param_1.271: s32[16]) -> bf16[16,1,1024] {
  %param_0.9 = bf16[151936,1024]{1,0} parameter(0)
  %param_1.271 = s32[16]{0} parameter(1)
  %convert.343.1 = s64[16]{0} convert(s32[16]{0} %param_1.271), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.344.1 = u32[16]{0} convert(s64[16]{0} %convert.343.1), metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1168.1 = u32[16,1]{1,0} bitcast(u32[16]{0} %convert.344.1)
  ROOT %gather.3 = bf16[16,1,1024]{2,0,1} gather(bf16[151936,1024]{1,0} %param_0.9, u32[16,1]{1,0} %bitcast.1168.1), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,1024}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_concatenate_computation (param_0.325: bf16[1024,2048], param_1.290: bf16[1024,2048], param_2.182: bf16[1024,2048], param_3.162: bf16[1024,2048], param_4.95: bf16[1024,2048], param_5.35: bf16[1024,2048]) -> bf16[6144,2048] {
  %param_0.325 = bf16[1024,2048]{1,0} parameter(0)
  %param_1.290 = bf16[1024,2048]{1,0} parameter(1)
  %param_2.182 = bf16[1024,2048]{1,0} parameter(2)
  %param_3.162 = bf16[1024,2048]{1,0} parameter(3)
  %param_4.95 = bf16[1024,2048]{1,0} parameter(4)
  %param_5.35 = bf16[1024,2048]{1,0} parameter(5)
  ROOT %concatenate.15.1 = bf16[6144,2048]{1,0} concatenate(bf16[1024,2048]{1,0} %param_0.325, bf16[1024,2048]{1,0} %param_1.290, bf16[1024,2048]{1,0} %param_2.182, bf16[1024,2048]{1,0} %param_3.162, bf16[1024,2048]{1,0} %param_4.95, /*index=5*/bf16[1024,2048]{1,0} %param_5.35), dimensions={0}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
}

%gemm_fusion_dot.23_computation (parameter_0: bf16[6144,2048]) -> bf16[16,6144] {
  %parameter_0 = bf16[6144,2048]{1,0} parameter(0)
  %constant_75 = bf16[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.65 = bf16[16,2048]{1,0} broadcast(bf16[] %constant_75), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %dot.25 = bf16[6144,16]{0,1} dot(bf16[6144,2048]{1,0} %parameter_0, bf16[16,2048]{1,0} %broadcast.65), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %bitcast.567 = bf16[16,6144]{1,0} bitcast(bf16[6144,16]{0,1} %dot.25), metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%AddComputation.58 (x.59: f32[], y.60: f32[]) -> f32[] {
  %y.60 = f32[] parameter(1)
  %x.59 = f32[] parameter(0)
  ROOT %add.89 = f32[] add(f32[] %x.59, f32[] %y.60)
}

%fused_computation.73 (param_0.297: f32[], param_1.254: bf16[16,1,1024], param_2.141: bf16[16,6144], param_3.111: bf16[1024]) -> bf16[16,1024] {
  %param_2.141 = bf16[16,6144]{1,0} parameter(2)
  %convert.342.24 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_2.141), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.9 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.24), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.254 = bf16[16,1,1024]{2,0,1} parameter(1)
  %bitcast.1171.9 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_1.254)
  %convert.345.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1171.9), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.94.9, f32[16,1024]{1,0} %convert.345.9), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.240 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.90.7, f32[16,1024]{1,0} %add.90.7), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_215 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.29 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.240, f32[] %constant_215), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_214 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.267 = f32[16]{0} broadcast(f32[] %constant_214), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.239 = f32[16]{0} multiply(f32[16]{0} %reduce.29, f32[16]{0} %broadcast.267), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.297 = f32[] parameter(0)
  %broadcast.266 = f32[16]{0} broadcast(f32[] %param_0.297), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.124 = f32[16]{0} add(f32[16]{0} %multiply.239, f32[16]{0} %broadcast.266), metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.53 = f32[16]{0} rsqrt(f32[16]{0} %add.124), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.265 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.53), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.15/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.238 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.90.7, f32[16,1024]{1,0} %broadcast.265), metadata={op_type="aten__mul" op_name="aten__mul.15/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.111 = bf16[1024]{0} parameter(3)
  %convert.346.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.111), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.167.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.346.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.16/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.167.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.238, f32[16,1024]{1,0} %broadcast.167.1), metadata={op_type="aten__mul" op_name="aten__mul.16/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.347.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.167.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.5 (param_0.221: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.221 = bf16[16,6144]{1,0} parameter(0)
  %slice.95.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.221), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.348.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.95.1)
  %constant_1_4 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.2 = f32[] convert(bf16[] %constant_1_4)
  %broadcast.194.24 = f32[16,3072]{1,0} broadcast(f32[] %convert.436.2), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.18.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.348.8)
  %convert.352.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.18.5)
  %exponential.18.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.352.3)
  %convert.353.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.18.1)
  %add.91.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.194.24, f32[16,3072]{1,0} %convert.353.3)
  %divide.18.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.194.24, f32[16,3072]{1,0} %add.91.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.168.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.348.8, f32[16,3072]{1,0} %divide.18.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.96.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.221), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.355.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.96.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.169.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.168.5, f32[16,3072]{1,0} %convert.355.1), metadata={op_type="aten__mul" op_name="aten__mul.17/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.356.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.169.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.71 (param_0.319: f32[], param_1.283: bf16[1024], param_2.172: bf16[16,1,1024], param_3.150: bf16[16,6144], param_4.79: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.150 = bf16[16,6144]{1,0} parameter(3)
  %convert.342.36 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_3.150), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.5 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.36), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.79 = bf16[16,1024]{1,0} parameter(4)
  %convert.357.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.79), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.11 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.36), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.172 = bf16[16,1,1024]{2,0,1} parameter(2)
  %bitcast.1171.11 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_2.172)
  %convert.345.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1171.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.94.11, f32[16,1024]{1,0} %convert.345.11), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.357.5, f32[16,1024]{1,0} %add.90.9), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.93.5, f32[16,1024]{1,0} %add.92.5), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.198 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.93.3, f32[16,1024]{1,0} %add.93.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_171 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.17 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.198, f32[] %constant_171), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_170 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.226 = f32[16]{0} broadcast(f32[] %constant_170), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.197 = f32[16]{0} multiply(f32[16]{0} %reduce.17, f32[16]{0} %broadcast.226), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.319 = f32[] parameter(0)
  %broadcast.225 = f32[16]{0} broadcast(f32[] %param_0.319), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.111 = f32[16]{0} add(f32[16]{0} %multiply.197, f32[16]{0} %broadcast.225), metadata={op_type="aten__add" op_name="aten__add.32/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.41 = f32[16]{0} rsqrt(f32[16]{0} %add.111), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.224 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.41), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.33/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.196 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.93.3, f32[16,1024]{1,0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul.33/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.283 = bf16[1024]{0} parameter(1)
  %convert.358.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.283), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.171.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.358.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.34/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.171.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.196, f32[16,1024]{1,0} %broadcast.171.1), metadata={op_type="aten__mul" op_name="aten__mul.34/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.359.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.171.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.4 (param_0.223: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.223 = bf16[16,6144]{1,0} parameter(0)
  %slice.97.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.223), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.360.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.97.1)
  %constant_1_6 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.4 = f32[] convert(bf16[] %constant_1_6)
  %broadcast.194.22 = f32[16,3072]{1,0} broadcast(f32[] %convert.436.4), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.19.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.360.8)
  %convert.365.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.19.5)
  %exponential.19.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.365.3)
  %convert.366.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.19.1)
  %add.94.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.194.22, f32[16,3072]{1,0} %convert.366.3)
  %divide.19.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.194.22, f32[16,3072]{1,0} %add.94.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.172.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.360.8, f32[16,3072]{1,0} %divide.19.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.98.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.223), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.367.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.98.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.173.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.172.5, f32[16,3072]{1,0} %convert.367.1), metadata={op_type="aten__mul" op_name="aten__mul.35/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.368.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.173.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.69 (param_0.316: f32[], param_1.279: bf16[1024], param_2.176: bf16[16,1024], param_3.153: bf16[16,6144], param_4.85: bf16[16,1,1024], param_5.23: bf16[16,1024]) -> bf16[16,1024] {
  %param_3.153 = bf16[16,6144]{1,0} parameter(3)
  %convert.342.30 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_3.153), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.5 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.30), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.176 = bf16[16,1024]{1,0} parameter(2)
  %convert.371.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.176), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.9 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.30), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.23 = bf16[16,1024]{1,0} parameter(5)
  %convert.357.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.23), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.15 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.30), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.85 = bf16[16,1,1024]{2,0,1} parameter(4)
  %bitcast.1171.15 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_4.85)
  %convert.345.15 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1171.15), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.13 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.94.15, f32[16,1024]{1,0} %convert.345.15), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.357.9, f32[16,1024]{1,0} %add.90.13), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.93.9, f32[16,1024]{1,0} %add.92.9), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.371.5, f32[16,1024]{1,0} %add.93.7), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.92.5, f32[16,1024]{1,0} %add.95.5), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.204 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.96.3, f32[16,1024]{1,0} %add.96.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_177 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.19 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.204, f32[] %constant_177), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_175 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.233 = f32[16]{0} broadcast(f32[] %constant_175), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.203 = f32[16]{0} multiply(f32[16]{0} %reduce.19, f32[16]{0} %broadcast.233), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.316 = f32[] parameter(0)
  %broadcast.232 = f32[16]{0} broadcast(f32[] %param_0.316), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.113 = f32[16]{0} add(f32[16]{0} %multiply.203, f32[16]{0} %broadcast.232), metadata={op_type="aten__add" op_name="aten__add.50/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.43 = f32[16]{0} rsqrt(f32[16]{0} %add.113), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.231 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.43), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.51/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.202 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.96.3, f32[16,1024]{1,0} %broadcast.231), metadata={op_type="aten__mul" op_name="aten__mul.51/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.279 = bf16[1024]{0} parameter(1)
  %convert.372.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.279), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.174.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.372.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.52/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.174.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.202, f32[16,1024]{1,0} %broadcast.174.1), metadata={op_type="aten__mul" op_name="aten__mul.52/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.374.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.174.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.3 (param_0.225: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.225 = bf16[16,6144]{1,0} parameter(0)
  %slice.99.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.225), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.375.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.99.1)
  %constant_1_1 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.6 = f32[] convert(bf16[] %constant_1_1)
  %broadcast.194.20 = f32[16,3072]{1,0} broadcast(f32[] %convert.436.6), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.20.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.375.8)
  %convert.381.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.20.5)
  %exponential.20.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.381.3)
  %convert.383.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.20.1)
  %add.97.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.194.20, f32[16,3072]{1,0} %convert.383.3)
  %divide.20.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.194.20, f32[16,3072]{1,0} %add.97.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.175.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.375.8, f32[16,3072]{1,0} %divide.20.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.100.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.225), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.385.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.100.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.176.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.175.5, f32[16,3072]{1,0} %convert.385.1), metadata={op_type="aten__mul" op_name="aten__mul.53/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.386.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.176.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_add (param_0.235: bf16[16,6144], param_1.281: bf16[16,1024], param_2.174: bf16[16,1024], param_3.152: bf16[16,1,1024], param_4.83: bf16[16,1024]) -> f32[16,1024] {
  %param_0.235 = bf16[16,6144]{1,0} parameter(0)
  %convert.342.14 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_0.235), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.3 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.14), slice={[0:16], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.281 = bf16[16,1024]{1,0} parameter(1)
  %convert.387.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.281), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.7 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.14), slice={[0:16], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.174 = bf16[16,1024]{1,0} parameter(2)
  %convert.371.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_2.174), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.7 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.14), slice={[0:16], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.83 = bf16[16,1024]{1,0} parameter(4)
  %convert.357.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.83), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.13 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.14), slice={[0:16], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.152 = bf16[16,1,1024]{2,0,1} parameter(3)
  %bitcast.1171.13 = bf16[16,1024]{1,0} bitcast(bf16[16,1,1024]{2,0,1} %param_3.152)
  %convert.345.13 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %bitcast.1171.13), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.94.13, f32[16,1024]{1,0} %convert.345.13), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.357.7, f32[16,1024]{1,0} %add.90.11), metadata={op_type="aten__add" op_name="aten__add.18/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.93.7, f32[16,1024]{1,0} %add.92.7), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.371.7, f32[16,1024]{1,0} %add.93.5), metadata={op_type="aten__add" op_name="aten__add.36/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.92.7, f32[16,1024]{1,0} %add.95.7), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.387.3, f32[16,1024]{1,0} %add.96.5), metadata={op_type="aten__add" op_name="aten__add.54/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %add.100.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.91.3, f32[16,1024]{1,0} %add.98.3), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.67 (param_0.307: f32[16,1024], param_1.267: f32[], param_2.154: bf16[1024]) -> bf16[16,1024] {
  %param_0.307 = f32[16,1024]{1,0} parameter(0)
  %multiply.210 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.307, f32[16,1024]{1,0} %param_0.307), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_182 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.21 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.210, f32[] %constant_182), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_181 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.239 = f32[16]{0} broadcast(f32[] %constant_181), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.209 = f32[16]{0} multiply(f32[16]{0} %reduce.21, f32[16]{0} %broadcast.239), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.267 = f32[] parameter(1)
  %broadcast.238 = f32[16]{0} broadcast(f32[] %param_1.267), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.116 = f32[16]{0} add(f32[16]{0} %multiply.209, f32[16]{0} %broadcast.238), metadata={op_type="aten__add" op_name="aten__add.68/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.45 = f32[16]{0} rsqrt(f32[16]{0} %add.116), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.237 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.45), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.69/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.208 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_0.307, f32[16,1024]{1,0} %broadcast.237), metadata={op_type="aten__mul" op_name="aten__mul.69/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.154 = bf16[1024]{0} parameter(2)
  %convert.390.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.154), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.177.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.390.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.70/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.177.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.208, f32[16,1024]{1,0} %broadcast.177.1), metadata={op_type="aten__mul" op_name="aten__mul.70/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.391.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.177.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.2 (param_0.224: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.224 = bf16[16,6144]{1,0} parameter(0)
  %slice.101.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.224), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.392.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.101.1)
  %constant_1_7 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.5 = f32[] convert(bf16[] %constant_1_7)
  %broadcast.194.18 = f32[16,3072]{1,0} broadcast(f32[] %convert.436.5), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.21.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.392.8)
  %convert.396.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.21.5)
  %exponential.21.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.396.3)
  %convert.397.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.21.1)
  %add.101.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.194.18, f32[16,3072]{1,0} %convert.397.3)
  %divide.21.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.194.18, f32[16,3072]{1,0} %add.101.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.178.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.392.8, f32[16,3072]{1,0} %divide.21.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.102.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.224), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.398.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.102.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.179.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.178.5, f32[16,3072]{1,0} %convert.398.1), metadata={op_type="aten__mul" op_name="aten__mul.71/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.399.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.179.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.65 (param_0.313: f32[], param_1.275: bf16[1024], param_2.160: f32[16,1024], param_3.134: bf16[16,1024], param_4.64: bf16[16,6144]) -> bf16[16,1024] {
  %param_4.64 = bf16[16,6144]{1,0} parameter(4)
  %convert.342.26 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_4.64), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.5 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.26), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.134 = bf16[16,1024]{1,0} parameter(3)
  %convert.401.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.134), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.160 = f32[16,1024]{1,0} parameter(2)
  %add.102.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.401.5, f32[16,1024]{1,0} %param_2.160), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.90.5, f32[16,1024]{1,0} %add.102.5), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.217 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.103.3, f32[16,1024]{1,0} %add.103.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_187 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.23 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.217, f32[] %constant_187), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_186 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.246 = f32[16]{0} broadcast(f32[] %constant_186), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.216 = f32[16]{0} multiply(f32[16]{0} %reduce.23, f32[16]{0} %broadcast.246), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.313 = f32[] parameter(0)
  %broadcast.245 = f32[16]{0} broadcast(f32[] %param_0.313), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.118 = f32[16]{0} add(f32[16]{0} %multiply.216, f32[16]{0} %broadcast.245), metadata={op_type="aten__add" op_name="aten__add.86/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.47 = f32[16]{0} rsqrt(f32[16]{0} %add.118), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.244 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.47), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.87/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.214 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.103.3, f32[16,1024]{1,0} %broadcast.244), metadata={op_type="aten__mul" op_name="aten__mul.87/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.275 = bf16[1024]{0} parameter(1)
  %convert.402.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.275), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.182.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.402.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.88/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.180.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.214, f32[16,1024]{1,0} %broadcast.182.1), metadata={op_type="aten__mul" op_name="aten__mul.88/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.403.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.180.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.1 (param_0.222: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.222 = bf16[16,6144]{1,0} parameter(0)
  %slice.103.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.222), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.406.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.103.1)
  %constant_1_5 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.3 = f32[] convert(bf16[] %constant_1_5)
  %broadcast.194.16 = f32[16,3072]{1,0} broadcast(f32[] %convert.436.3), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.22.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.406.8)
  %convert.410.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.22.5)
  %exponential.22.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.410.3)
  %convert.412.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.22.1)
  %add.104.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.194.16, f32[16,3072]{1,0} %convert.412.3)
  %divide.22.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.194.16, f32[16,3072]{1,0} %add.104.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.181.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.406.8, f32[16,3072]{1,0} %divide.22.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.104.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.222), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.413.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.104.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.182.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.181.5, f32[16,3072]{1,0} %convert.413.1), metadata={op_type="aten__mul" op_name="aten__mul.89/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.414.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.182.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.63 (param_0.323: f32[], param_1.287: bf16[1024], param_2.179: f32[16,1024], param_3.158: bf16[16,1024], param_4.90: bf16[16,6144], param_5.29: bf16[16,1024]) -> bf16[16,1024] {
  %param_4.90 = bf16[16,6144]{1,0} parameter(4)
  %convert.342.48 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_4.90), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.88.5 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.48), slice={[0:16], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.29 = bf16[16,1024]{1,0} parameter(5)
  %convert.415.5 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_5.29), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.9 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.48), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.158 = bf16[16,1024]{1,0} parameter(3)
  %convert.401.9 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_3.158), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.179 = f32[16,1024]{1,0} parameter(2)
  %add.102.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.401.9, f32[16,1024]{1,0} %param_2.179), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.90.9, f32[16,1024]{1,0} %add.102.9), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.105.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.415.5, f32[16,1024]{1,0} %add.103.7), metadata={op_type="aten__add" op_name="aten__add.90/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.88.5, f32[16,1024]{1,0} %add.105.5), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.225 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.106.3, f32[16,1024]{1,0} %add.106.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_192 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.25 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.225, f32[] %constant_192), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_191 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.254 = f32[16]{0} broadcast(f32[] %constant_191), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.223 = f32[16]{0} multiply(f32[16]{0} %reduce.25, f32[16]{0} %broadcast.254), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.323 = f32[] parameter(0)
  %broadcast.253 = f32[16]{0} broadcast(f32[] %param_0.323), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.120 = f32[16]{0} add(f32[16]{0} %multiply.223, f32[16]{0} %broadcast.253), metadata={op_type="aten__add" op_name="aten__add.104/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.49 = f32[16]{0} rsqrt(f32[16]{0} %add.120), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.251 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.49), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.105/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.222 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.106.3, f32[16,1024]{1,0} %broadcast.251), metadata={op_type="aten__mul" op_name="aten__mul.105/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.287 = bf16[1024]{0} parameter(1)
  %convert.416.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.287), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.186.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.416.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.106/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.183.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.222, f32[16,1024]{1,0} %broadcast.186.1), metadata={op_type="aten__mul" op_name="aten__mul.106/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.417.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.183.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert (param_0.220: bf16[16,6144]) -> bf16[16,3072] {
  %param_0.220 = bf16[16,6144]{1,0} parameter(0)
  %slice.105.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.220), slice={[0:16], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.418.8 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.105.1)
  %constant_1_3 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.1 = f32[] convert(bf16[] %constant_1_3)
  %broadcast.194.14 = f32[16,3072]{1,0} broadcast(f32[] %convert.436.1), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.23.5 = f32[16,3072]{1,0} negate(f32[16,3072]{1,0} %convert.418.8)
  %convert.422.3 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %negate.23.5)
  %exponential.23.1 = bf16[16,3072]{1,0} exponential(bf16[16,3072]{1,0} %convert.422.3)
  %convert.423.3 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %exponential.23.1)
  %add.107.3 = f32[16,3072]{1,0} add(f32[16,3072]{1,0} %broadcast.194.14, f32[16,3072]{1,0} %convert.423.3)
  %divide.23.3 = f32[16,3072]{1,0} divide(f32[16,3072]{1,0} %broadcast.194.14, f32[16,3072]{1,0} %add.107.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.184.5 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %convert.418.8, f32[16,3072]{1,0} %divide.23.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.106.1 = bf16[16,3072]{1,0} slice(bf16[16,6144]{1,0} %param_0.220), slice={[0:16], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.424.1 = f32[16,3072]{1,0} convert(bf16[16,3072]{1,0} %slice.106.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.185.3 = f32[16,3072]{1,0} multiply(f32[16,3072]{1,0} %multiply.184.5, f32[16,3072]{1,0} %convert.424.1), metadata={op_type="aten__mul" op_name="aten__mul.107/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.425.1 = bf16[16,3072]{1,0} convert(f32[16,3072]{1,0} %multiply.185.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.61 (param_0.304: f32[], param_1.289: bf16[16,1024], param_2.181: bf16[1024], param_3.161: f32[16,1024], param_4.94: bf16[16,1024], param_5.34: bf16[16,6144], param_6.20: bf16[16,1024]) -> bf16[16,1024] {
  %param_1.289 = bf16[16,1024]{1,0} parameter(1)
  %convert.427.3 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_1.289), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.34 = bf16[16,6144]{1,0} parameter(5)
  %convert.342.52 = f32[16,6144]{1,0} convert(bf16[16,6144]{1,0} %param_5.34), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.88.7 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.52), slice={[0:16], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.20 = bf16[16,1024]{1,0} parameter(6)
  %convert.415.7 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_6.20), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.11 = f32[16,1024]{1,0} slice(f32[16,6144]{1,0} %convert.342.52), slice={[0:16], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.94 = bf16[16,1024]{1,0} parameter(4)
  %convert.401.11 = f32[16,1024]{1,0} convert(bf16[16,1024]{1,0} %param_4.94), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.161 = f32[16,1024]{1,0} parameter(3)
  %add.102.11 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.401.11, f32[16,1024]{1,0} %param_3.161), metadata={op_type="aten__add" op_name="aten__add.72/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.9 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.90.11, f32[16,1024]{1,0} %add.102.11), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.105.7 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.415.7, f32[16,1024]{1,0} %add.103.9), metadata={op_type="aten__add" op_name="aten__add.90/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106.5 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.88.7, f32[16,1024]{1,0} %add.105.7), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.108.3 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %convert.427.3, f32[16,1024]{1,0} %add.106.5), metadata={op_type="aten__add" op_name="aten__add.108/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.232 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.108.3, f32[16,1024]{1,0} %add.108.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_199 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.27 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.232, f32[] %constant_199), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_198 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.261 = f32[16]{0} broadcast(f32[] %constant_198), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.231 = f32[16]{0} multiply(f32[16]{0} %reduce.27, f32[16]{0} %broadcast.261), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.304 = f32[] parameter(0)
  %broadcast.260 = f32[16]{0} broadcast(f32[] %param_0.304), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.14/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.122 = f32[16]{0} add(f32[16]{0} %multiply.231, f32[16]{0} %broadcast.260), metadata={op_type="aten__add" op_name="aten__add.109/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.51 = f32[16]{0} rsqrt(f32[16]{0} %add.122), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.259 = f32[16,1024]{1,0} broadcast(f32[16]{0} %rsqrt.51), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.110/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.230 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.108.3, f32[16,1024]{1,0} %broadcast.259), metadata={op_type="aten__mul" op_name="aten__mul.110/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.181 = bf16[1024]{0} parameter(2)
  %convert.428.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.181), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.189.1 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %convert.428.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.111/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.187.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.230, f32[16,1024]{1,0} %broadcast.189.1), metadata={op_type="aten__mul" op_name="aten__mul.111/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.429.1 = bf16[16,1024]{1,0} convert(f32[16,1024]{1,0} %multiply.187.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_slice_computation (param_0.326: bf16[16,4096]) -> bf16[16,1024] {
  %param_0.326 = bf16[16,4096]{1,0} parameter(0)
  ROOT %slice.112.1 = bf16[16,1024]{1,0} slice(bf16[16,4096]{1,0} %param_0.326), slice={[0:16], [3072:4096]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%triton_softmax_computation.8 (param_0.241: f32[], param_1.238: bf16[16,4096]) -> f32[16,8,128] {
  %param_1.238 = bf16[16,4096]{1,0} parameter(1)
  %slice.107.1 = bf16[16,1024]{1,0} slice(bf16[16,4096]{1,0} %param_1.238), slice={[0:16], [2048:3072]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1458.3 = bf16[16,8,128]{2,1,0} bitcast(bf16[16,1024]{1,0} %slice.107.1)
  %convert.430.3 = f32[16,8,128]{2,1,0} convert(bf16[16,8,128]{2,1,0} %bitcast.1458.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.137 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %convert.430.3, f32[16,8,128]{2,1,0} %convert.430.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_92 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.8 = f32[16,8]{1,0} reduce(f32[16,8,128]{2,1,0} %multiply.137, f32[] %constant_92), dimensions={2}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_93 = f32[] constant(0.0078125), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.139 = f32[16,8]{1,0} broadcast(f32[] %constant_93), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.138 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %reduce.8, f32[16,8]{1,0} %broadcast.139), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.241 = f32[] parameter(0)
  %broadcast.140 = f32[16,8]{1,0} broadcast(f32[] %param_0.241), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.112/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.81 = f32[16,8]{1,0} add(f32[16,8]{1,0} %multiply.138, f32[16,8]{1,0} %broadcast.140), metadata={op_type="aten__add" op_name="aten__add.112/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.32 = f32[16,8]{1,0} rsqrt(f32[16,8]{1,0} %add.81), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.141 = f32[16,8,128]{2,1,0} broadcast(f32[16,8]{1,0} %rsqrt.32), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.113/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %multiply.139 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %convert.430.3, f32[16,8,128]{2,1,0} %broadcast.141), metadata={op_type="aten__mul" op_name="aten__mul.113/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_concatenate (param_0.311: f32[16,8,128], param_1.273: bf16[128], param_2.157: bf16[40960,128], param_3.130: s32[16]) -> bf16[16,8,128] {
  %param_0.311 = f32[16,8,128]{2,1,0} parameter(0)
  %param_1.273 = bf16[128]{0} parameter(1)
  %convert.431.11 = f32[128]{0} convert(bf16[128]{0} %param_1.273), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.190.14 = f32[16,8,128]{2,1,0} broadcast(f32[128]{0} %convert.431.11), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.114/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.188.14 = f32[16,8,128]{2,1,0} multiply(f32[16,8,128]{2,1,0} %param_0.311, f32[16,8,128]{2,1,0} %broadcast.190.14), metadata={op_type="aten__mul" op_name="aten__mul.114/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.108.7 = f32[16,8,64]{2,1,0} slice(f32[16,8,128]{2,1,0} %multiply.188.14), slice={[0:16], [0:8], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.157 = bf16[40960,128]{1,0} parameter(2)
  %param_3.130 = s32[16]{0} parameter(3)
  %bitcast.1474.3 = s32[16,1]{1,0} bitcast(s32[16]{0} %param_3.130)
  %gather.1.3 = bf16[16,1,128]{2,0,1} gather(bf16[40960,128]{1,0} %param_2.157, s32[16,1]{1,0} %bitcast.1474.3), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1477.17 = bf16[16,128]{1,0} bitcast(bf16[16,1,128]{2,0,1} %gather.1.3)
  %convert.432.17 = f32[16,128]{1,0} convert(bf16[16,128]{1,0} %bitcast.1477.17), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.109.7 = f32[16,64]{1,0} slice(f32[16,128]{1,0} %convert.432.17), slice={[0:16], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.191.12 = f32[16,8,64]{2,1,0} broadcast(f32[16,64]{1,0} %slice.109.7), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.115/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.189.7 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.108.7, f32[16,8,64]{2,1,0} %broadcast.191.12), metadata={op_type="aten__mul" op_name="aten__mul.115/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.110.7 = f32[16,8,64]{2,1,0} slice(f32[16,8,128]{2,1,0} %multiply.188.14), slice={[0:16], [0:8], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.111.7 = f32[16,64]{1,0} slice(f32[16,128]{1,0} %convert.432.17), slice={[0:16], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.192.8 = f32[16,8,64]{2,1,0} broadcast(f32[16,64]{1,0} %slice.111.7), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.116/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.190.5 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.110.7, f32[16,8,64]{2,1,0} %broadcast.192.8), metadata={op_type="aten__mul" op_name="aten__mul.116/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %subtract.2.5 = f32[16,8,64]{2,1,0} subtract(f32[16,8,64]{2,1,0} %multiply.189.7, f32[16,8,64]{2,1,0} %multiply.190.5), metadata={op_type="aten__sub" op_name="aten__sub.117/aten__sub" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.434.3 = bf16[16,8,64]{2,1,0} convert(f32[16,8,64]{2,1,0} %subtract.2.5)
  %multiply.191.7 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.110.7, f32[16,8,64]{2,1,0} %broadcast.191.12), metadata={op_type="aten__mul" op_name="aten__mul.118/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.192.5 = f32[16,8,64]{2,1,0} multiply(f32[16,8,64]{2,1,0} %slice.108.7, f32[16,8,64]{2,1,0} %broadcast.192.8), metadata={op_type="aten__mul" op_name="aten__mul.119/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.109.5 = f32[16,8,64]{2,1,0} add(f32[16,8,64]{2,1,0} %multiply.191.7, f32[16,8,64]{2,1,0} %multiply.192.5), metadata={op_type="aten__add" op_name="aten__add.120/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.435.3 = bf16[16,8,64]{2,1,0} convert(f32[16,8,64]{2,1,0} %add.109.5)
  ROOT %concatenate.16.1 = bf16[16,8,128]{2,1,0} concatenate(bf16[16,8,64]{2,1,0} %convert.434.3, bf16[16,8,64]{2,1,0} %convert.435.3), dimensions={2}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_slice (param_0.1: bf16[2,4233,16,8,128]) -> bf16[69353472] {
  %param_0.1 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  %bitcast.1518.1 = bf16[138706944]{0} bitcast(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.1)
  ROOT %slice.114.1 = bf16[69353472]{0} slice(bf16[138706944]{0} %bitcast.1518.1), slice={[69353472:138706944]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%wrapped_slice_computation.1 (param_0.327: bf16[2,4233,16,8,128]) -> bf16[1,4233,16,8,128] {
  %param_0.327 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  ROOT %slice.113.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} slice(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.327), slice={[0:1], [0:4233], [0:16], [0:8], [0:128]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%command_buffer (p: bf16[151936,1024], p.1: s32[16], p.2: bf16[1024,2048], p.3: bf16[1024,2048], p.4: bf16[1024,2048], p.5: bf16[1024,2048], p.6: bf16[1024,2048], p.7: bf16[1024,2048], p.8: f32[], p.9: bf16[1024], p.10: bf16[6144,1024], p.11: bf16[1024,3072], p.12: bf16[1024], p.13: bf16[6144,1024], p.14: bf16[1024,3072], p.15: bf16[1024], p.16: bf16[6144,1024], p.17: bf16[1024,3072], p.18: bf16[1024], p.19: bf16[6144,1024], p.20: bf16[1024,3072], p.21: bf16[1024], p.22: bf16[6144,1024], p.23: bf16[1024,3072], p.24: bf16[1024], p.25: bf16[6144,1024], p.26: bf16[1024,3072], p.27: bf16[1024], p.28: bf16[4096,1024], p.29: bf16[128], p.30: bf16[40960,128], p.31: s32[16], p.32: bf16[2,4233,16,8,128]) -> (bf16[16,8,128], bf16[16,8,128], bf16[4233,16,8,128], bf16[1,4233,16,8,128]) {
  %p = bf16[151936,1024]{1,0} parameter(0)
  %p.1 = s32[16]{0} parameter(1)
  %p.2 = bf16[1024,2048]{1,0} parameter(2)
  %p.3 = bf16[1024,2048]{1,0} parameter(3)
  %p.4 = bf16[1024,2048]{1,0} parameter(4)
  %p.5 = bf16[1024,2048]{1,0} parameter(5)
  %p.6 = bf16[1024,2048]{1,0} parameter(6)
  %p.7 = bf16[1024,2048]{1,0} parameter(7)
  %p.8 = f32[] parameter(8)
  %p.9 = bf16[1024]{0} parameter(9)
  %p.10 = bf16[6144,1024]{1,0} parameter(10)
  %p.11 = bf16[1024,3072]{1,0} parameter(11)
  %p.12 = bf16[1024]{0} parameter(12)
  %p.13 = bf16[6144,1024]{1,0} parameter(13)
  %p.14 = bf16[1024,3072]{1,0} parameter(14)
  %p.15 = bf16[1024]{0} parameter(15)
  %p.16 = bf16[6144,1024]{1,0} parameter(16)
  %p.17 = bf16[1024,3072]{1,0} parameter(17)
  %p.18 = bf16[1024]{0} parameter(18)
  %p.19 = bf16[6144,1024]{1,0} parameter(19)
  %p.20 = bf16[1024,3072]{1,0} parameter(20)
  %p.21 = bf16[1024]{0} parameter(21)
  %p.22 = bf16[6144,1024]{1,0} parameter(22)
  %p.23 = bf16[1024,3072]{1,0} parameter(23)
  %p.24 = bf16[1024]{0} parameter(24)
  %p.25 = bf16[6144,1024]{1,0} parameter(25)
  %p.26 = bf16[1024,3072]{1,0} parameter(26)
  %p.27 = bf16[1024]{0} parameter(27)
  %p.28 = bf16[4096,1024]{1,0} parameter(28)
  %p.29 = bf16[128]{0} parameter(29)
  %p.30 = bf16[40960,128]{1,0} parameter(30)
  %p.31 = s32[16]{0} parameter(31)
  %p.32 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(32)
  %loop_gather_fusion = bf16[16,1,1024]{2,0,1} fusion(bf16[151936,1024]{1,0} %p, s32[16]{0} %p.1), kind=kLoop, calls=%fused_gather, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_concatenate = bf16[6144,2048]{1,0} fusion(bf16[1024,2048]{1,0} %p.2, bf16[1024,2048]{1,0} %p.3, bf16[1024,2048]{1,0} %p.4, bf16[1024,2048]{1,0} %p.5, bf16[1024,2048]{1,0} %p.6, /*index=5*/bf16[1024,2048]{1,0} %p.7), kind=kLoop, calls=%wrapped_concatenate_computation, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %gemm_fusion_dot.23.0 = bf16[16,6144]{1,0} fusion(bf16[6144,2048]{1,0} %wrapped_concatenate), kind=kCustom, calls=%gemm_fusion_dot.23_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton_gemm","triton_gemm_config":{"block_m":"64","block_n":"16","block_k":"128","split_k":"1","num_stages":"4","num_warps":"4","num_ctas":"1"}},"force_earliest_schedule":false}
  %fusion.90 = bf16[16,1024]{1,0} fusion(f32[] %p.8, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,6144]{1,0} %gemm_fusion_dot.23.0, bf16[1024]{0} %p.9), kind=kCustom, calls=%fused_computation.73, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","256"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.13.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.90, bf16[6144,1024]{1,0} %p.10), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.13 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.13.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.5 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.13), kind=kLoop, calls=%fused_convert.5, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.14.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.5, bf16[1024,3072]{1,0} %p.11), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.1.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.14.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.88 = bf16[16,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.12, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,6144]{1,0} %gemm_fusion_dot.23.0, bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.71, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","256"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.15.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.88, bf16[6144,1024]{1,0} %p.13), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.2.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.15.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.4 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.2.0), kind=kLoop, calls=%fused_convert.4, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.16.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.4, bf16[1024,3072]{1,0} %p.14), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.3.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.16.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.86 = bf16[16,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.15, bf16[16,1024]{1,0} %get-tuple-element.3.0, bf16[16,6144]{1,0} %gemm_fusion_dot.23.0, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.69, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.17.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.86, bf16[6144,1024]{1,0} %p.16), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.4.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.17.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.3 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.4.0), kind=kLoop, calls=%fused_convert.3, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.18.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.3, bf16[1024,3072]{1,0} %p.17), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.5.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.18.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_add_fusion = f32[16,1024]{1,0} fusion(bf16[16,6144]{1,0} %gemm_fusion_dot.23.0, bf16[16,1024]{1,0} %get-tuple-element.5.0, bf16[16,1024]{1,0} %get-tuple-element.3.0, bf16[16,1,1024]{2,0,1} %loop_gather_fusion, bf16[16,1024]{1,0} %get-tuple-element.1.0), kind=kLoop, calls=%fused_add, metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.84 = bf16[16,1024]{1,0} fusion(f32[16,1024]{1,0} %loop_add_fusion, f32[] %p.8, bf16[1024]{0} %p.18), kind=kCustom, calls=%fused_computation.67, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","128"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.19.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.84, bf16[6144,1024]{1,0} %p.19), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.6.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.19.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.2 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.6.0), kind=kLoop, calls=%fused_convert.2, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.20.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.2, bf16[1024,3072]{1,0} %p.20), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.7.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.20.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.82 = bf16[16,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.21, f32[16,1024]{1,0} %loop_add_fusion, bf16[16,1024]{1,0} %get-tuple-element.7.0, bf16[16,6144]{1,0} %gemm_fusion_dot.23.0), kind=kCustom, calls=%fused_computation.65, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.21.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.82, bf16[6144,1024]{1,0} %p.22), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.8.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.21.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.1 = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.8.0), kind=kLoop, calls=%fused_convert.1, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.22.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion.1, bf16[1024,3072]{1,0} %p.23), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.9.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.22.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.80 = bf16[16,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.24, f32[16,1024]{1,0} %loop_add_fusion, bf16[16,1024]{1,0} %get-tuple-element.7.0, bf16[16,6144]{1,0} %gemm_fusion_dot.23.0, /*index=5*/bf16[16,1024]{1,0} %get-tuple-element.9.0), kind=kCustom, calls=%fused_computation.63, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.23.0 = (bf16[16,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.80, bf16[6144,1024]{1,0} %p.25), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.10.0 = bf16[16,6144]{1,0} get-tuple-element((bf16[16,6144]{1,0}, s8[4194304]{0}) %custom-call.23.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion = bf16[16,3072]{1,0} fusion(bf16[16,6144]{1,0} %get-tuple-element.10.0), kind=kLoop, calls=%fused_convert, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.24.0 = (bf16[16,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[16,3072]{1,0} %loop_convert_fusion, bf16[1024,3072]{1,0} %p.26), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"49152","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.11.0 = bf16[16,1024]{1,0} get-tuple-element((bf16[16,1024]{1,0}, s8[4194304]{0}) %custom-call.24.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.78 = bf16[16,1024]{1,0} fusion(f32[] %p.8, bf16[16,1024]{1,0} %get-tuple-element.11.0, bf16[1024]{0} %p.27, f32[16,1024]{1,0} %loop_add_fusion, bf16[16,1024]{1,0} %get-tuple-element.7.0, /*index=5*/bf16[16,6144]{1,0} %gemm_fusion_dot.23.0, bf16[16,1024]{1,0} %get-tuple-element.9.0), kind=kCustom, calls=%fused_computation.61, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.25.0 = (bf16[16,4096]{1,0}, s8[4194304]{0}) custom-call(bf16[16,1024]{1,0} %fusion.78, bf16[4096,1024]{1,0} %p.28), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"16384","rhs_stride":"4194304","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.12.0 = bf16[16,4096]{1,0} get-tuple-element((bf16[16,4096]{1,0}, s8[4194304]{0}) %custom-call.25.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_slice = bf16[16,1024]{1,0} fusion(bf16[16,4096]{1,0} %get-tuple-element.12.0), kind=kLoop, calls=%wrapped_slice_computation, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %triton_softmax.8.0 = f32[16,8,128]{2,1,0} fusion(f32[] %p.8, bf16[16,4096]{1,0} %get-tuple-element.12.0), kind=kCustom, calls=%triton_softmax_computation.8, metadata={op_type="aten__mul" op_name="aten__mul.113/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1","128"]}],"num_warps":"1"}},"force_earliest_schedule":false}
  %input_concatenate_fusion = bf16[16,8,128]{2,1,0} fusion(f32[16,8,128]{2,1,0} %triton_softmax.8.0, bf16[128]{0} %p.29, bf16[40960,128]{1,0} %p.30, s32[16]{0} %p.31), kind=kInput, calls=%fused_concatenate, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1510.0 = bf16[16,8,128]{2,1,0} bitcast(bf16[16,1024]{1,0} %wrapped_slice)
  %loop_slice_fusion = bf16[69353472]{0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.32), kind=kLoop, calls=%fused_slice, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  %bitcast.1522.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[69353472]{0} %loop_slice_fusion)
  %wrapped_slice.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.32), kind=kLoop, calls=%wrapped_slice_computation.1, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  ROOT %tuple = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) tuple(bf16[16,8,128]{2,1,0} %input_concatenate_fusion, bf16[16,8,128]{2,1,0} %bitcast.1510.0, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1522.0, bf16[1,4233,16,8,128]{4,3,2,1,0} %wrapped_slice.1)
}

ENTRY %SyncTensorsGraph.589 (p0.1.0: bf16[128], p1.4.0: f32[], p2.6.0: bf16[4096,1024], p3.8.0: bf16[1024], p4.24.0: s32[16], p5.26.0: bf16[151936,1024], p6.30.0: bf16[1024,2048], p7.46.0: bf16[1024,3072], p8.48.0: bf16[6144,1024], p9.50.0: bf16[1024], p10.102.0: bf16[1024,2048], p11.118.0: bf16[1024,3072], p12.120.0: bf16[6144,1024], p13.122.0: bf16[1024], p14.174.0: bf16[1024,2048], p15.190.0: bf16[1024,3072], p16.192.0: bf16[6144,1024], p17.194.0: bf16[1024], p18.246.0: bf16[1024,2048], p19.262.0: bf16[1024,3072], p20.264.0: bf16[6144,1024], p21.266.0: bf16[1024], p22.318.0: bf16[1024,2048], p23.334.0: bf16[1024,3072], p24.336.0: bf16[6144,1024], p25.338.0: bf16[1024], p26.390.0: bf16[1024,2048], p27.406.0: bf16[1024,3072], p28.408.0: bf16[6144,1024], p29.410.0: bf16[1024], p30.534.0: s32[16], p31.535.0: bf16[40960,128], p32.579.0: bf16[2,4233,16,8,128]) -> (bf16[16,8,128], bf16[16,8,128], bf16[4233,16,8,128], bf16[4233,16,8,128]) {
  %p1.4.0 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %p32.579.0 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(32), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p31.535.0 = bf16[40960,128]{1,0} parameter(31), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p30.534.0 = s32[16]{0} parameter(30), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p29.410.0 = bf16[1024]{0} parameter(29), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p28.408.0 = bf16[6144,1024]{1,0} parameter(28), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p27.406.0 = bf16[1024,3072]{1,0} parameter(27), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p26.390.0 = bf16[1024,2048]{1,0} parameter(26), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p25.338.0 = bf16[1024]{0} parameter(25), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p24.336.0 = bf16[6144,1024]{1,0} parameter(24), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p23.334.0 = bf16[1024,3072]{1,0} parameter(23), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p22.318.0 = bf16[1024,2048]{1,0} parameter(22), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p21.266.0 = bf16[1024]{0} parameter(21), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p20.264.0 = bf16[6144,1024]{1,0} parameter(20), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p19.262.0 = bf16[1024,3072]{1,0} parameter(19), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p18.246.0 = bf16[1024,2048]{1,0} parameter(18), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p17.194.0 = bf16[1024]{0} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p16.192.0 = bf16[6144,1024]{1,0} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p15.190.0 = bf16[1024,3072]{1,0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p14.174.0 = bf16[1024,2048]{1,0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p13.122.0 = bf16[1024]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p12.120.0 = bf16[6144,1024]{1,0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p11.118.0 = bf16[1024,3072]{1,0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p10.102.0 = bf16[1024,2048]{1,0} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p9.50.0 = bf16[1024]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p8.48.0 = bf16[6144,1024]{1,0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p7.46.0 = bf16[1024,3072]{1,0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p6.30.0 = bf16[1024,2048]{1,0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p5.26.0 = bf16[151936,1024]{1,0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p4.24.0 = s32[16]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p3.8.0 = bf16[1024]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p2.6.0 = bf16[4096,1024]{1,0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p0.1.0 = bf16[128]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %call = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) call(bf16[151936,1024]{1,0} %p5.26.0, s32[16]{0} %p4.24.0, bf16[1024,2048]{1,0} %p26.390.0, bf16[1024,2048]{1,0} %p22.318.0, bf16[1024,2048]{1,0} %p18.246.0, /*index=5*/bf16[1024,2048]{1,0} %p14.174.0, bf16[1024,2048]{1,0} %p10.102.0, bf16[1024,2048]{1,0} %p6.30.0, f32[] %p1.4.0, bf16[1024]{0} %p9.50.0, /*index=10*/bf16[6144,1024]{1,0} %p8.48.0, bf16[1024,3072]{1,0} %p7.46.0, bf16[1024]{0} %p13.122.0, bf16[6144,1024]{1,0} %p12.120.0, bf16[1024,3072]{1,0} %p11.118.0, /*index=15*/bf16[1024]{0} %p17.194.0, bf16[6144,1024]{1,0} %p16.192.0, bf16[1024,3072]{1,0} %p15.190.0, bf16[1024]{0} %p21.266.0, bf16[6144,1024]{1,0} %p20.264.0, /*index=20*/bf16[1024,3072]{1,0} %p19.262.0, bf16[1024]{0} %p25.338.0, bf16[6144,1024]{1,0} %p24.336.0, bf16[1024,3072]{1,0} %p23.334.0, bf16[1024]{0} %p29.410.0, /*index=25*/bf16[6144,1024]{1,0} %p28.408.0, bf16[1024,3072]{1,0} %p27.406.0, bf16[1024]{0} %p3.8.0, bf16[4096,1024]{1,0} %p2.6.0, bf16[128]{0} %p0.1.0, /*index=30*/bf16[40960,128]{1,0} %p31.535.0, s32[16]{0} %p30.534.0, bf16[2,4233,16,8,128]{4,3,2,1,0} %p32.579.0), to_apply=%command_buffer
  %get-tuple-element.15 = bf16[16,8,128]{2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=0
  %get-tuple-element.16 = bf16[16,8,128]{2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=1
  %get-tuple-element.17 = bf16[4233,16,8,128]{3,2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=2
  %get-tuple-element.18 = bf16[1,4233,16,8,128]{4,3,2,1,0} get-tuple-element((bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=3
  %bitcast.1515.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[1,4233,16,8,128]{4,3,2,1,0} %get-tuple-element.18)
  ROOT %tuple.588.0 = (bf16[16,8,128]{2,1,0}, bf16[16,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0}) tuple(bf16[16,8,128]{2,1,0} %get-tuple-element.15, bf16[16,8,128]{2,1,0} %get-tuple-element.16, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1515.0, bf16[4233,16,8,128]{3,2,1,0} %get-tuple-element.17)
}

