HloModule SyncTensorsGraph.589, is_scheduled=true, entry_computation_layout={(bf16[128]{0}, f32[], bf16[4096,1024]{1,0}, bf16[1024]{0}, s32[32]{0}, /*index=5*/bf16[151936,1024]{1,0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=10*/bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, /*index=15*/bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, /*index=20*/bf16[6144,1024]{1,0}, bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, /*index=25*/bf16[1024]{0}, bf16[1024,2048]{1,0}, bf16[1024,3072]{1,0}, bf16[6144,1024]{1,0}, bf16[1024]{0}, /*index=30*/s32[32]{0}, bf16[40960,128]{1,0}, bf16[2,4233,16,8,128]{4,3,2,1,0})->(bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0})}, frontend_attributes={fingerprint_before_lhs="6ced65151da4c7d73b425d71235c4adc"}

%fused_gather (param_0.9: bf16[151936,1024], param_1.275: s32[32]) -> bf16[32,1,1024] {
  %param_0.9 = bf16[151936,1024]{1,0} parameter(0)
  %param_1.275 = s32[32]{0} parameter(1)
  %convert.343.1 = s64[32]{0} convert(s32[32]{0} %param_1.275), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.344.1 = u32[32]{0} convert(s64[32]{0} %convert.343.1), metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1168.1 = u32[32,1]{1,0} bitcast(u32[32]{0} %convert.344.1)
  ROOT %gather.3 = bf16[32,1,1024]{2,0,1} gather(bf16[151936,1024]{1,0} %param_0.9, u32[32,1]{1,0} %bitcast.1168.1), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,1024}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_concatenate_computation (param_0.340: bf16[1024,2048], param_1.286: bf16[1024,2048], param_2.190: bf16[1024,2048], param_3.144: bf16[1024,2048], param_4.69: bf16[1024,2048], param_5.28: bf16[1024,2048]) -> bf16[6144,2048] {
  %param_0.340 = bf16[1024,2048]{1,0} parameter(0)
  %param_1.286 = bf16[1024,2048]{1,0} parameter(1)
  %param_2.190 = bf16[1024,2048]{1,0} parameter(2)
  %param_3.144 = bf16[1024,2048]{1,0} parameter(3)
  %param_4.69 = bf16[1024,2048]{1,0} parameter(4)
  %param_5.28 = bf16[1024,2048]{1,0} parameter(5)
  ROOT %concatenate.15.1 = bf16[6144,2048]{1,0} concatenate(bf16[1024,2048]{1,0} %param_0.340, bf16[1024,2048]{1,0} %param_1.286, bf16[1024,2048]{1,0} %param_2.190, bf16[1024,2048]{1,0} %param_3.144, bf16[1024,2048]{1,0} %param_4.69, /*index=5*/bf16[1024,2048]{1,0} %param_5.28), dimensions={0}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
}

%gemm_fusion_dot.23_computation (parameter_0: bf16[6144,2048]) -> bf16[32,6144] {
  %parameter_0 = bf16[6144,2048]{1,0} parameter(0)
  %constant_75 = bf16[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.65 = bf16[32,2048]{1,0} broadcast(bf16[] %constant_75), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %dot.25 = bf16[6144,32]{0,1} dot(bf16[6144,2048]{1,0} %parameter_0, bf16[32,2048]{1,0} %broadcast.65), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %bitcast.567 = bf16[32,6144]{1,0} bitcast(bf16[6144,32]{0,1} %dot.25), metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%AddComputation.58 (x.59: f32[], y.60: f32[]) -> f32[] {
  %y.60 = f32[] parameter(1)
  %x.59 = f32[] parameter(0)
  ROOT %add.89 = f32[] add(f32[] %x.59, f32[] %y.60)
}

%fused_computation.69 (param_0.331: f32[], param_1.273: bf16[32,1,1024], param_2.175: bf16[32,6144], param_3.128: bf16[1024]) -> bf16[32,1024] {
  %param_2.175 = bf16[32,6144]{1,0} parameter(2)
  %convert.342.24 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_2.175), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.9 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.24), slice={[0:32], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.273 = bf16[32,1,1024]{2,0,1} parameter(1)
  %bitcast.1171.9 = bf16[32,1024]{1,0} bitcast(bf16[32,1,1024]{2,0,1} %param_1.273)
  %convert.345.9 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %bitcast.1171.9), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.7 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.94.9, f32[32,1024]{1,0} %convert.345.9), metadata={op_type="aten__add" op_name="aten__add.520/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.240 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.90.7, f32[32,1024]{1,0} %add.90.7), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_224 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.29 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.240, f32[] %constant_224), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_223 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.267 = f32[32]{0} broadcast(f32[] %constant_223), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.239 = f32[32]{0} multiply(f32[32]{0} %reduce.29, f32[32]{0} %broadcast.267), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.331 = f32[] parameter(0)
  %broadcast.266 = f32[32]{0} broadcast(f32[] %param_0.331), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.124 = f32[32]{0} add(f32[32]{0} %multiply.239, f32[32]{0} %broadcast.266), metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.53 = f32[32]{0} rsqrt(f32[32]{0} %add.124), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.265 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.53), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.522/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.238 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.90.7, f32[32,1024]{1,0} %broadcast.265), metadata={op_type="aten__mul" op_name="aten__mul.522/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.128 = bf16[1024]{0} parameter(3)
  %convert.346.1 = f32[1024]{0} convert(bf16[1024]{0} %param_3.128), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.167.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.346.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.523/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.167.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.238, f32[32,1024]{1,0} %broadcast.167.3), metadata={op_type="aten__mul" op_name="aten__mul.523/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.347.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.167.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert (param_0.293: bf16[32,6144]) -> bf16[32,3072] {
  %param_0.293 = bf16[32,6144]{1,0} parameter(0)
  %slice.95.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.293), slice={[0:32], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.348.8 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.95.1)
  %constant_1_4 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.2 = f32[] convert(bf16[] %constant_1_4)
  %broadcast.194.24 = f32[32,3072]{1,0} broadcast(f32[] %convert.436.2), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.18.7 = f32[32,3072]{1,0} negate(f32[32,3072]{1,0} %convert.348.8)
  %convert.352.5 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %negate.18.7)
  %exponential.18.3 = bf16[32,3072]{1,0} exponential(bf16[32,3072]{1,0} %convert.352.5)
  %convert.353.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %exponential.18.3)
  %add.91.3 = f32[32,3072]{1,0} add(f32[32,3072]{1,0} %broadcast.194.24, f32[32,3072]{1,0} %convert.353.1)
  %divide.18.3 = f32[32,3072]{1,0} divide(f32[32,3072]{1,0} %broadcast.194.24, f32[32,3072]{1,0} %add.91.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.168.5 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %convert.348.8, f32[32,3072]{1,0} %divide.18.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.96.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.293), slice={[0:32], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.355.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.96.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.169.3 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %multiply.168.5, f32[32,3072]{1,0} %convert.355.1), metadata={op_type="aten__mul" op_name="aten__mul.524/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.356.1 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %multiply.169.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.70 (param_0.337: f32[], param_1.283: bf16[1024], param_2.185: bf16[32,1,1024], param_3.140: bf16[32,6144], param_4.62: bf16[32,1024]) -> bf16[32,1024] {
  %param_3.140 = bf16[32,6144]{1,0} parameter(3)
  %convert.342.44 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_3.140), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.5 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.44), slice={[0:32], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.62 = bf16[32,1024]{1,0} parameter(4)
  %convert.357.3 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_4.62), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.11 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.44), slice={[0:32], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.185 = bf16[32,1,1024]{2,0,1} parameter(2)
  %bitcast.1171.11 = bf16[32,1024]{1,0} bitcast(bf16[32,1,1024]{2,0,1} %param_2.185)
  %convert.345.11 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %bitcast.1171.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.9 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.94.11, f32[32,1024]{1,0} %convert.345.11), metadata={op_type="aten__add" op_name="aten__add.520/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.357.3, f32[32,1024]{1,0} %add.90.9), metadata={op_type="aten__add" op_name="aten__add.525/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.93.5, f32[32,1024]{1,0} %add.92.3), metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.204 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.93.3, f32[32,1024]{1,0} %add.93.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_192 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.19 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.204, f32[] %constant_192), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_191 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.233 = f32[32]{0} broadcast(f32[] %constant_191), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.203 = f32[32]{0} multiply(f32[32]{0} %reduce.19, f32[32]{0} %broadcast.233), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.337 = f32[] parameter(0)
  %broadcast.232 = f32[32]{0} broadcast(f32[] %param_0.337), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.113 = f32[32]{0} add(f32[32]{0} %multiply.203, f32[32]{0} %broadcast.232), metadata={op_type="aten__add" op_name="aten__add.539/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.43 = f32[32]{0} rsqrt(f32[32]{0} %add.113), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.231 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.43), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.540/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.202 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.93.3, f32[32,1024]{1,0} %broadcast.231), metadata={op_type="aten__mul" op_name="aten__mul.540/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.283 = bf16[1024]{0} parameter(1)
  %convert.358.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.283), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.171.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.358.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.541/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.171.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.202, f32[32,1024]{1,0} %broadcast.171.3), metadata={op_type="aten__mul" op_name="aten__mul.541/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.359.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.171.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.1 (param_0.295: bf16[32,6144]) -> bf16[32,3072] {
  %param_0.295 = bf16[32,6144]{1,0} parameter(0)
  %slice.97.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.295), slice={[0:32], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.360.8 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.97.1)
  %constant_1_6 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.4 = f32[] convert(bf16[] %constant_1_6)
  %broadcast.194.22 = f32[32,3072]{1,0} broadcast(f32[] %convert.436.4), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.19.7 = f32[32,3072]{1,0} negate(f32[32,3072]{1,0} %convert.360.8)
  %convert.365.5 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %negate.19.7)
  %exponential.19.3 = bf16[32,3072]{1,0} exponential(bf16[32,3072]{1,0} %convert.365.5)
  %convert.366.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %exponential.19.3)
  %add.94.3 = f32[32,3072]{1,0} add(f32[32,3072]{1,0} %broadcast.194.22, f32[32,3072]{1,0} %convert.366.1)
  %divide.19.3 = f32[32,3072]{1,0} divide(f32[32,3072]{1,0} %broadcast.194.22, f32[32,3072]{1,0} %add.94.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.172.5 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %convert.360.8, f32[32,3072]{1,0} %divide.19.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.98.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.295), slice={[0:32], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.367.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.98.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.173.3 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %multiply.172.5, f32[32,3072]{1,0} %convert.367.1), metadata={op_type="aten__mul" op_name="aten__mul.542/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.368.1 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %multiply.173.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.71 (param_0.312: f32[], param_1.261: bf16[1024], param_2.189: bf16[32,1024], param_3.143: bf16[32,6144], param_4.68: bf16[32,1,1024], param_5.27: bf16[32,1024]) -> bf16[32,1024] {
  %param_3.143 = bf16[32,6144]{1,0} parameter(3)
  %convert.342.30 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_3.143), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.5 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.30), slice={[0:32], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.189 = bf16[32,1024]{1,0} parameter(2)
  %convert.371.3 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_2.189), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.9 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.30), slice={[0:32], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.27 = bf16[32,1024]{1,0} parameter(5)
  %convert.357.7 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_5.27), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.15 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.30), slice={[0:32], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.68 = bf16[32,1,1024]{2,0,1} parameter(4)
  %bitcast.1171.15 = bf16[32,1024]{1,0} bitcast(bf16[32,1,1024]{2,0,1} %param_4.68)
  %convert.345.15 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %bitcast.1171.15), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.13 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.94.15, f32[32,1024]{1,0} %convert.345.15), metadata={op_type="aten__add" op_name="aten__add.520/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.7 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.357.7, f32[32,1024]{1,0} %add.90.13), metadata={op_type="aten__add" op_name="aten__add.525/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.7 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.93.9, f32[32,1024]{1,0} %add.92.7), metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.371.3, f32[32,1024]{1,0} %add.93.7), metadata={op_type="aten__add" op_name="aten__add.543/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.92.5, f32[32,1024]{1,0} %add.95.3), metadata={op_type="aten__add" op_name="aten__add.556/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.210 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.96.3, f32[32,1024]{1,0} %add.96.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_199 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.21 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.210, f32[] %constant_199), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_198 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.239 = f32[32]{0} broadcast(f32[] %constant_198), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.209 = f32[32]{0} multiply(f32[32]{0} %reduce.21, f32[32]{0} %broadcast.239), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.312 = f32[] parameter(0)
  %broadcast.238 = f32[32]{0} broadcast(f32[] %param_0.312), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.116 = f32[32]{0} add(f32[32]{0} %multiply.209, f32[32]{0} %broadcast.238), metadata={op_type="aten__add" op_name="aten__add.557/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.45 = f32[32]{0} rsqrt(f32[32]{0} %add.116), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.237 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.45), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.558/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.208 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.96.3, f32[32,1024]{1,0} %broadcast.237), metadata={op_type="aten__mul" op_name="aten__mul.558/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.261 = bf16[1024]{0} parameter(1)
  %convert.372.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.261), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.174.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.372.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.559/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.174.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.208, f32[32,1024]{1,0} %broadcast.174.3), metadata={op_type="aten__mul" op_name="aten__mul.559/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.374.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.174.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.2 (param_0.297: bf16[32,6144]) -> bf16[32,3072] {
  %param_0.297 = bf16[32,6144]{1,0} parameter(0)
  %slice.99.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.297), slice={[0:32], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.375.8 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.99.1)
  %constant_1_1 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.6 = f32[] convert(bf16[] %constant_1_1)
  %broadcast.194.20 = f32[32,3072]{1,0} broadcast(f32[] %convert.436.6), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.20.7 = f32[32,3072]{1,0} negate(f32[32,3072]{1,0} %convert.375.8)
  %convert.381.5 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %negate.20.7)
  %exponential.20.3 = bf16[32,3072]{1,0} exponential(bf16[32,3072]{1,0} %convert.381.5)
  %convert.383.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %exponential.20.3)
  %add.97.3 = f32[32,3072]{1,0} add(f32[32,3072]{1,0} %broadcast.194.20, f32[32,3072]{1,0} %convert.383.1)
  %divide.20.3 = f32[32,3072]{1,0} divide(f32[32,3072]{1,0} %broadcast.194.20, f32[32,3072]{1,0} %add.97.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.175.5 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %convert.375.8, f32[32,3072]{1,0} %divide.20.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.100.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.297), slice={[0:32], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.385.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.100.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.176.3 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %multiply.175.5, f32[32,3072]{1,0} %convert.385.1), metadata={op_type="aten__mul" op_name="aten__mul.560/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.386.1 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %multiply.176.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_add (param_0.243: bf16[32,6144], param_1.263: bf16[32,1024], param_2.187: bf16[32,1024], param_3.142: bf16[32,1,1024], param_4.66: bf16[32,1024]) -> f32[32,1024] {
  %param_0.243 = bf16[32,6144]{1,0} parameter(0)
  %convert.342.14 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_0.243), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.91.3 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.14), slice={[0:32], [2048:3072]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.263 = bf16[32,1024]{1,0} parameter(1)
  %convert.387.1 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_1.263), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.92.7 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.14), slice={[0:32], [3072:4096]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.187 = bf16[32,1024]{1,0} parameter(2)
  %convert.371.5 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_2.187), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.93.7 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.14), slice={[0:32], [4096:5120]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.66 = bf16[32,1024]{1,0} parameter(4)
  %convert.357.5 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_4.66), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.94.13 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.14), slice={[0:32], [5120:6144]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.142 = bf16[32,1,1024]{2,0,1} parameter(3)
  %bitcast.1171.13 = bf16[32,1024]{1,0} bitcast(bf16[32,1,1024]{2,0,1} %param_3.142)
  %convert.345.13 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %bitcast.1171.13), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.90.11 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.94.13, f32[32,1024]{1,0} %convert.345.13), metadata={op_type="aten__add" op_name="aten__add.520/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.92.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.357.5, f32[32,1024]{1,0} %add.90.11), metadata={op_type="aten__add" op_name="aten__add.525/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.93.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.93.7, f32[32,1024]{1,0} %add.92.5), metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.95.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.371.5, f32[32,1024]{1,0} %add.93.5), metadata={op_type="aten__add" op_name="aten__add.543/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.96.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.92.7, f32[32,1024]{1,0} %add.95.5), metadata={op_type="aten__add" op_name="aten__add.556/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.98.1 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.387.1, f32[32,1024]{1,0} %add.96.5), metadata={op_type="aten__add" op_name="aten__add.561/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %add.100.1 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.91.3, f32[32,1024]{1,0} %add.98.1), metadata={op_type="aten__add" op_name="aten__add.574/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.72 (param_0.305: f32[32,1024], param_1.253: f32[], param_2.147: bf16[1024]) -> bf16[32,1024] {
  %param_0.305 = f32[32,1024]{1,0} parameter(0)
  %multiply.217 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %param_0.305, f32[32,1024]{1,0} %param_0.305), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_206 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.23 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.217, f32[] %constant_206), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_205 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.246 = f32[32]{0} broadcast(f32[] %constant_205), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.216 = f32[32]{0} multiply(f32[32]{0} %reduce.23, f32[32]{0} %broadcast.246), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.253 = f32[] parameter(1)
  %broadcast.245 = f32[32]{0} broadcast(f32[] %param_1.253), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.118 = f32[32]{0} add(f32[32]{0} %multiply.216, f32[32]{0} %broadcast.245), metadata={op_type="aten__add" op_name="aten__add.575/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.47 = f32[32]{0} rsqrt(f32[32]{0} %add.118), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.244 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.47), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.576/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.214 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %param_0.305, f32[32,1024]{1,0} %broadcast.244), metadata={op_type="aten__mul" op_name="aten__mul.576/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.147 = bf16[1024]{0} parameter(2)
  %convert.390.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.147), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.177.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.390.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.577/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.177.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.214, f32[32,1024]{1,0} %broadcast.177.3), metadata={op_type="aten__mul" op_name="aten__mul.577/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.391.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.177.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.3 (param_0.296: bf16[32,6144]) -> bf16[32,3072] {
  %param_0.296 = bf16[32,6144]{1,0} parameter(0)
  %slice.101.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.296), slice={[0:32], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.392.8 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.101.1)
  %constant_1_7 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.5 = f32[] convert(bf16[] %constant_1_7)
  %broadcast.194.18 = f32[32,3072]{1,0} broadcast(f32[] %convert.436.5), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.21.7 = f32[32,3072]{1,0} negate(f32[32,3072]{1,0} %convert.392.8)
  %convert.396.5 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %negate.21.7)
  %exponential.21.3 = bf16[32,3072]{1,0} exponential(bf16[32,3072]{1,0} %convert.396.5)
  %convert.397.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %exponential.21.3)
  %add.101.3 = f32[32,3072]{1,0} add(f32[32,3072]{1,0} %broadcast.194.18, f32[32,3072]{1,0} %convert.397.1)
  %divide.21.3 = f32[32,3072]{1,0} divide(f32[32,3072]{1,0} %broadcast.194.18, f32[32,3072]{1,0} %add.101.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.178.5 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %convert.392.8, f32[32,3072]{1,0} %divide.21.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.102.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.296), slice={[0:32], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.398.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.102.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.179.3 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %multiply.178.5, f32[32,3072]{1,0} %convert.398.1), metadata={op_type="aten__mul" op_name="aten__mul.578/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.399.1 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %multiply.179.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.73 (param_0.309: f32[], param_1.257: bf16[1024], param_2.152: f32[32,1024], param_3.107: bf16[32,1024], param_4.33: bf16[32,6144]) -> bf16[32,1024] {
  %param_4.33 = bf16[32,6144]{1,0} parameter(4)
  %convert.342.26 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_4.33), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.5 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.26), slice={[0:32], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.107 = bf16[32,1024]{1,0} parameter(3)
  %convert.401.3 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_3.107), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.152 = f32[32,1024]{1,0} parameter(2)
  %add.102.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.401.3, f32[32,1024]{1,0} %param_2.152), metadata={op_type="aten__add" op_name="aten__add.579/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.90.5, f32[32,1024]{1,0} %add.102.3), metadata={op_type="aten__add" op_name="aten__add.592/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.225 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.103.3, f32[32,1024]{1,0} %add.103.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_214 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.25 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.225, f32[] %constant_214), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_213 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.254 = f32[32]{0} broadcast(f32[] %constant_213), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.223 = f32[32]{0} multiply(f32[32]{0} %reduce.25, f32[32]{0} %broadcast.254), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.309 = f32[] parameter(0)
  %broadcast.253 = f32[32]{0} broadcast(f32[] %param_0.309), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.120 = f32[32]{0} add(f32[32]{0} %multiply.223, f32[32]{0} %broadcast.253), metadata={op_type="aten__add" op_name="aten__add.593/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.49 = f32[32]{0} rsqrt(f32[32]{0} %add.120), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.251 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.49), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.594/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.222 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.103.3, f32[32,1024]{1,0} %broadcast.251), metadata={op_type="aten__mul" op_name="aten__mul.594/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.257 = bf16[1024]{0} parameter(1)
  %convert.402.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.257), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.182.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.402.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.595/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.180.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.222, f32[32,1024]{1,0} %broadcast.182.3), metadata={op_type="aten__mul" op_name="aten__mul.595/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.403.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.180.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.4 (param_0.294: bf16[32,6144]) -> bf16[32,3072] {
  %param_0.294 = bf16[32,6144]{1,0} parameter(0)
  %slice.103.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.294), slice={[0:32], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.406.8 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.103.1)
  %constant_1_5 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.3 = f32[] convert(bf16[] %constant_1_5)
  %broadcast.194.16 = f32[32,3072]{1,0} broadcast(f32[] %convert.436.3), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.22.7 = f32[32,3072]{1,0} negate(f32[32,3072]{1,0} %convert.406.8)
  %convert.410.5 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %negate.22.7)
  %exponential.22.3 = bf16[32,3072]{1,0} exponential(bf16[32,3072]{1,0} %convert.410.5)
  %convert.412.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %exponential.22.3)
  %add.104.3 = f32[32,3072]{1,0} add(f32[32,3072]{1,0} %broadcast.194.16, f32[32,3072]{1,0} %convert.412.1)
  %divide.22.3 = f32[32,3072]{1,0} divide(f32[32,3072]{1,0} %broadcast.194.16, f32[32,3072]{1,0} %add.104.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.181.5 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %convert.406.8, f32[32,3072]{1,0} %divide.22.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.104.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.294), slice={[0:32], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.413.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.104.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.182.3 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %multiply.181.5, f32[32,3072]{1,0} %convert.413.1), metadata={op_type="aten__mul" op_name="aten__mul.596/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.414.1 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %multiply.182.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.74 (param_0.334: f32[], param_1.279: bf16[1024], param_2.180: f32[32,1024], param_3.133: bf16[32,1024], param_4.53: bf16[32,6144], param_5.6: bf16[32,1024]) -> bf16[32,1024] {
  %param_4.53 = bf16[32,6144]{1,0} parameter(4)
  %convert.342.36 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_4.53), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.88.5 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.36), slice={[0:32], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.6 = bf16[32,1024]{1,0} parameter(5)
  %convert.415.3 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_5.6), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.9 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.36), slice={[0:32], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.133 = bf16[32,1024]{1,0} parameter(3)
  %convert.401.7 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_3.133), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.180 = f32[32,1024]{1,0} parameter(2)
  %add.102.7 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.401.7, f32[32,1024]{1,0} %param_2.180), metadata={op_type="aten__add" op_name="aten__add.579/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.7 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.90.9, f32[32,1024]{1,0} %add.102.7), metadata={op_type="aten__add" op_name="aten__add.592/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.105.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.415.3, f32[32,1024]{1,0} %add.103.7), metadata={op_type="aten__add" op_name="aten__add.597/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106.3 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.88.5, f32[32,1024]{1,0} %add.105.3), metadata={op_type="aten__add" op_name="aten__add.610/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.232 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.106.3, f32[32,1024]{1,0} %add.106.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_219 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.27 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.232, f32[] %constant_219), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_218 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.261 = f32[32]{0} broadcast(f32[] %constant_218), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.231 = f32[32]{0} multiply(f32[32]{0} %reduce.27, f32[32]{0} %broadcast.261), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.334 = f32[] parameter(0)
  %broadcast.260 = f32[32]{0} broadcast(f32[] %param_0.334), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.122 = f32[32]{0} add(f32[32]{0} %multiply.231, f32[32]{0} %broadcast.260), metadata={op_type="aten__add" op_name="aten__add.611/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.51 = f32[32]{0} rsqrt(f32[32]{0} %add.122), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.259 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.51), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.612/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.230 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.106.3, f32[32,1024]{1,0} %broadcast.259), metadata={op_type="aten__mul" op_name="aten__mul.612/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.279 = bf16[1024]{0} parameter(1)
  %convert.416.1 = f32[1024]{0} convert(bf16[1024]{0} %param_1.279), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.186.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.416.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.613/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.183.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.230, f32[32,1024]{1,0} %broadcast.186.3), metadata={op_type="aten__mul" op_name="aten__mul.613/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.417.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.183.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_convert.5 (param_0.292: bf16[32,6144]) -> bf16[32,3072] {
  %param_0.292 = bf16[32,6144]{1,0} parameter(0)
  %slice.105.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.292), slice={[0:32], [0:3072]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.418.8 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.105.1)
  %constant_1_3 = bf16[] constant(1), metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.436.1 = f32[] convert(bf16[] %constant_1_3)
  %broadcast.194.14 = f32[32,3072]{1,0} broadcast(f32[] %convert.436.1), dimensions={}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %negate.23.7 = f32[32,3072]{1,0} negate(f32[32,3072]{1,0} %convert.418.8)
  %convert.422.5 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %negate.23.7)
  %exponential.23.3 = bf16[32,3072]{1,0} exponential(bf16[32,3072]{1,0} %convert.422.5)
  %convert.423.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %exponential.23.3)
  %add.107.3 = f32[32,3072]{1,0} add(f32[32,3072]{1,0} %broadcast.194.14, f32[32,3072]{1,0} %convert.423.1)
  %divide.23.3 = f32[32,3072]{1,0} divide(f32[32,3072]{1,0} %broadcast.194.14, f32[32,3072]{1,0} %add.107.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.184.5 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %convert.418.8, f32[32,3072]{1,0} %divide.23.3), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.106.1 = bf16[32,3072]{1,0} slice(bf16[32,6144]{1,0} %param_0.292), slice={[0:32], [3072:6144]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.424.1 = f32[32,3072]{1,0} convert(bf16[32,3072]{1,0} %slice.106.1), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.185.3 = f32[32,3072]{1,0} multiply(f32[32,3072]{1,0} %multiply.184.5, f32[32,3072]{1,0} %convert.424.1), metadata={op_type="aten__mul" op_name="aten__mul.614/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.425.1 = bf16[32,3072]{1,0} convert(f32[32,3072]{1,0} %multiply.185.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.75 (param_0.302: f32[], param_1.281: bf16[32,1024], param_2.182: bf16[1024], param_3.136: f32[32,1024], param_4.57: bf16[32,1024], param_5.11: bf16[32,6144], param_6.11: bf16[32,1024]) -> bf16[32,1024] {
  %param_1.281 = bf16[32,1024]{1,0} parameter(1)
  %convert.427.5 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_1.281), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_5.11 = bf16[32,6144]{1,0} parameter(5)
  %convert.342.40 = f32[32,6144]{1,0} convert(bf16[32,6144]{1,0} %param_5.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.88.7 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.40), slice={[0:32], [0:1024]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_6.11 = bf16[32,1024]{1,0} parameter(6)
  %convert.415.5 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_6.11), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.90.11 = f32[32,1024]{1,0} slice(f32[32,6144]{1,0} %convert.342.40), slice={[0:32], [1024:2048]}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_4.57 = bf16[32,1024]{1,0} parameter(4)
  %convert.401.9 = f32[32,1024]{1,0} convert(bf16[32,1024]{1,0} %param_4.57), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_3.136 = f32[32,1024]{1,0} parameter(3)
  %add.102.9 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.401.9, f32[32,1024]{1,0} %param_3.136), metadata={op_type="aten__add" op_name="aten__add.579/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.103.9 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.90.11, f32[32,1024]{1,0} %add.102.9), metadata={op_type="aten__add" op_name="aten__add.592/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.105.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.415.5, f32[32,1024]{1,0} %add.103.9), metadata={op_type="aten__add" op_name="aten__add.597/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.106.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %slice.88.7, f32[32,1024]{1,0} %add.105.5), metadata={op_type="aten__add" op_name="aten__add.610/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.108.5 = f32[32,1024]{1,0} add(f32[32,1024]{1,0} %convert.427.5, f32[32,1024]{1,0} %add.106.5), metadata={op_type="aten__add" op_name="aten__add.615/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.247 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.108.5, f32[32,1024]{1,0} %add.108.5), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_229 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.31 = f32[32]{0} reduce(f32[32,1024]{1,0} %multiply.247, f32[] %constant_229), dimensions={1}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_228 = f32[] constant(0.0009765625), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.274 = f32[32]{0} broadcast(f32[] %constant_228), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.246 = f32[32]{0} multiply(f32[32]{0} %reduce.31, f32[32]{0} %broadcast.274), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.302 = f32[] parameter(0)
  %broadcast.273 = f32[32]{0} broadcast(f32[] %param_0.302), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.126 = f32[32]{0} add(f32[32]{0} %multiply.246, f32[32]{0} %broadcast.273), metadata={op_type="aten__add" op_name="aten__add.616/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.55 = f32[32]{0} rsqrt(f32[32]{0} %add.126), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.272 = f32[32,1024]{1,0} broadcast(f32[32]{0} %rsqrt.55), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul.617/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.245 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %add.108.5, f32[32,1024]{1,0} %broadcast.272), metadata={op_type="aten__mul" op_name="aten__mul.617/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.182 = bf16[1024]{0} parameter(2)
  %convert.428.1 = f32[1024]{0} convert(bf16[1024]{0} %param_2.182), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.189.3 = f32[32,1024]{1,0} broadcast(f32[1024]{0} %convert.428.1), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul.618/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.187.3 = f32[32,1024]{1,0} multiply(f32[32,1024]{1,0} %multiply.245, f32[32,1024]{1,0} %broadcast.189.3), metadata={op_type="aten__mul" op_name="aten__mul.618/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %convert.429.1 = bf16[32,1024]{1,0} convert(f32[32,1024]{1,0} %multiply.187.3), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%wrapped_slice_computation (param_0.341: bf16[32,4096]) -> bf16[32,1024] {
  %param_0.341 = bf16[32,4096]{1,0} parameter(0)
  ROOT %slice.112.1 = bf16[32,1024]{1,0} slice(bf16[32,4096]{1,0} %param_0.341), slice={[0:32], [3072:4096]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_computation.61 (param_0.330: f32[], param_1.272: bf16[32,4096], param_2.174: bf16[128]) -> f32[32,8,128] {
  %param_1.272 = bf16[32,4096]{1,0} parameter(1)
  %slice.107.1 = bf16[32,1024]{1,0} slice(bf16[32,4096]{1,0} %param_1.272), slice={[0:32], [2048:3072]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1458.5 = bf16[32,8,128]{2,1,0} bitcast(bf16[32,1024]{1,0} %slice.107.1)
  %convert.430.5 = f32[32,8,128]{2,1,0} convert(bf16[32,8,128]{2,1,0} %bitcast.1458.5), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.198 = f32[32,8,128]{2,1,0} multiply(f32[32,8,128]{2,1,0} %convert.430.5, f32[32,8,128]{2,1,0} %convert.430.5), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_178 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %reduce.17 = f32[32,8]{1,0} reduce(f32[32,8,128]{2,1,0} %multiply.198, f32[] %constant_178), dimensions={2}, to_apply=%AddComputation.58, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %constant_177 = f32[] constant(0.0078125), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.226 = f32[32,8]{1,0} broadcast(f32[] %constant_177), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.197 = f32[32,8]{1,0} multiply(f32[32,8]{1,0} %reduce.17, f32[32,8]{1,0} %broadcast.226), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_0.330 = f32[] parameter(0)
  %broadcast.225 = f32[32,8]{1,0} broadcast(f32[] %param_0.330), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.619/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.111 = f32[32,8]{1,0} add(f32[32,8]{1,0} %multiply.197, f32[32,8]{1,0} %broadcast.225), metadata={op_type="aten__add" op_name="aten__add.619/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %rsqrt.41 = f32[32,8]{1,0} rsqrt(f32[32,8]{1,0} %add.111), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.224 = f32[32,8,128]{2,1,0} broadcast(f32[32,8]{1,0} %rsqrt.41), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.620/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.196 = f32[32,8,128]{2,1,0} multiply(f32[32,8,128]{2,1,0} %convert.430.5, f32[32,8,128]{2,1,0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul.620/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_2.174 = bf16[128]{0} parameter(2)
  %convert.431.1 = f32[128]{0} convert(bf16[128]{0} %param_2.174), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.190.1 = f32[32,8,128]{2,1,0} broadcast(f32[128]{0} %convert.431.1), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.621/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  ROOT %multiply.188.1 = f32[32,8,128]{2,1,0} multiply(f32[32,8,128]{2,1,0} %multiply.196, f32[32,8,128]{2,1,0} %broadcast.190.1), metadata={op_type="aten__mul" op_name="aten__mul.621/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_concatenate (param_0.329: f32[32,8,128], param_1.277: bf16[40960,128], param_2.177: s32[32]) -> bf16[32,8,128] {
  %param_0.329 = f32[32,8,128]{2,1,0} parameter(0)
  %slice.108.4 = f32[32,8,64]{2,1,0} slice(f32[32,8,128]{2,1,0} %param_0.329), slice={[0:32], [0:8], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %param_1.277 = bf16[40960,128]{1,0} parameter(1)
  %param_2.177 = s32[32]{0} parameter(2)
  %bitcast.1474.3 = s32[32,1]{1,0} bitcast(s32[32]{0} %param_2.177)
  %gather.1.3 = bf16[32,1,128]{2,0,1} gather(bf16[40960,128]{1,0} %param_1.277, s32[32,1]{1,0} %bitcast.1474.3), offset_dims={1,2}, collapsed_slice_dims={}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,128}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1477.7 = bf16[32,128]{1,0} bitcast(bf16[32,1,128]{2,0,1} %gather.1.3)
  %convert.432.7 = f32[32,128]{1,0} convert(bf16[32,128]{1,0} %bitcast.1477.7), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.109.3 = f32[32,64]{1,0} slice(f32[32,128]{1,0} %convert.432.7), slice={[0:32], [0:64]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.191.12 = f32[32,8,64]{2,1,0} broadcast(f32[32,64]{1,0} %slice.109.3), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.622/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.189.7 = f32[32,8,64]{2,1,0} multiply(f32[32,8,64]{2,1,0} %slice.108.4, f32[32,8,64]{2,1,0} %broadcast.191.12), metadata={op_type="aten__mul" op_name="aten__mul.622/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.110.4 = f32[32,8,64]{2,1,0} slice(f32[32,8,128]{2,1,0} %param_0.329), slice={[0:32], [0:8], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %slice.111.3 = f32[32,64]{1,0} slice(f32[32,128]{1,0} %convert.432.7), slice={[0:32], [64:128]}, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %broadcast.192.8 = f32[32,8,64]{2,1,0} broadcast(f32[32,64]{1,0} %slice.111.3), dimensions={0,2}, metadata={op_type="aten__mul" op_name="aten__mul.623/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.190.5 = f32[32,8,64]{2,1,0} multiply(f32[32,8,64]{2,1,0} %slice.110.4, f32[32,8,64]{2,1,0} %broadcast.192.8), metadata={op_type="aten__mul" op_name="aten__mul.623/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %subtract.2.5 = f32[32,8,64]{2,1,0} subtract(f32[32,8,64]{2,1,0} %multiply.189.7, f32[32,8,64]{2,1,0} %multiply.190.5), metadata={op_type="aten__sub" op_name="aten__sub.624/aten__sub" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.434.3 = bf16[32,8,64]{2,1,0} convert(f32[32,8,64]{2,1,0} %subtract.2.5)
  %multiply.191.7 = f32[32,8,64]{2,1,0} multiply(f32[32,8,64]{2,1,0} %slice.110.4, f32[32,8,64]{2,1,0} %broadcast.191.12), metadata={op_type="aten__mul" op_name="aten__mul.625/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %multiply.192.5 = f32[32,8,64]{2,1,0} multiply(f32[32,8,64]{2,1,0} %slice.108.4, f32[32,8,64]{2,1,0} %broadcast.192.8), metadata={op_type="aten__mul" op_name="aten__mul.626/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %add.109.5 = f32[32,8,64]{2,1,0} add(f32[32,8,64]{2,1,0} %multiply.191.7, f32[32,8,64]{2,1,0} %multiply.192.5), metadata={op_type="aten__add" op_name="aten__add.627/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %convert.435.3 = bf16[32,8,64]{2,1,0} convert(f32[32,8,64]{2,1,0} %add.109.5)
  ROOT %concatenate.16.1 = bf16[32,8,128]{2,1,0} concatenate(bf16[32,8,64]{2,1,0} %convert.434.3, bf16[32,8,64]{2,1,0} %convert.435.3), dimensions={2}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
}

%fused_slice (param_0.1: bf16[2,4233,16,8,128]) -> bf16[69353472] {
  %param_0.1 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  %bitcast.1518.1 = bf16[138706944]{0} bitcast(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.1)
  ROOT %slice.114.1 = bf16[69353472]{0} slice(bf16[138706944]{0} %bitcast.1518.1), slice={[69353472:138706944]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%wrapped_slice_computation.1 (param_0.342: bf16[2,4233,16,8,128]) -> bf16[1,4233,16,8,128] {
  %param_0.342 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(0)
  ROOT %slice.113.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} slice(bf16[2,4233,16,8,128]{4,3,2,1,0} %param_0.342), slice={[0:1], [0:4233], [0:16], [0:8], [0:128]}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
}

%command_buffer (p: bf16[151936,1024], p.1: s32[32], p.2: bf16[1024,2048], p.3: bf16[1024,2048], p.4: bf16[1024,2048], p.5: bf16[1024,2048], p.6: bf16[1024,2048], p.7: bf16[1024,2048], p.8: f32[], p.9: bf16[1024], p.10: bf16[6144,1024], p.11: bf16[1024,3072], p.12: bf16[1024], p.13: bf16[6144,1024], p.14: bf16[1024,3072], p.15: bf16[1024], p.16: bf16[6144,1024], p.17: bf16[1024,3072], p.18: bf16[1024], p.19: bf16[6144,1024], p.20: bf16[1024,3072], p.21: bf16[1024], p.22: bf16[6144,1024], p.23: bf16[1024,3072], p.24: bf16[1024], p.25: bf16[6144,1024], p.26: bf16[1024,3072], p.27: bf16[1024], p.28: bf16[4096,1024], p.29: bf16[128], p.30: bf16[40960,128], p.31: s32[32], p.32: bf16[2,4233,16,8,128]) -> (bf16[32,8,128], bf16[32,8,128], bf16[4233,16,8,128], bf16[1,4233,16,8,128]) {
  %p = bf16[151936,1024]{1,0} parameter(0)
  %p.1 = s32[32]{0} parameter(1)
  %p.2 = bf16[1024,2048]{1,0} parameter(2)
  %p.3 = bf16[1024,2048]{1,0} parameter(3)
  %p.4 = bf16[1024,2048]{1,0} parameter(4)
  %p.5 = bf16[1024,2048]{1,0} parameter(5)
  %p.6 = bf16[1024,2048]{1,0} parameter(6)
  %p.7 = bf16[1024,2048]{1,0} parameter(7)
  %p.8 = f32[] parameter(8)
  %p.9 = bf16[1024]{0} parameter(9)
  %p.10 = bf16[6144,1024]{1,0} parameter(10)
  %p.11 = bf16[1024,3072]{1,0} parameter(11)
  %p.12 = bf16[1024]{0} parameter(12)
  %p.13 = bf16[6144,1024]{1,0} parameter(13)
  %p.14 = bf16[1024,3072]{1,0} parameter(14)
  %p.15 = bf16[1024]{0} parameter(15)
  %p.16 = bf16[6144,1024]{1,0} parameter(16)
  %p.17 = bf16[1024,3072]{1,0} parameter(17)
  %p.18 = bf16[1024]{0} parameter(18)
  %p.19 = bf16[6144,1024]{1,0} parameter(19)
  %p.20 = bf16[1024,3072]{1,0} parameter(20)
  %p.21 = bf16[1024]{0} parameter(21)
  %p.22 = bf16[6144,1024]{1,0} parameter(22)
  %p.23 = bf16[1024,3072]{1,0} parameter(23)
  %p.24 = bf16[1024]{0} parameter(24)
  %p.25 = bf16[6144,1024]{1,0} parameter(25)
  %p.26 = bf16[1024,3072]{1,0} parameter(26)
  %p.27 = bf16[1024]{0} parameter(27)
  %p.28 = bf16[4096,1024]{1,0} parameter(28)
  %p.29 = bf16[128]{0} parameter(29)
  %p.30 = bf16[40960,128]{1,0} parameter(30)
  %p.31 = s32[32]{0} parameter(31)
  %p.32 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(32)
  %loop_gather_fusion = bf16[32,1,1024]{2,0,1} fusion(bf16[151936,1024]{1,0} %p, s32[32]{0} %p.1), kind=kLoop, calls=%fused_gather, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_concatenate = bf16[6144,2048]{1,0} fusion(bf16[1024,2048]{1,0} %p.2, bf16[1024,2048]{1,0} %p.3, bf16[1024,2048]{1,0} %p.4, bf16[1024,2048]{1,0} %p.5, bf16[1024,2048]{1,0} %p.6, /*index=5*/bf16[1024,2048]{1,0} %p.7), kind=kLoop, calls=%wrapped_concatenate_computation, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %gemm_fusion_dot.23.0 = bf16[32,6144]{1,0} fusion(bf16[6144,2048]{1,0} %wrapped_concatenate), kind=kCustom, calls=%gemm_fusion_dot.23_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton_gemm","triton_gemm_config":{"block_m":"64","block_n":"32","block_k":"128","split_k":"1","num_stages":"4","num_warps":"4","num_ctas":"1"}},"force_earliest_schedule":false}
  %fusion.86 = bf16[32,1024]{1,0} fusion(f32[] %p.8, bf16[32,1,1024]{2,0,1} %loop_gather_fusion, bf16[32,6144]{1,0} %gemm_fusion_dot.23.0, bf16[1024]{0} %p.9), kind=kCustom, calls=%fused_computation.69, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.13.0 = (bf16[32,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.86, bf16[6144,1024]{1,0} %p.10), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.13 = bf16[32,6144]{1,0} get-tuple-element((bf16[32,6144]{1,0}, s8[4194304]{0}) %custom-call.13.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion = bf16[32,3072]{1,0} fusion(bf16[32,6144]{1,0} %get-tuple-element.13), kind=kLoop, calls=%fused_convert, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.14.0 = (bf16[32,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[32,3072]{1,0} %loop_convert_fusion, bf16[1024,3072]{1,0} %p.11), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"98304","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.1.0 = bf16[32,1024]{1,0} get-tuple-element((bf16[32,1024]{1,0}, s8[4194304]{0}) %custom-call.14.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.87 = bf16[32,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.12, bf16[32,1,1024]{2,0,1} %loop_gather_fusion, bf16[32,6144]{1,0} %gemm_fusion_dot.23.0, bf16[32,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.70, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.15.0 = (bf16[32,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.87, bf16[6144,1024]{1,0} %p.13), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.2.0 = bf16[32,6144]{1,0} get-tuple-element((bf16[32,6144]{1,0}, s8[4194304]{0}) %custom-call.15.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.1 = bf16[32,3072]{1,0} fusion(bf16[32,6144]{1,0} %get-tuple-element.2.0), kind=kLoop, calls=%fused_convert.1, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.16.0 = (bf16[32,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[32,3072]{1,0} %loop_convert_fusion.1, bf16[1024,3072]{1,0} %p.14), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"98304","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.3.0 = bf16[32,1024]{1,0} get-tuple-element((bf16[32,1024]{1,0}, s8[4194304]{0}) %custom-call.16.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.88 = bf16[32,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.15, bf16[32,1024]{1,0} %get-tuple-element.3.0, bf16[32,6144]{1,0} %gemm_fusion_dot.23.0, bf16[32,1,1024]{2,0,1} %loop_gather_fusion, /*index=5*/bf16[32,1024]{1,0} %get-tuple-element.1.0), kind=kCustom, calls=%fused_computation.71, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.17.0 = (bf16[32,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.88, bf16[6144,1024]{1,0} %p.16), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.4.0 = bf16[32,6144]{1,0} get-tuple-element((bf16[32,6144]{1,0}, s8[4194304]{0}) %custom-call.17.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.2 = bf16[32,3072]{1,0} fusion(bf16[32,6144]{1,0} %get-tuple-element.4.0), kind=kLoop, calls=%fused_convert.2, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.18.0 = (bf16[32,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[32,3072]{1,0} %loop_convert_fusion.2, bf16[1024,3072]{1,0} %p.17), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"98304","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.5.0 = bf16[32,1024]{1,0} get-tuple-element((bf16[32,1024]{1,0}, s8[4194304]{0}) %custom-call.18.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_add_fusion = f32[32,1024]{1,0} fusion(bf16[32,6144]{1,0} %gemm_fusion_dot.23.0, bf16[32,1024]{1,0} %get-tuple-element.5.0, bf16[32,1024]{1,0} %get-tuple-element.3.0, bf16[32,1,1024]{2,0,1} %loop_gather_fusion, bf16[32,1024]{1,0} %get-tuple-element.1.0), kind=kLoop, calls=%fused_add, metadata={op_type="aten__add" op_name="aten__add.574/aten__add" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.89 = bf16[32,1024]{1,0} fusion(f32[32,1024]{1,0} %loop_add_fusion, f32[] %p.8, bf16[1024]{0} %p.18), kind=kCustom, calls=%fused_computation.72, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.19.0 = (bf16[32,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.89, bf16[6144,1024]{1,0} %p.19), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.6.0 = bf16[32,6144]{1,0} get-tuple-element((bf16[32,6144]{1,0}, s8[4194304]{0}) %custom-call.19.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.3 = bf16[32,3072]{1,0} fusion(bf16[32,6144]{1,0} %get-tuple-element.6.0), kind=kLoop, calls=%fused_convert.3, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.20.0 = (bf16[32,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[32,3072]{1,0} %loop_convert_fusion.3, bf16[1024,3072]{1,0} %p.20), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"98304","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.7.0 = bf16[32,1024]{1,0} get-tuple-element((bf16[32,1024]{1,0}, s8[4194304]{0}) %custom-call.20.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.90 = bf16[32,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.21, f32[32,1024]{1,0} %loop_add_fusion, bf16[32,1024]{1,0} %get-tuple-element.7.0, bf16[32,6144]{1,0} %gemm_fusion_dot.23.0), kind=kCustom, calls=%fused_computation.73, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.21.0 = (bf16[32,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.90, bf16[6144,1024]{1,0} %p.22), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.8.0 = bf16[32,6144]{1,0} get-tuple-element((bf16[32,6144]{1,0}, s8[4194304]{0}) %custom-call.21.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.4 = bf16[32,3072]{1,0} fusion(bf16[32,6144]{1,0} %get-tuple-element.8.0), kind=kLoop, calls=%fused_convert.4, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.22.0 = (bf16[32,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[32,3072]{1,0} %loop_convert_fusion.4, bf16[1024,3072]{1,0} %p.23), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"98304","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.9.0 = bf16[32,1024]{1,0} get-tuple-element((bf16[32,1024]{1,0}, s8[4194304]{0}) %custom-call.22.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.91 = bf16[32,1024]{1,0} fusion(f32[] %p.8, bf16[1024]{0} %p.24, f32[32,1024]{1,0} %loop_add_fusion, bf16[32,1024]{1,0} %get-tuple-element.7.0, bf16[32,6144]{1,0} %gemm_fusion_dot.23.0, /*index=5*/bf16[32,1024]{1,0} %get-tuple-element.9.0), kind=kCustom, calls=%fused_computation.74, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.23.0 = (bf16[32,6144]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.91, bf16[6144,1024]{1,0} %p.25), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"6291456","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.10.0 = bf16[32,6144]{1,0} get-tuple-element((bf16[32,6144]{1,0}, s8[4194304]{0}) %custom-call.23.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %loop_convert_fusion.5 = bf16[32,3072]{1,0} fusion(bf16[32,6144]{1,0} %get-tuple-element.10.0), kind=kLoop, calls=%fused_convert.5, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756 deduplicated_name="loop_convert_fusion"}
  %custom-call.24.0 = (bf16[32,1024]{1,0}, s8[4194304]{0}) custom-call(bf16[32,3072]{1,0} %loop_convert_fusion.5, bf16[1024,3072]{1,0} %p.26), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"98304","rhs_stride":"3145728","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.11.0 = bf16[32,1024]{1,0} get-tuple-element((bf16[32,1024]{1,0}, s8[4194304]{0}) %custom-call.24.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.92 = bf16[32,1024]{1,0} fusion(f32[] %p.8, bf16[32,1024]{1,0} %get-tuple-element.11.0, bf16[1024]{0} %p.27, f32[32,1024]{1,0} %loop_add_fusion, bf16[32,1024]{1,0} %get-tuple-element.7.0, /*index=5*/bf16[32,6144]{1,0} %gemm_fusion_dot.23.0, bf16[32,1024]{1,0} %get-tuple-element.9.0), kind=kCustom, calls=%fused_computation.75, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","1024"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %custom-call.25.0 = (bf16[32,4096]{1,0}, s8[4194304]{0}) custom-call(bf16[32,1024]{1,0} %fusion.92, bf16[4096,1024]{1,0} %p.28), custom_call_target="__cublas$gemm", metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"gemm_backend_config":{"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"],"algorithm":"ALG_UNSET"},"epilogue":"DEFAULT","damax_output":false,"lhs_stride":"32768","rhs_stride":"4194304","grad_x":false,"grad_y":false},"force_earliest_schedule":false}
  %get-tuple-element.12.0 = bf16[32,4096]{1,0} get-tuple-element((bf16[32,4096]{1,0}, s8[4194304]{0}) %custom-call.25.0), index=0, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %wrapped_slice = bf16[32,1024]{1,0} fusion(bf16[32,4096]{1,0} %get-tuple-element.12.0), kind=kLoop, calls=%wrapped_slice_computation, metadata={op_type="aten__split" op_name="aten__split" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %fusion.78 = f32[32,8,128]{2,1,0} fusion(f32[] %p.8, bf16[32,4096]{1,0} %get-tuple-element.12.0, bf16[128]{0} %p.29), kind=kCustom, calls=%fused_computation.61, metadata={op_type="aten__mul" op_name="aten__mul.621/aten__mul" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}, backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"fusion_backend_config":{"kind":"__triton","block_level_fusion_config":{"output_tiles":[{"sizes":["1","4","128"]}],"num_warps":"2"}},"force_earliest_schedule":false}
  %input_concatenate_fusion = bf16[32,8,128]{2,1,0} fusion(f32[32,8,128]{2,1,0} %fusion.78, bf16[40960,128]{1,0} %p.30, s32[32]{0} %p.31), kind=kInput, calls=%fused_concatenate, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %bitcast.1510.0 = bf16[32,8,128]{2,1,0} bitcast(bf16[32,1024]{1,0} %wrapped_slice)
  %loop_slice_fusion = bf16[69353472]{0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.32), kind=kLoop, calls=%fused_slice, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  %bitcast.1522.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[69353472]{0} %loop_slice_fusion)
  %wrapped_slice.1 = bf16[1,4233,16,8,128]{4,3,2,1,0} fusion(bf16[2,4233,16,8,128]{4,3,2,1,0} %p.32), kind=kLoop, calls=%wrapped_slice_computation.1, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/usr/local/lib/python3.10/site-packages/torch/_higher_order_ops/auto_functionalize.py" source_line=54}
  ROOT %tuple = (bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) tuple(bf16[32,8,128]{2,1,0} %input_concatenate_fusion, bf16[32,8,128]{2,1,0} %bitcast.1510.0, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1522.0, bf16[1,4233,16,8,128]{4,3,2,1,0} %wrapped_slice.1)
}

ENTRY %SyncTensorsGraph.589 (p0.1.0: bf16[128], p1.4.0: f32[], p2.6.0: bf16[4096,1024], p3.8.0: bf16[1024], p4.24.0: s32[32], p5.26.0: bf16[151936,1024], p6.30.0: bf16[1024,2048], p7.46.0: bf16[1024,3072], p8.48.0: bf16[6144,1024], p9.50.0: bf16[1024], p10.102.0: bf16[1024,2048], p11.118.0: bf16[1024,3072], p12.120.0: bf16[6144,1024], p13.122.0: bf16[1024], p14.174.0: bf16[1024,2048], p15.190.0: bf16[1024,3072], p16.192.0: bf16[6144,1024], p17.194.0: bf16[1024], p18.246.0: bf16[1024,2048], p19.262.0: bf16[1024,3072], p20.264.0: bf16[6144,1024], p21.266.0: bf16[1024], p22.318.0: bf16[1024,2048], p23.334.0: bf16[1024,3072], p24.336.0: bf16[6144,1024], p25.338.0: bf16[1024], p26.390.0: bf16[1024,2048], p27.406.0: bf16[1024,3072], p28.408.0: bf16[6144,1024], p29.410.0: bf16[1024], p30.534.0: s32[32], p31.535.0: bf16[40960,128], p32.579.0: bf16[2,4233,16,8,128]) -> (bf16[32,8,128], bf16[32,8,128], bf16[4233,16,8,128], bf16[4233,16,8,128]) {
  %p1.4.0 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch/_ops.py" source_line=756}
  %p32.579.0 = bf16[2,4233,16,8,128]{4,3,2,1,0} parameter(32), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p31.535.0 = bf16[40960,128]{1,0} parameter(31), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p30.534.0 = s32[32]{0} parameter(30), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p29.410.0 = bf16[1024]{0} parameter(29), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p28.408.0 = bf16[6144,1024]{1,0} parameter(28), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p27.406.0 = bf16[1024,3072]{1,0} parameter(27), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p26.390.0 = bf16[1024,2048]{1,0} parameter(26), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p25.338.0 = bf16[1024]{0} parameter(25), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p24.336.0 = bf16[6144,1024]{1,0} parameter(24), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p23.334.0 = bf16[1024,3072]{1,0} parameter(23), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p22.318.0 = bf16[1024,2048]{1,0} parameter(22), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p21.266.0 = bf16[1024]{0} parameter(21), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p20.264.0 = bf16[6144,1024]{1,0} parameter(20), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p19.262.0 = bf16[1024,3072]{1,0} parameter(19), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p18.246.0 = bf16[1024,2048]{1,0} parameter(18), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p17.194.0 = bf16[1024]{0} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p16.192.0 = bf16[6144,1024]{1,0} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p15.190.0 = bf16[1024,3072]{1,0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p14.174.0 = bf16[1024,2048]{1,0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p13.122.0 = bf16[1024]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p12.120.0 = bf16[6144,1024]{1,0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p11.118.0 = bf16[1024,3072]{1,0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p10.102.0 = bf16[1024,2048]{1,0} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p9.50.0 = bf16[1024]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p8.48.0 = bf16[6144,1024]{1,0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p7.46.0 = bf16[1024,3072]{1,0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p6.30.0 = bf16[1024,2048]{1,0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p5.26.0 = bf16[151936,1024]{1,0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p4.24.0 = s32[32]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p3.8.0 = bf16[1024]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p2.6.0 = bf16[4096,1024]{1,0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %p0.1.0 = bf16[128]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/usr/local/lib/python3.10/site-packages/torch_xla/_dynamo/dynamo_bridge.py" source_line=355}
  %call = (bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) call(bf16[151936,1024]{1,0} %p5.26.0, s32[32]{0} %p4.24.0, bf16[1024,2048]{1,0} %p26.390.0, bf16[1024,2048]{1,0} %p22.318.0, bf16[1024,2048]{1,0} %p18.246.0, /*index=5*/bf16[1024,2048]{1,0} %p14.174.0, bf16[1024,2048]{1,0} %p10.102.0, bf16[1024,2048]{1,0} %p6.30.0, f32[] %p1.4.0, bf16[1024]{0} %p9.50.0, /*index=10*/bf16[6144,1024]{1,0} %p8.48.0, bf16[1024,3072]{1,0} %p7.46.0, bf16[1024]{0} %p13.122.0, bf16[6144,1024]{1,0} %p12.120.0, bf16[1024,3072]{1,0} %p11.118.0, /*index=15*/bf16[1024]{0} %p17.194.0, bf16[6144,1024]{1,0} %p16.192.0, bf16[1024,3072]{1,0} %p15.190.0, bf16[1024]{0} %p21.266.0, bf16[6144,1024]{1,0} %p20.264.0, /*index=20*/bf16[1024,3072]{1,0} %p19.262.0, bf16[1024]{0} %p25.338.0, bf16[6144,1024]{1,0} %p24.336.0, bf16[1024,3072]{1,0} %p23.334.0, bf16[1024]{0} %p29.410.0, /*index=25*/bf16[6144,1024]{1,0} %p28.408.0, bf16[1024,3072]{1,0} %p27.406.0, bf16[1024]{0} %p3.8.0, bf16[4096,1024]{1,0} %p2.6.0, bf16[128]{0} %p0.1.0, /*index=30*/bf16[40960,128]{1,0} %p31.535.0, s32[32]{0} %p30.534.0, bf16[2,4233,16,8,128]{4,3,2,1,0} %p32.579.0), to_apply=%command_buffer
  %get-tuple-element.15 = bf16[32,8,128]{2,1,0} get-tuple-element((bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=0
  %get-tuple-element.16 = bf16[32,8,128]{2,1,0} get-tuple-element((bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=1
  %get-tuple-element.17 = bf16[4233,16,8,128]{3,2,1,0} get-tuple-element((bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=2
  %get-tuple-element.18 = bf16[1,4233,16,8,128]{4,3,2,1,0} get-tuple-element((bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[1,4233,16,8,128]{4,3,2,1,0}) %call), index=3
  %bitcast.1515.0 = bf16[4233,16,8,128]{3,2,1,0} bitcast(bf16[1,4233,16,8,128]{4,3,2,1,0} %get-tuple-element.18)
  ROOT %tuple.588.0 = (bf16[32,8,128]{2,1,0}, bf16[32,8,128]{2,1,0}, bf16[4233,16,8,128]{3,2,1,0}, bf16[4233,16,8,128]{3,2,1,0}) tuple(bf16[32,8,128]{2,1,0} %get-tuple-element.15, bf16[32,8,128]{2,1,0} %get-tuple-element.16, bf16[4233,16,8,128]{3,2,1,0} %bitcast.1515.0, bf16[4233,16,8,128]{3,2,1,0} %get-tuple-element.17)
}

