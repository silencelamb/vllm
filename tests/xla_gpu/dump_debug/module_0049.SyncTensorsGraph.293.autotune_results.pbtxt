version: 3
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[1024,2048]{1,0} parameter(1)\n  tmp_2 = bf16[2048,2048]{1,0} concatenate(bf16[1024,2048]{1,0} tmp_0, bf16[1024,2048]{1,0} tmp_1), dimensions={0}\n  tmp_3 = bf16[] constant(0)\n  tmp_4 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_3), dimensions={}\n  tmp_5 = bf16[2048,16]{0,1} dot(bf16[2048,2048]{1,0} tmp_2, bf16[16,2048]{1,0} tmp_4), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_6 = bf16[16,2048]{1,0} bitcast(bf16[2048,16]{0,1} tmp_5)\n}"
  result {
    run_time {
      nanos: 22528
    }
    triton {
      block_m: 16
      block_n: 16
      block_k: 256
      split_k: 1
      num_stages: 3
      num_warps: 4
      num_ctas: 1
    }
  }
}
results {
  device: "CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB"
  hlo: "{\n  tmp_0 = bf16[1024,2048]{1,0} parameter(0)\n  tmp_1 = bf16[] constant(0)\n  tmp_2 = bf16[16,2048]{1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[1024,16]{0,1} dot(bf16[1024,2048]{1,0} tmp_0, bf16[16,2048]{1,0} tmp_2), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n  ROOT tmp_4 = bf16[16,1024]{1,0} bitcast(bf16[1024,16]{0,1} tmp_3)\n}"
  result {
    run_time {
      nanos: 32768
    }
    triton {
      block_m: 16
      block_n: 16
      block_k: 256
      split_k: 1
      num_stages: 3
      num_warps: 4
      num_ctas: 1
    }
  }
}
